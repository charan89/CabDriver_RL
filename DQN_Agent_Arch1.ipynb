{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cab-Driver Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Importing libraries\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "from collections import deque\n",
    "import collections\n",
    "import pickle\n",
    "\n",
    "# for building DQN model\n",
    "from keras import layers\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from keras.optimizers import Adam\n",
    "import time\n",
    "# for plotting graphs\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Env import CabDriver\n",
    "env=CabDriver()\n",
    "action_space, state_space, state = env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining Time Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Already imported time_matrix in enviroment so no need to pass via arguements\n",
    "Time_matrix = np.load(\"TM.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent Class\n",
    "\n",
    "If you are using this framework, you need to fill the following to complete the following code block:\n",
    "1. State and Action Size\n",
    "2. Hyperparameters\n",
    "3. Create a neural-network model in function 'build_model()'\n",
    "4. Define epsilon-greedy strategy in function 'get_action()'\n",
    "5. Complete the function 'append_sample()'. This function appends the recent experience tuple <state, action, reward, new-state> to the memory\n",
    "6. Complete the 'train_model()' function with following logic:\n",
    "   - If the memory size is greater than mini-batch size, you randomly sample experiences from memory as per the mini-batch size and do the following:\n",
    "      - Initialise your input and output batch for training the model\n",
    "      - Calculate the target Q value for each sample: reward + gamma*max(Q(s'a,))\n",
    "      - Get Q(s', a) values from the last trained model\n",
    "      - Update the input batch as your encoded state and output batch as your Q-values\n",
    "      - Then fit your DQN model using the updated input and output batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNAgent:\n",
    "    def __init__(self, state_size, action_size):\n",
    "        # Define size of state and action\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "\n",
    "        # Write here: Specify you hyper parameters for the DQN\n",
    "        self.discount_factor =0.95\n",
    "        self.learning_rate = 0.01  \n",
    "        self.epsilon_max = 1\n",
    "        self.epsilon=1\n",
    "        self.epsilon_decay = -0.0005\n",
    "        self.epsilon_min = 0.00001\n",
    "        \n",
    "        self.batch_size = 32        \n",
    "        # create replay memory using deque\n",
    "        self.memory = deque(maxlen=2000)\n",
    "        # for tracking states which is (0,0,0) and action as (0,4)\n",
    "        self.states_tracked=[]\n",
    "        self.track_state=env.state_encod_arch1((0,0,0)).reshape(1,36)\n",
    "        \n",
    "        # create main model and target model\n",
    "        self.model = self.build_model()\n",
    "        #self.model.load_weights(\"model_weights.h5\")       \n",
    "\n",
    "    # approximate Q function using Neural Network\n",
    "    def build_model(self):\n",
    "        model = Sequential()\n",
    "        # Write your code here: Add layers to your neural nets       \n",
    "        # hidden layers\n",
    "        model.add(Dense(32, input_dim=self.state_size, activation='relu', kernel_initializer='he_uniform'))\n",
    "        model.add(Dense(32, activation='relu', kernel_initializer='he_uniform'))\n",
    "        # the output layer: output is of size num_actions\n",
    "        model.add(Dense(self.action_size, activation='relu', kernel_initializer='he_uniform'))\n",
    "        model.summary()\n",
    "        model.compile(loss='mse', optimizer=Adam(lr=self.learning_rate))\n",
    "       \n",
    "        return model\n",
    "\n",
    "\n",
    "\n",
    "    def get_action(self, state, actions_idx):\n",
    "        \n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return random.choice(actions_idx)\n",
    "        else:\n",
    "            #return random.choice(actions)\n",
    "            # choose the action with the highest q(s, a)\n",
    "            # the first index corresponds to the batch size, so\n",
    "            # reshape state to (1, state_size) so that the first index corresponds to the batch size\n",
    "            state = env.state_encod_arch1(state).reshape(1,36)\n",
    "            q_value = self.model.predict(state)\n",
    "            # check for q values whose requests are possible on given day and time\n",
    "            possible_q=[q_value[0][k] for k in actions_idx]\n",
    "            return actions_idx[np.argmax(possible_q)]\n",
    "             \n",
    "\n",
    "\n",
    "    def append_sample(self, state, action_idx, reward, next_state,done):\n",
    "        # save sample <s,a,r,s'> to the replay memory\n",
    "        self.memory.append((state, action_idx, reward, next_state,done))\n",
    "    \n",
    "    \n",
    "    \n",
    "    # pick samples randomly from replay memory (with batch_size) and train the network\n",
    "    def train_model(self):\n",
    "        \n",
    "        if len(self.memory) > self.batch_size:\n",
    "            \n",
    "            # sample minibatch from memory\n",
    "            minibatch = random.sample(self.memory, self.batch_size)\n",
    "\n",
    "            # initialise two matrices - update_input and update_output\n",
    "            update_input = np.zeros((self.batch_size, self.state_size))\n",
    "            update_output = np.zeros((self.batch_size, self.state_size))\n",
    "            actions, rewards,done = [], [],[]\n",
    "\n",
    "            # populate update_input and update_output and the lists rewards, actions, done\n",
    "            for i in range(self.batch_size):\n",
    "                state, action, reward, next_state,don = minibatch[i]\n",
    "                update_input[i] = env.state_encod_arch1(state)\n",
    "                actions.append(action)\n",
    "                rewards.append(reward)\n",
    "                done.append(don)\n",
    "                update_output[i] = env.state_encod_arch1(next_state)\n",
    "\n",
    "\n",
    "            # predict the target q-values from states s\n",
    "            target = self.model.predict(update_input)\n",
    "\n",
    "            # target for q-network\n",
    "            target_qval = self.model.predict(update_output)\n",
    "\n",
    "            # update the target values\n",
    "            for i in range(self.batch_size):\n",
    "                if done[i]:\n",
    "                    target[i][actions[i]] = rewards[i]\n",
    "                else: # non-terminal state\n",
    "                    target[i][actions[i]] = rewards[i] + self.discount_factor * np.max(target_qval[i])\n",
    "            # model fit\n",
    "            self.model.fit(update_input, target, batch_size=self.batch_size, epochs=1, verbose=0)\n",
    "            \n",
    "\n",
    "    def save_tracking_states(self):\n",
    "        # Using the model to predict q_value of state(0,0,0) of action of index-4 (0,4)\n",
    "        q_value = self.model.predict(self.track_state)\n",
    "        self.states_tracked.append(q_value[0][4])\n",
    "        \n",
    "    def save(self, name):\n",
    "        with open(name, 'wb') as file:  \n",
    "            pickle.dump(self.model, file,pickle.HIGHEST_PROTOCOL)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Episodes = 20000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DQN block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 32)                1184      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 21)                693       \n",
      "=================================================================\n",
      "Total params: 2,933\n",
      "Trainable params: 2,933\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From D:\\ProgramData\\Anaconda3\\envs\\myenv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Saving Model 0\n",
      "episode 9, reward -186.0, memory_length 1443, epsilon 0.9955001547284723 total_time 723\n",
      "episode 19, reward 88.0, memory_length 2000, epsilon 0.9905350769930761 total_time 724\n",
      "episode 29, reward -189.0, memory_length 2000, epsilon 0.9855947626861951 total_time 729\n",
      "episode 39, reward -83.0, memory_length 2000, epsilon 0.9806790882997144 total_time 724\n",
      "episode 49, reward -334.0, memory_length 2000, epsilon 0.9757879309415182 total_time 722\n",
      "episode 59, reward -312.0, memory_length 2000, epsilon 0.9709211683324178 total_time 723\n",
      "episode 69, reward -356.0, memory_length 2000, epsilon 0.9660786788030947 total_time 721\n",
      "episode 79, reward -24.0, memory_length 2000, epsilon 0.9612603412910584 total_time 723\n",
      "episode 89, reward -19.0, memory_length 2000, epsilon 0.9564660353376199 total_time 722\n",
      "episode 99, reward -275.0, memory_length 2000, epsilon 0.9516956410848808 total_time 721\n",
      "Saving Model 100\n",
      "episode 109, reward -41.0, memory_length 2000, epsilon 0.9469490392727365 total_time 721\n",
      "episode 119, reward -365.0, memory_length 2000, epsilon 0.9422261112358942 total_time 721\n",
      "episode 129, reward -322.0, memory_length 2000, epsilon 0.9375267389009072 total_time 725\n",
      "episode 139, reward 192.0, memory_length 2000, epsilon 0.9328508047832221 total_time 732\n",
      "episode 149, reward -285.0, memory_length 2000, epsilon 0.9281981919842428 total_time 723\n",
      "episode 159, reward 202.0, memory_length 2000, epsilon 0.9235687841884068 total_time 721\n",
      "episode 169, reward -303.0, memory_length 2000, epsilon 0.918962465660278 total_time 723\n",
      "episode 179, reward -150.0, memory_length 2000, epsilon 0.9143791212416534 total_time 723\n",
      "episode 189, reward -289.0, memory_length 2000, epsilon 0.9098186363486838 total_time 731\n",
      "episode 199, reward -10.0, memory_length 2000, epsilon 0.9052808969690094 total_time 722\n",
      "Saving Model 200\n",
      "episode 209, reward -218.0, memory_length 2000, epsilon 0.9007657896589091 total_time 724\n",
      "episode 219, reward -105.0, memory_length 2000, epsilon 0.8962732015404654 total_time 723\n",
      "episode 229, reward 51.0, memory_length 2000, epsilon 0.891803020298741 total_time 726\n",
      "episode 239, reward -457.0, memory_length 2000, epsilon 0.8873551341789723 total_time 725\n",
      "episode 249, reward -34.0, memory_length 2000, epsilon 0.8829294319837746 total_time 725\n",
      "episode 259, reward 228.0, memory_length 2000, epsilon 0.8785258030703623 total_time 723\n",
      "episode 269, reward 166.0, memory_length 2000, epsilon 0.8741441373477834 total_time 721\n",
      "episode 279, reward -277.0, memory_length 2000, epsilon 0.8697843252741666 total_time 725\n",
      "episode 289, reward 61.0, memory_length 2000, epsilon 0.8654462578539829 total_time 724\n",
      "episode 299, reward 174.0, memory_length 2000, epsilon 0.8611298266353209 total_time 723\n",
      "Saving Model 300\n",
      "episode 309, reward -54.0, memory_length 2000, epsilon 0.8568349237071754 total_time 729\n",
      "episode 319, reward 250.0, memory_length 2000, epsilon 0.8525614416967494 total_time 724\n",
      "episode 329, reward -42.0, memory_length 2000, epsilon 0.84830927376677 total_time 723\n",
      "episode 339, reward 4.0, memory_length 2000, epsilon 0.8440783136128177 total_time 721\n",
      "episode 349, reward -328.0, memory_length 2000, epsilon 0.8398684554606681 total_time 728\n",
      "episode 359, reward -151.0, memory_length 2000, epsilon 0.8356795940636483 total_time 725\n",
      "episode 369, reward 85.0, memory_length 2000, epsilon 0.8315116247000052 total_time 730\n",
      "episode 379, reward 340.0, memory_length 2000, epsilon 0.8273644431702872 total_time 724\n",
      "episode 389, reward -23.0, memory_length 2000, epsilon 0.8232379457947406 total_time 730\n",
      "episode 399, reward 138.0, memory_length 2000, epsilon 0.819132029410716 total_time 723\n",
      "Saving Model 400\n",
      "episode 409, reward 196.0, memory_length 2000, epsilon 0.8150465913700896 total_time 724\n",
      "episode 419, reward 39.0, memory_length 2000, epsilon 0.8109815295366979 total_time 723\n",
      "episode 429, reward 253.0, memory_length 2000, epsilon 0.8069367422837833 total_time 727\n",
      "episode 439, reward -199.0, memory_length 2000, epsilon 0.8029121284914538 total_time 740\n",
      "episode 449, reward -116.0, memory_length 2000, epsilon 0.7989075875441549 total_time 727\n",
      "episode 459, reward 48.0, memory_length 2000, epsilon 0.7949230193281545 total_time 723\n",
      "episode 469, reward -104.0, memory_length 2000, epsilon 0.7909583242290396 total_time 721\n",
      "episode 479, reward 115.0, memory_length 2000, epsilon 0.7870134031292261 total_time 724\n",
      "episode 489, reward 119.0, memory_length 2000, epsilon 0.7830881574054811 total_time 725\n",
      "episode 499, reward 217.0, memory_length 2000, epsilon 0.7791824889264571 total_time 727\n",
      "Saving Model 500\n",
      "episode 509, reward -23.0, memory_length 2000, epsilon 0.7752963000502389 total_time 721\n",
      "episode 519, reward 76.0, memory_length 2000, epsilon 0.7714294936219019 total_time 721\n",
      "episode 529, reward 93.0, memory_length 2000, epsilon 0.7675819729710842 total_time 732\n",
      "episode 539, reward 193.0, memory_length 2000, epsilon 0.763753641909569 total_time 721\n",
      "episode 549, reward -74.0, memory_length 2000, epsilon 0.7599444047288803 total_time 724\n",
      "episode 559, reward 245.0, memory_length 2000, epsilon 0.7561541661978903 total_time 725\n",
      "episode 569, reward 247.0, memory_length 2000, epsilon 0.7523828315604384 total_time 721\n",
      "episode 579, reward 94.0, memory_length 2000, epsilon 0.7486303065329623 total_time 730\n",
      "episode 589, reward 161.0, memory_length 2000, epsilon 0.7448964973021404 total_time 722\n",
      "episode 599, reward 98.0, memory_length 2000, epsilon 0.7411813105225479 total_time 722\n",
      "Saving Model 600\n",
      "episode 609, reward 174.0, memory_length 2000, epsilon 0.7374846533143217 total_time 723\n",
      "episode 619, reward 141.0, memory_length 2000, epsilon 0.733806433260839 total_time 726\n",
      "episode 629, reward -155.0, memory_length 2000, epsilon 0.7301465584064071 total_time 724\n",
      "episode 639, reward 255.0, memory_length 2000, epsilon 0.7265049372539636 total_time 723\n",
      "episode 649, reward 111.0, memory_length 2000, epsilon 0.7228814787627905 total_time 723\n",
      "episode 659, reward 141.0, memory_length 2000, epsilon 0.7192760923462365 total_time 726\n",
      "episode 669, reward 373.0, memory_length 2000, epsilon 0.7156886878694535 total_time 721\n",
      "episode 679, reward 224.0, memory_length 2000, epsilon 0.7121191756471427 total_time 722\n",
      "episode 689, reward 237.0, memory_length 2000, epsilon 0.7085674664413126 total_time 723\n",
      "episode 699, reward 284.0, memory_length 2000, epsilon 0.7050334714590482 total_time 728\n",
      "Saving Model 700\n",
      "episode 709, reward 141.0, memory_length 2000, epsilon 0.7015171023502909 total_time 726\n",
      "episode 719, reward 376.0, memory_length 2000, epsilon 0.6980182712056295 total_time 733\n",
      "episode 729, reward -90.0, memory_length 2000, epsilon 0.6945368905541035 total_time 729\n",
      "episode 739, reward 535.0, memory_length 2000, epsilon 0.6910728733610152 total_time 721\n",
      "episode 749, reward 303.0, memory_length 2000, epsilon 0.6876261330257543 total_time 726\n",
      "episode 759, reward 310.0, memory_length 2000, epsilon 0.684196583379633 total_time 721\n",
      "episode 769, reward 157.0, memory_length 2000, epsilon 0.6807841386837313 total_time 721\n",
      "episode 779, reward 451.0, memory_length 2000, epsilon 0.6773887136267543 total_time 727\n",
      "episode 789, reward -181.0, memory_length 2000, epsilon 0.6740102233228988 total_time 722\n",
      "episode 799, reward 238.0, memory_length 2000, epsilon 0.670648583309731 total_time 721\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Model 800\n",
      "episode 809, reward 252.0, memory_length 2000, epsilon 0.6673037095460755 total_time 729\n",
      "episode 819, reward 542.0, memory_length 2000, epsilon 0.6639755184099142 total_time 725\n",
      "episode 829, reward 166.0, memory_length 2000, epsilon 0.6606639266962953 total_time 721\n",
      "episode 839, reward -50.0, memory_length 2000, epsilon 0.6573688516152534 total_time 721\n",
      "episode 849, reward 299.0, memory_length 2000, epsilon 0.6540902107897397 total_time 725\n",
      "episode 859, reward 381.0, memory_length 2000, epsilon 0.6508279222535631 total_time 732\n",
      "episode 869, reward 161.0, memory_length 2000, epsilon 0.64758190444934 total_time 722\n",
      "episode 879, reward 116.0, memory_length 2000, epsilon 0.6443520762264566 total_time 722\n",
      "episode 889, reward -23.0, memory_length 2000, epsilon 0.6411383568390387 total_time 721\n",
      "episode 899, reward -15.0, memory_length 2000, epsilon 0.6379406659439346 total_time 723\n",
      "Saving Model 900\n",
      "episode 909, reward 463.0, memory_length 2000, epsilon 0.6347589235987051 total_time 721\n",
      "episode 919, reward 351.0, memory_length 2000, epsilon 0.631593050259626 total_time 729\n",
      "episode 929, reward 36.0, memory_length 2000, epsilon 0.6284429667796988 total_time 729\n",
      "episode 939, reward 158.0, memory_length 2000, epsilon 0.6253085944066726 total_time 728\n",
      "episode 949, reward 148.0, memory_length 2000, epsilon 0.6221898547810748 total_time 721\n",
      "episode 959, reward 292.0, memory_length 2000, epsilon 0.6190866699342522 total_time 721\n",
      "episode 969, reward 221.0, memory_length 2000, epsilon 0.6159989622864221 total_time 728\n",
      "episode 979, reward 341.0, memory_length 2000, epsilon 0.6129266546447325 total_time 722\n",
      "episode 989, reward 281.0, memory_length 2000, epsilon 0.6098696702013323 total_time 725\n",
      "episode 999, reward 610.0, memory_length 2000, epsilon 0.6068279325314512 total_time 724\n",
      "Saving Model 1000\n",
      "episode 1009, reward 212.0, memory_length 2000, epsilon 0.6038013655914889 total_time 728\n",
      "episode 1019, reward 299.0, memory_length 2000, epsilon 0.6007898937171146 total_time 725\n",
      "episode 1029, reward 465.0, memory_length 2000, epsilon 0.5977934416213744 total_time 726\n",
      "episode 1039, reward 49.0, memory_length 2000, epsilon 0.5948119343928097 total_time 721\n",
      "episode 1049, reward 138.0, memory_length 2000, epsilon 0.5918452974935846 total_time 732\n",
      "episode 1059, reward 471.0, memory_length 2000, epsilon 0.5888934567576223 total_time 723\n",
      "episode 1069, reward 143.0, memory_length 2000, epsilon 0.5859563383887504 total_time 722\n",
      "episode 1079, reward 319.0, memory_length 2000, epsilon 0.5830338689588568 total_time 721\n",
      "episode 1089, reward 250.0, memory_length 2000, epsilon 0.5801259754060536 total_time 724\n",
      "episode 1099, reward 722.0, memory_length 2000, epsilon 0.5772325850328504 total_time 725\n",
      "Saving Model 1100\n",
      "episode 1109, reward 463.0, memory_length 2000, epsilon 0.5743536255043372 total_time 730\n",
      "episode 1119, reward 165.0, memory_length 2000, epsilon 0.5714890248463761 total_time 723\n",
      "episode 1129, reward 462.0, memory_length 2000, epsilon 0.5686387114438011 total_time 723\n",
      "episode 1139, reward 775.0, memory_length 2000, epsilon 0.5658026140386287 total_time 727\n",
      "episode 1149, reward 408.0, memory_length 2000, epsilon 0.5629806617282764 total_time 732\n",
      "episode 1159, reward 425.0, memory_length 2000, epsilon 0.5601727839637891 total_time 725\n",
      "episode 1169, reward 517.0, memory_length 2000, epsilon 0.5573789105480766 total_time 721\n",
      "episode 1179, reward 633.0, memory_length 2000, epsilon 0.5545989716341581 total_time 723\n",
      "episode 1189, reward 710.0, memory_length 2000, epsilon 0.5518328977234156 total_time 722\n",
      "episode 1199, reward 634.0, memory_length 2000, epsilon 0.5490806196638577 total_time 721\n",
      "Saving Model 1200\n",
      "episode 1209, reward 548.0, memory_length 2000, epsilon 0.5463420686483893 total_time 722\n",
      "episode 1219, reward 421.0, memory_length 2000, epsilon 0.5436171762130925 total_time 724\n",
      "episode 1229, reward 292.0, memory_length 2000, epsilon 0.5409058742355145 total_time 721\n",
      "episode 1239, reward 408.0, memory_length 2000, epsilon 0.5382080949329644 total_time 723\n",
      "episode 1249, reward 159.0, memory_length 2000, epsilon 0.5355237708608195 total_time 726\n",
      "episode 1259, reward 665.0, memory_length 2000, epsilon 0.5328528349108379 total_time 722\n",
      "episode 1269, reward 134.0, memory_length 2000, epsilon 0.5301952203094819 total_time 722\n",
      "episode 1279, reward 480.0, memory_length 2000, epsilon 0.5275508606162479 total_time 723\n",
      "episode 1289, reward 494.0, memory_length 2000, epsilon 0.5249196897220061 total_time 722\n",
      "episode 1299, reward 483.0, memory_length 2000, epsilon 0.5223016418473468 total_time 726\n",
      "Saving Model 1300\n",
      "episode 1309, reward 517.0, memory_length 2000, epsilon 0.519696651540937 total_time 721\n",
      "episode 1319, reward 209.0, memory_length 2000, epsilon 0.5171046536778833 total_time 725\n",
      "episode 1329, reward 535.0, memory_length 2000, epsilon 0.514525583458104 total_time 721\n",
      "episode 1339, reward 539.0, memory_length 2000, epsilon 0.5119593764047093 total_time 722\n",
      "episode 1349, reward 319.0, memory_length 2000, epsilon 0.5094059683623896 total_time 721\n",
      "episode 1359, reward 386.0, memory_length 2000, epsilon 0.5068652954958104 total_time 722\n",
      "episode 1369, reward 241.0, memory_length 2000, epsilon 0.5043372942880178 total_time 724\n",
      "episode 1379, reward 426.0, memory_length 2000, epsilon 0.50182190153885 total_time 723\n",
      "episode 1389, reward 692.0, memory_length 2000, epsilon 0.49931905436335716 total_time 722\n",
      "episode 1399, reward 438.0, memory_length 2000, epsilon 0.49682869019022974 total_time 726\n",
      "Saving Model 1400\n",
      "episode 1409, reward 283.0, memory_length 2000, epsilon 0.49435074676023355 total_time 730\n",
      "episode 1419, reward 145.0, memory_length 2000, epsilon 0.4918851621246539 total_time 727\n",
      "episode 1429, reward 695.0, memory_length 2000, epsilon 0.4894318746437464 total_time 725\n",
      "episode 1439, reward 474.0, memory_length 2000, epsilon 0.4869908229851962 total_time 726\n",
      "episode 1449, reward 247.0, memory_length 2000, epsilon 0.48456194612258474 total_time 721\n",
      "episode 1459, reward 467.0, memory_length 2000, epsilon 0.48214518333386397 total_time 731\n",
      "episode 1469, reward 64.0, memory_length 2000, epsilon 0.47974047419983834 total_time 727\n",
      "episode 1479, reward 480.0, memory_length 2000, epsilon 0.4773477586026542 total_time 723\n",
      "episode 1489, reward 292.0, memory_length 2000, epsilon 0.474966976724297 total_time 721\n",
      "episode 1499, reward 222.0, memory_length 2000, epsilon 0.47259806904509577 total_time 726\n",
      "Saving Model 1500\n",
      "episode 1509, reward 238.0, memory_length 2000, epsilon 0.4702409763422352 total_time 721\n",
      "episode 1519, reward 587.0, memory_length 2000, epsilon 0.4678956396882749 total_time 725\n",
      "episode 1529, reward 520.0, memory_length 2000, epsilon 0.4655620004496764 total_time 724\n",
      "episode 1539, reward 604.0, memory_length 2000, epsilon 0.46324000028533724 total_time 727\n",
      "episode 1549, reward 454.0, memory_length 2000, epsilon 0.4609295811451323 total_time 721\n",
      "episode 1559, reward 268.0, memory_length 2000, epsilon 0.4586306852684627 total_time 724\n",
      "episode 1569, reward 182.0, memory_length 2000, epsilon 0.4563432551828119 total_time 725\n",
      "episode 1579, reward 377.0, memory_length 2000, epsilon 0.4540672337023085 total_time 722\n",
      "episode 1589, reward 811.0, memory_length 2000, epsilon 0.45180256392629703 total_time 727\n",
      "episode 1599, reward 454.0, memory_length 2000, epsilon 0.4495491892379152 total_time 721\n",
      "Saving Model 1600\n",
      "episode 1609, reward 319.0, memory_length 2000, epsilon 0.4473070533026783 total_time 721\n",
      "episode 1619, reward 733.0, memory_length 2000, epsilon 0.4450761000670712 total_time 721\n",
      "episode 1629, reward 628.0, memory_length 2000, epsilon 0.4428562737571469 total_time 724\n",
      "episode 1639, reward 647.0, memory_length 2000, epsilon 0.44064751887713194 total_time 722\n",
      "episode 1649, reward 624.0, memory_length 2000, epsilon 0.4384497802080393 total_time 732\n",
      "episode 1659, reward 974.0, memory_length 2000, epsilon 0.4362630028062879 total_time 725\n",
      "episode 1669, reward 1077.0, memory_length 2000, epsilon 0.43408713200232857 total_time 726\n",
      "episode 1679, reward 651.0, memory_length 2000, epsilon 0.43192211339927816 total_time 723\n",
      "episode 1689, reward 497.0, memory_length 2000, epsilon 0.4297678928715586 total_time 725\n",
      "episode 1699, reward 431.0, memory_length 2000, epsilon 0.4276244165635446 total_time 722\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Model 1700\n",
      "episode 1709, reward 492.0, memory_length 2000, epsilon 0.42549163088821684 total_time 726\n",
      "episode 1719, reward 728.0, memory_length 2000, epsilon 0.4233694825258223 total_time 731\n",
      "episode 1729, reward 294.0, memory_length 2000, epsilon 0.4212579184225415 total_time 726\n",
      "episode 1739, reward 411.0, memory_length 2000, epsilon 0.4191568857891617 total_time 726\n",
      "episode 1749, reward 855.0, memory_length 2000, epsilon 0.4170663320997578 total_time 729\n",
      "episode 1759, reward 733.0, memory_length 2000, epsilon 0.4149862050903786 total_time 721\n",
      "episode 1769, reward 638.0, memory_length 2000, epsilon 0.4129164527577405 total_time 731\n",
      "episode 1779, reward 740.0, memory_length 2000, epsilon 0.41085702335792745 total_time 725\n",
      "episode 1789, reward 731.0, memory_length 2000, epsilon 0.40880786540509717 total_time 725\n",
      "episode 1799, reward 382.0, memory_length 2000, epsilon 0.4067689276701942 total_time 721\n",
      "Saving Model 1800\n",
      "episode 1809, reward 535.0, memory_length 2000, epsilon 0.40474015917966877 total_time 721\n",
      "episode 1819, reward 845.0, memory_length 2000, epsilon 0.4027215092142031 total_time 731\n",
      "episode 1829, reward 942.0, memory_length 2000, epsilon 0.4007129273074429 total_time 726\n",
      "episode 1839, reward 701.0, memory_length 2000, epsilon 0.39871436324473586 total_time 722\n",
      "episode 1849, reward 759.0, memory_length 2000, epsilon 0.3967257670618763 total_time 723\n",
      "episode 1859, reward 645.0, memory_length 2000, epsilon 0.3947470890438561 total_time 726\n",
      "episode 1869, reward 722.0, memory_length 2000, epsilon 0.3927782797236218 total_time 725\n",
      "episode 1879, reward 853.0, memory_length 2000, epsilon 0.3908192898808378 total_time 724\n",
      "episode 1889, reward 761.0, memory_length 2000, epsilon 0.388870070540656 total_time 728\n",
      "episode 1899, reward 962.0, memory_length 2000, epsilon 0.38693057297249134 total_time 722\n",
      "Saving Model 1900\n",
      "episode 1909, reward 997.0, memory_length 2000, epsilon 0.3850007486888037 total_time 724\n",
      "episode 1919, reward 552.0, memory_length 2000, epsilon 0.3830805494438854 total_time 723\n",
      "episode 1929, reward 825.0, memory_length 2000, epsilon 0.38116992723265536 total_time 726\n",
      "episode 1939, reward 1084.0, memory_length 2000, epsilon 0.3792688342894587 total_time 721\n",
      "episode 1949, reward 799.0, memory_length 2000, epsilon 0.3773772230868729 total_time 724\n",
      "episode 1959, reward 578.0, memory_length 2000, epsilon 0.37549504633451936 total_time 725\n",
      "episode 1969, reward 389.0, memory_length 2000, epsilon 0.37362225697788115 total_time 725\n",
      "episode 1979, reward 350.0, memory_length 2000, epsilon 0.37175880819712703 total_time 722\n",
      "episode 1989, reward 530.0, memory_length 2000, epsilon 0.3699046534059402 total_time 731\n",
      "episode 1999, reward 1168.0, memory_length 2000, epsilon 0.3680597462503545 total_time 724\n",
      "Saving Model 2000\n",
      "episode 2009, reward 553.0, memory_length 2000, epsilon 0.3662240406075948 total_time 721\n",
      "episode 2019, reward 485.0, memory_length 2000, epsilon 0.3643974905849244 total_time 722\n",
      "episode 2029, reward 932.0, memory_length 2000, epsilon 0.3625800505184978 total_time 728\n",
      "episode 2039, reward 526.0, memory_length 2000, epsilon 0.3607716749722184 total_time 721\n",
      "episode 2049, reward 958.0, memory_length 2000, epsilon 0.3589723187366037 total_time 721\n",
      "episode 2059, reward 854.0, memory_length 2000, epsilon 0.35718193682765376 total_time 722\n",
      "episode 2069, reward 747.0, memory_length 2000, epsilon 0.3554004844857278 total_time 729\n",
      "episode 2079, reward 483.0, memory_length 2000, epsilon 0.35362791717442443 total_time 726\n",
      "episode 2089, reward 659.0, memory_length 2000, epsilon 0.35186419057946866 total_time 725\n",
      "episode 2099, reward 427.0, memory_length 2000, epsilon 0.3501092606076035 total_time 721\n",
      "Saving Model 2100\n",
      "episode 2109, reward 900.0, memory_length 2000, epsilon 0.3483630833854885 total_time 729\n",
      "episode 2119, reward 948.0, memory_length 2000, epsilon 0.34662561525860197 total_time 723\n",
      "episode 2129, reward 610.0, memory_length 2000, epsilon 0.34489681279015044 total_time 724\n",
      "episode 2139, reward 971.0, memory_length 2000, epsilon 0.34317663275998195 total_time 722\n",
      "episode 2149, reward 1104.0, memory_length 2000, epsilon 0.3414650321635064 total_time 726\n",
      "episode 2159, reward 756.0, memory_length 2000, epsilon 0.33976196821061944 total_time 729\n",
      "episode 2169, reward 913.0, memory_length 2000, epsilon 0.3380673983246338 total_time 721\n",
      "episode 2179, reward 615.0, memory_length 2000, epsilon 0.336381280141214 total_time 723\n",
      "episode 2189, reward 872.0, memory_length 2000, epsilon 0.33470357150731744 total_time 722\n",
      "episode 2199, reward 873.0, memory_length 2000, epsilon 0.3330342304801412 total_time 729\n",
      "Saving Model 2200\n",
      "episode 2209, reward 804.0, memory_length 2000, epsilon 0.33137321532607245 total_time 723\n",
      "episode 2219, reward 574.0, memory_length 2000, epsilon 0.3297204845196459 total_time 724\n",
      "episode 2229, reward 788.0, memory_length 2000, epsilon 0.32807599674250526 total_time 728\n",
      "episode 2239, reward 463.0, memory_length 2000, epsilon 0.32643971088237056 total_time 721\n",
      "episode 2249, reward 951.0, memory_length 2000, epsilon 0.32481158603200994 total_time 726\n",
      "episode 2259, reward 366.0, memory_length 2000, epsilon 0.32319158148821747 total_time 726\n",
      "episode 2269, reward 552.0, memory_length 2000, epsilon 0.3215796567507951 total_time 723\n",
      "episode 2279, reward 553.0, memory_length 2000, epsilon 0.31997577152154044 total_time 721\n",
      "episode 2289, reward 458.0, memory_length 2000, epsilon 0.31837988570323916 total_time 722\n",
      "episode 2299, reward 751.0, memory_length 2000, epsilon 0.3167919593986629 total_time 721\n",
      "Saving Model 2300\n",
      "episode 2309, reward 790.0, memory_length 2000, epsilon 0.3152119529095711 total_time 724\n",
      "episode 2319, reward 832.0, memory_length 2000, epsilon 0.3136398267357194 total_time 721\n",
      "episode 2329, reward 713.0, memory_length 2000, epsilon 0.31207554157387146 total_time 725\n",
      "episode 2339, reward 544.0, memory_length 2000, epsilon 0.3105190583168168 total_time 721\n",
      "episode 2349, reward 885.0, memory_length 2000, epsilon 0.30897033805239293 total_time 723\n",
      "episode 2359, reward 942.0, memory_length 2000, epsilon 0.3074293420625127 total_time 726\n",
      "episode 2369, reward 1029.0, memory_length 2000, epsilon 0.3058960318221959 total_time 723\n",
      "episode 2379, reward 765.0, memory_length 2000, epsilon 0.30437036899860687 total_time 729\n",
      "episode 2389, reward 904.0, memory_length 2000, epsilon 0.3028523154500953 total_time 721\n",
      "episode 2399, reward 1000.0, memory_length 2000, epsilon 0.30134183322524366 total_time 727\n",
      "Saving Model 2400\n",
      "episode 2409, reward 580.0, memory_length 2000, epsilon 0.29983888456191743 total_time 721\n",
      "episode 2419, reward 727.0, memory_length 2000, epsilon 0.29834343188632195 total_time 724\n",
      "episode 2429, reward 463.0, memory_length 2000, epsilon 0.2968554378120623 total_time 721\n",
      "episode 2439, reward 890.0, memory_length 2000, epsilon 0.2953748651392093 total_time 722\n",
      "episode 2449, reward 830.0, memory_length 2000, epsilon 0.2939016768533689 total_time 725\n",
      "episode 2459, reward 906.0, memory_length 2000, epsilon 0.2924358361247571 total_time 726\n",
      "episode 2469, reward 762.0, memory_length 2000, epsilon 0.2909773063072796 total_time 726\n",
      "episode 2479, reward 1039.0, memory_length 2000, epsilon 0.28952605093761474 total_time 730\n",
      "episode 2489, reward 989.0, memory_length 2000, epsilon 0.28808203373430286 total_time 722\n",
      "episode 2499, reward 920.0, memory_length 2000, epsilon 0.28664521859683867 total_time 725\n",
      "Saving Model 2500\n",
      "episode 2509, reward 633.0, memory_length 2000, epsilon 0.2852155696047688 total_time 723\n",
      "episode 2519, reward 922.0, memory_length 2000, epsilon 0.28379305101679403 total_time 730\n",
      "episode 2529, reward 877.0, memory_length 2000, epsilon 0.28237762726987564 total_time 721\n",
      "episode 2539, reward 1039.0, memory_length 2000, epsilon 0.28096926297834607 total_time 721\n",
      "episode 2549, reward 949.0, memory_length 2000, epsilon 0.2795679229330249 total_time 721\n",
      "episode 2559, reward 917.0, memory_length 2000, epsilon 0.27817357210033783 total_time 722\n",
      "episode 2569, reward 979.0, memory_length 2000, epsilon 0.27678617562144153 total_time 724\n",
      "episode 2579, reward 652.0, memory_length 2000, epsilon 0.2754056988113517 total_time 721\n",
      "episode 2589, reward 862.0, memory_length 2000, epsilon 0.27403210715807624 total_time 724\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 2599, reward 1156.0, memory_length 2000, epsilon 0.2726653663217522 total_time 721\n",
      "Saving Model 2600\n",
      "episode 2609, reward 1000.0, memory_length 2000, epsilon 0.27130544213378754 total_time 727\n",
      "episode 2619, reward 820.0, memory_length 2000, epsilon 0.2699523005960067 total_time 727\n",
      "episode 2629, reward 759.0, memory_length 2000, epsilon 0.26860590787980093 total_time 723\n",
      "episode 2639, reward 853.0, memory_length 2000, epsilon 0.26726623032528185 total_time 724\n",
      "episode 2649, reward 702.0, memory_length 2000, epsilon 0.2659332344404412 total_time 729\n",
      "episode 2659, reward 1110.0, memory_length 2000, epsilon 0.2646068869003122 total_time 723\n",
      "episode 2669, reward 668.0, memory_length 2000, epsilon 0.2632871545461373 total_time 725\n",
      "episode 2679, reward 931.0, memory_length 2000, epsilon 0.261974004384539 total_time 721\n",
      "episode 2689, reward 977.0, memory_length 2000, epsilon 0.26066740358669477 total_time 728\n",
      "episode 2699, reward 1046.0, memory_length 2000, epsilon 0.25936731948751673 total_time 725\n",
      "Saving Model 2700\n",
      "episode 2709, reward 678.0, memory_length 2000, epsilon 0.2580737195848345 total_time 723\n",
      "episode 2719, reward 1128.0, memory_length 2000, epsilon 0.25678657153858325 total_time 723\n",
      "episode 2729, reward 993.0, memory_length 2000, epsilon 0.2555058431699948 total_time 723\n",
      "episode 2739, reward 1221.0, memory_length 2000, epsilon 0.25423150246079323 total_time 726\n",
      "episode 2749, reward 969.0, memory_length 2000, epsilon 0.2529635175523944 total_time 726\n",
      "episode 2759, reward 1394.0, memory_length 2000, epsilon 0.25170185674510953 total_time 722\n",
      "episode 2769, reward 992.0, memory_length 2000, epsilon 0.25044648849735274 total_time 725\n",
      "episode 2779, reward 1008.0, memory_length 2000, epsilon 0.2491973814248526 total_time 729\n",
      "episode 2789, reward 895.0, memory_length 2000, epsilon 0.24795450429986704 total_time 721\n",
      "episode 2799, reward 735.0, memory_length 2000, epsilon 0.24671782605040335 total_time 726\n",
      "Saving Model 2800\n",
      "episode 2809, reward 804.0, memory_length 2000, epsilon 0.24548731575944074 total_time 723\n",
      "episode 2819, reward 781.0, memory_length 2000, epsilon 0.244262942664158 total_time 724\n",
      "episode 2829, reward 1138.0, memory_length 2000, epsilon 0.24304467615516384 total_time 721\n",
      "episode 2839, reward 1564.0, memory_length 2000, epsilon 0.24183248577573216 total_time 724\n",
      "episode 2849, reward 904.0, memory_length 2000, epsilon 0.24062634122104032 total_time 721\n",
      "episode 2859, reward 1170.0, memory_length 2000, epsilon 0.2394262123374117 total_time 729\n",
      "episode 2869, reward 861.0, memory_length 2000, epsilon 0.23823206912156156 total_time 726\n",
      "episode 2879, reward 771.0, memory_length 2000, epsilon 0.23704388171984747 total_time 726\n",
      "episode 2889, reward 936.0, memory_length 2000, epsilon 0.23586162042752232 total_time 729\n",
      "episode 2899, reward 1076.0, memory_length 2000, epsilon 0.23468525568799242 total_time 728\n",
      "Saving Model 2900\n",
      "episode 2909, reward 581.0, memory_length 2000, epsilon 0.23351475809207786 total_time 728\n",
      "episode 2919, reward 1045.0, memory_length 2000, epsilon 0.2323500983772779 total_time 727\n",
      "episode 2929, reward 781.0, memory_length 2000, epsilon 0.2311912474270389 total_time 724\n",
      "episode 2939, reward 674.0, memory_length 2000, epsilon 0.23003817627002682 total_time 722\n",
      "episode 2949, reward 307.0, memory_length 2000, epsilon 0.22889085607940265 total_time 727\n",
      "episode 2959, reward 619.0, memory_length 2000, epsilon 0.22774925817210187 total_time 724\n",
      "episode 2969, reward 830.0, memory_length 2000, epsilon 0.22661335400811736 total_time 725\n",
      "episode 2979, reward 758.0, memory_length 2000, epsilon 0.2254831151897858 total_time 725\n",
      "episode 2989, reward 1050.0, memory_length 2000, epsilon 0.22435851346107796 total_time 726\n",
      "episode 2999, reward 1038.0, memory_length 2000, epsilon 0.22323952070689196 total_time 723\n",
      "Saving Model 3000\n",
      "episode 3009, reward 958.0, memory_length 2000, epsilon 0.22212610895235071 total_time 730\n",
      "episode 3019, reward 1058.0, memory_length 2000, epsilon 0.22101825036210232 total_time 728\n",
      "episode 3029, reward 715.0, memory_length 2000, epsilon 0.21991591723962442 total_time 721\n",
      "episode 3039, reward 382.0, memory_length 2000, epsilon 0.21881908202653141 total_time 730\n",
      "episode 3049, reward 1138.0, memory_length 2000, epsilon 0.21772771730188595 total_time 730\n",
      "episode 3059, reward 1205.0, memory_length 2000, epsilon 0.216641795781513 total_time 722\n",
      "episode 3069, reward 1151.0, memory_length 2000, epsilon 0.21556129031731802 total_time 722\n",
      "episode 3079, reward 699.0, memory_length 2000, epsilon 0.21448617389660815 total_time 726\n",
      "episode 3089, reward 1035.0, memory_length 2000, epsilon 0.21341641964141686 total_time 729\n",
      "episode 3099, reward 1057.0, memory_length 2000, epsilon 0.21235200080783204 total_time 721\n",
      "Saving Model 3100\n",
      "episode 3109, reward 1043.0, memory_length 2000, epsilon 0.21129289078532745 total_time 731\n",
      "episode 3119, reward 1117.0, memory_length 2000, epsilon 0.2102390630960973 total_time 727\n",
      "episode 3129, reward 950.0, memory_length 2000, epsilon 0.20919049139439458 total_time 728\n",
      "episode 3139, reward 802.0, memory_length 2000, epsilon 0.20814714946587198 total_time 727\n",
      "episode 3149, reward 1119.0, memory_length 2000, epsilon 0.2071090112269271 total_time 723\n",
      "episode 3159, reward 1199.0, memory_length 2000, epsilon 0.2060760507240498 total_time 725\n",
      "episode 3169, reward 1209.0, memory_length 2000, epsilon 0.20504824213317377 total_time 723\n",
      "episode 3179, reward 778.0, memory_length 2000, epsilon 0.2040255597590306 total_time 721\n",
      "episode 3189, reward 1244.0, memory_length 2000, epsilon 0.20300797803450785 total_time 725\n",
      "episode 3199, reward 858.0, memory_length 2000, epsilon 0.2019954715200092 total_time 723\n",
      "Saving Model 3200\n",
      "episode 3209, reward 638.0, memory_length 2000, epsilon 0.20098801490281926 total_time 722\n",
      "episode 3219, reward 832.0, memory_length 2000, epsilon 0.19998558299646998 total_time 721\n",
      "episode 3229, reward 1148.0, memory_length 2000, epsilon 0.1989881507401115 total_time 728\n",
      "episode 3239, reward 980.0, memory_length 2000, epsilon 0.19799569319788554 total_time 731\n",
      "episode 3249, reward 653.0, memory_length 2000, epsilon 0.1970081855583018 total_time 728\n",
      "episode 3259, reward 1220.0, memory_length 2000, epsilon 0.19602560313361786 total_time 728\n",
      "episode 3269, reward 837.0, memory_length 2000, epsilon 0.19504792135922194 total_time 729\n",
      "episode 3279, reward 1169.0, memory_length 2000, epsilon 0.19407511579301878 total_time 722\n",
      "episode 3289, reward 836.0, memory_length 2000, epsilon 0.1931071621148185 total_time 722\n",
      "episode 3299, reward 868.0, memory_length 2000, epsilon 0.19214403612572878 total_time 721\n",
      "Saving Model 3300\n",
      "episode 3309, reward 689.0, memory_length 2000, epsilon 0.19118571374754967 total_time 728\n",
      "episode 3319, reward 1214.0, memory_length 2000, epsilon 0.1902321710221719 total_time 722\n",
      "episode 3329, reward 899.0, memory_length 2000, epsilon 0.1892833841109776 total_time 731\n",
      "episode 3339, reward 872.0, memory_length 2000, epsilon 0.1883393292942446 total_time 722\n",
      "episode 3349, reward 863.0, memory_length 2000, epsilon 0.18739998297055327 total_time 722\n",
      "episode 3359, reward 672.0, memory_length 2000, epsilon 0.18646532165619667 total_time 726\n",
      "episode 3369, reward 1126.0, memory_length 2000, epsilon 0.1855353219845932 total_time 727\n",
      "episode 3379, reward 850.0, memory_length 2000, epsilon 0.18460996070570268 total_time 721\n",
      "episode 3389, reward 854.0, memory_length 2000, epsilon 0.18368921468544486 total_time 722\n",
      "episode 3399, reward 653.0, memory_length 2000, epsilon 0.18277306090512138 total_time 728\n",
      "Saving Model 3400\n",
      "episode 3409, reward 867.0, memory_length 2000, epsilon 0.18186147646083992 total_time 723\n",
      "episode 3419, reward 737.0, memory_length 2000, epsilon 0.18095443856294197 total_time 722\n",
      "episode 3429, reward 930.0, memory_length 2000, epsilon 0.1800519245354328 total_time 723\n",
      "episode 3439, reward 943.0, memory_length 2000, epsilon 0.17915391181541473 total_time 733\n",
      "episode 3449, reward 663.0, memory_length 2000, epsilon 0.17826037795252297 total_time 726\n",
      "episode 3459, reward 1096.0, memory_length 2000, epsilon 0.17737130060836448 total_time 733\n",
      "episode 3469, reward 1015.0, memory_length 2000, epsilon 0.17648665755595927 total_time 724\n",
      "episode 3479, reward 885.0, memory_length 2000, epsilon 0.17560642667918497 total_time 723\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 3489, reward 700.0, memory_length 2000, epsilon 0.17473058597222385 total_time 724\n",
      "episode 3499, reward 1214.0, memory_length 2000, epsilon 0.17385911353901257 total_time 722\n",
      "Saving Model 3500\n",
      "episode 3509, reward 844.0, memory_length 2000, epsilon 0.17299198759269493 total_time 724\n",
      "episode 3519, reward 865.0, memory_length 2000, epsilon 0.1721291864550771 total_time 727\n",
      "episode 3529, reward 881.0, memory_length 2000, epsilon 0.17127068855608577 total_time 722\n",
      "episode 3539, reward 798.0, memory_length 2000, epsilon 0.17041647243322863 total_time 726\n",
      "episode 3549, reward 858.0, memory_length 2000, epsilon 0.16956651673105824 total_time 723\n",
      "episode 3559, reward 799.0, memory_length 2000, epsilon 0.16872080020063768 total_time 724\n",
      "episode 3569, reward 637.0, memory_length 2000, epsilon 0.16787930169900972 total_time 724\n",
      "episode 3579, reward 790.0, memory_length 2000, epsilon 0.16704200018866794 total_time 724\n",
      "episode 3589, reward 814.0, memory_length 2000, epsilon 0.166208874737031 total_time 721\n",
      "episode 3599, reward 1027.0, memory_length 2000, epsilon 0.1653799045159192 total_time 727\n",
      "Saving Model 3600\n",
      "episode 3609, reward 916.0, memory_length 2000, epsilon 0.16455506880103385 total_time 724\n",
      "episode 3619, reward 593.0, memory_length 2000, epsilon 0.1637343469714391 total_time 722\n",
      "episode 3629, reward 1219.0, memory_length 2000, epsilon 0.1629177185090465 total_time 721\n",
      "episode 3639, reward 931.0, memory_length 2000, epsilon 0.16210516299810185 total_time 730\n",
      "episode 3649, reward 903.0, memory_length 2000, epsilon 0.16129666012467522 total_time 723\n",
      "episode 3659, reward 1182.0, memory_length 2000, epsilon 0.16049218967615253 total_time 723\n",
      "episode 3669, reward 1378.0, memory_length 2000, epsilon 0.15969173154073077 total_time 727\n",
      "episode 3679, reward 1093.0, memory_length 2000, epsilon 0.15889526570691476 total_time 721\n",
      "episode 3689, reward 1032.0, memory_length 2000, epsilon 0.15810277226301725 total_time 726\n",
      "episode 3699, reward 974.0, memory_length 2000, epsilon 0.15731423139666081 total_time 734\n",
      "Saving Model 3700\n",
      "episode 3709, reward 1120.0, memory_length 2000, epsilon 0.15652962339428284 total_time 721\n",
      "episode 3719, reward 625.0, memory_length 2000, epsilon 0.15574892864064224 total_time 721\n",
      "episode 3729, reward 1037.0, memory_length 2000, epsilon 0.1549721276183296 total_time 725\n",
      "episode 3739, reward 839.0, memory_length 2000, epsilon 0.1541992009072789 total_time 725\n",
      "episode 3749, reward 946.0, memory_length 2000, epsilon 0.1534301291842821 total_time 727\n",
      "episode 3759, reward 1090.0, memory_length 2000, epsilon 0.15266489322250604 total_time 727\n",
      "episode 3769, reward 1201.0, memory_length 2000, epsilon 0.15190347389101183 total_time 730\n",
      "episode 3779, reward 715.0, memory_length 2000, epsilon 0.1511458521542766 total_time 721\n",
      "episode 3789, reward 881.0, memory_length 2000, epsilon 0.15039200907171735 total_time 722\n",
      "episode 3799, reward 989.0, memory_length 2000, epsilon 0.14964192579721786 total_time 722\n",
      "Saving Model 3800\n",
      "episode 3809, reward 1059.0, memory_length 2000, epsilon 0.14889558357865715 total_time 726\n",
      "episode 3819, reward 985.0, memory_length 2000, epsilon 0.1481529637574409 total_time 721\n",
      "episode 3829, reward 964.0, memory_length 2000, epsilon 0.14741404776803485 total_time 727\n",
      "episode 3839, reward 1120.0, memory_length 2000, epsilon 0.1466788171375009 total_time 721\n",
      "episode 3849, reward 961.0, memory_length 2000, epsilon 0.14594725348503484 total_time 724\n",
      "episode 3859, reward 1170.0, memory_length 2000, epsilon 0.14521933852150737 total_time 729\n",
      "episode 3869, reward 1146.0, memory_length 2000, epsilon 0.14449505404900642 total_time 723\n",
      "episode 3879, reward 910.0, memory_length 2000, epsilon 0.1437743819603825 total_time 727\n",
      "episode 3889, reward 830.0, memory_length 2000, epsilon 0.14305730423879587 total_time 725\n",
      "episode 3899, reward 980.0, memory_length 2000, epsilon 0.1423438029572661 total_time 722\n",
      "Saving Model 3900\n",
      "episode 3909, reward 971.0, memory_length 2000, epsilon 0.141633860278224 total_time 722\n",
      "episode 3919, reward 1036.0, memory_length 2000, epsilon 0.14092745845306562 total_time 727\n",
      "episode 3929, reward 951.0, memory_length 2000, epsilon 0.14022457982170855 total_time 726\n",
      "episode 3939, reward 730.0, memory_length 2000, epsilon 0.13952520681215042 total_time 727\n",
      "episode 3949, reward 832.0, memory_length 2000, epsilon 0.1388293219400295 total_time 721\n",
      "episode 3959, reward 820.0, memory_length 2000, epsilon 0.1381369078081878 total_time 727\n",
      "episode 3969, reward 1106.0, memory_length 2000, epsilon 0.13744794710623595 total_time 731\n",
      "episode 3979, reward 1146.0, memory_length 2000, epsilon 0.13676242261012048 total_time 723\n",
      "episode 3989, reward 1030.0, memory_length 2000, epsilon 0.13608031718169336 total_time 721\n",
      "episode 3999, reward 935.0, memory_length 2000, epsilon 0.13540161376828327 total_time 722\n",
      "Saving Model 4000\n",
      "episode 4009, reward 882.0, memory_length 2000, epsilon 0.13472629540226955 total_time 729\n",
      "episode 4019, reward 938.0, memory_length 2000, epsilon 0.1340543452006579 total_time 725\n",
      "episode 4029, reward 703.0, memory_length 2000, epsilon 0.1333857463646583 total_time 727\n",
      "episode 4039, reward 780.0, memory_length 2000, epsilon 0.132720482179265 total_time 726\n",
      "episode 4049, reward 1030.0, memory_length 2000, epsilon 0.1320585360128386 total_time 721\n",
      "episode 4059, reward 1157.0, memory_length 2000, epsilon 0.1313998913166907 total_time 728\n",
      "episode 4069, reward 1443.0, memory_length 2000, epsilon 0.1307445316246694 total_time 723\n",
      "episode 4079, reward 1028.0, memory_length 2000, epsilon 0.13009244055274838 total_time 725\n",
      "episode 4089, reward 1087.0, memory_length 2000, epsilon 0.12944360179861678 total_time 724\n",
      "episode 4099, reward 1163.0, memory_length 2000, epsilon 0.12879799914127205 total_time 725\n",
      "Saving Model 4100\n",
      "episode 4109, reward 939.0, memory_length 2000, epsilon 0.12815561644061407 total_time 723\n",
      "episode 4119, reward 1274.0, memory_length 2000, epsilon 0.1275164376370419 total_time 728\n",
      "episode 4129, reward 1261.0, memory_length 2000, epsilon 0.1268804467510521 total_time 727\n",
      "episode 4139, reward 1403.0, memory_length 2000, epsilon 0.12624762788283944 total_time 722\n",
      "episode 4149, reward 1105.0, memory_length 2000, epsilon 0.1256179652118993 total_time 724\n",
      "episode 4159, reward 1030.0, memory_length 2000, epsilon 0.12499144299663205 total_time 721\n",
      "episode 4169, reward 740.0, memory_length 2000, epsilon 0.12436804557394966 total_time 725\n",
      "episode 4179, reward 778.0, memory_length 2000, epsilon 0.12374775735888416 total_time 721\n",
      "episode 4189, reward 1134.0, memory_length 2000, epsilon 0.12313056284419784 total_time 729\n",
      "episode 4199, reward 1123.0, memory_length 2000, epsilon 0.12251644659999568 total_time 724\n",
      "Saving Model 4200\n",
      "episode 4209, reward 1329.0, memory_length 2000, epsilon 0.12190539327333952 total_time 735\n",
      "episode 4219, reward 887.0, memory_length 2000, epsilon 0.12129738758786451 total_time 728\n",
      "episode 4229, reward 848.0, memory_length 2000, epsilon 0.12069241434339678 total_time 725\n",
      "episode 4239, reward 590.0, memory_length 2000, epsilon 0.12009045841557368 total_time 728\n",
      "episode 4249, reward 989.0, memory_length 2000, epsilon 0.1194915047554657 total_time 722\n",
      "episode 4259, reward 1069.0, memory_length 2000, epsilon 0.11889553838920008 total_time 724\n",
      "episode 4269, reward 616.0, memory_length 2000, epsilon 0.11830254441758672 total_time 721\n",
      "episode 4279, reward 926.0, memory_length 2000, epsilon 0.1177125080157454 total_time 722\n",
      "episode 4289, reward 1123.0, memory_length 2000, epsilon 0.11712541443273533 total_time 724\n",
      "episode 4299, reward 1193.0, memory_length 2000, epsilon 0.11654124899118631 total_time 728\n",
      "Saving Model 4300\n",
      "episode 4309, reward 555.0, memory_length 2000, epsilon 0.115959997086932 total_time 726\n",
      "episode 4319, reward 1083.0, memory_length 2000, epsilon 0.11538164418864444 total_time 723\n",
      "episode 4329, reward 1415.0, memory_length 2000, epsilon 0.11480617583747106 total_time 725\n",
      "episode 4339, reward 944.0, memory_length 2000, epsilon 0.11423357764667307 total_time 722\n",
      "episode 4349, reward 1083.0, memory_length 2000, epsilon 0.11366383530126595 total_time 723\n",
      "episode 4359, reward 1037.0, memory_length 2000, epsilon 0.11309693455766137 total_time 725\n",
      "episode 4369, reward 1223.0, memory_length 2000, epsilon 0.1125328612433112 total_time 722\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 4379, reward 1028.0, memory_length 2000, epsilon 0.11197160125635315 total_time 725\n",
      "episode 4389, reward 1043.0, memory_length 2000, epsilon 0.11141314056525843 total_time 722\n",
      "episode 4399, reward 1250.0, memory_length 2000, epsilon 0.11085746520848058 total_time 722\n",
      "Saving Model 4400\n",
      "episode 4409, reward 1057.0, memory_length 2000, epsilon 0.11030456129410682 total_time 721\n",
      "episode 4419, reward 1432.0, memory_length 2000, epsilon 0.10975441499951036 total_time 727\n",
      "episode 4429, reward 1263.0, memory_length 2000, epsilon 0.10920701257100535 total_time 723\n",
      "episode 4439, reward 1214.0, memory_length 2000, epsilon 0.10866234032350246 total_time 722\n",
      "episode 4449, reward 1074.0, memory_length 2000, epsilon 0.10812038464016717 total_time 723\n",
      "episode 4459, reward 962.0, memory_length 2000, epsilon 0.10758113197207911 total_time 722\n",
      "episode 4469, reward 1203.0, memory_length 2000, epsilon 0.10704456883789358 total_time 726\n",
      "episode 4479, reward 1356.0, memory_length 2000, epsilon 0.10651068182350425 total_time 726\n",
      "episode 4489, reward 1129.0, memory_length 2000, epsilon 0.10597945758170793 total_time 730\n",
      "episode 4499, reward 1413.0, memory_length 2000, epsilon 0.10545088283187094 total_time 729\n",
      "Saving Model 4500\n",
      "episode 4509, reward 1211.0, memory_length 2000, epsilon 0.10492494435959693 total_time 728\n",
      "episode 4519, reward 1158.0, memory_length 2000, epsilon 0.1044016290163968 total_time 726\n",
      "episode 4529, reward 1061.0, memory_length 2000, epsilon 0.10388092371935967 total_time 722\n",
      "episode 4539, reward 1237.0, memory_length 2000, epsilon 0.103362815450826 total_time 721\n",
      "episode 4549, reward 955.0, memory_length 2000, epsilon 0.10284729125806202 total_time 727\n",
      "episode 4559, reward 863.0, memory_length 2000, epsilon 0.1023343382529362 total_time 731\n",
      "episode 4569, reward 1010.0, memory_length 2000, epsilon 0.10182394361159659 total_time 725\n",
      "episode 4579, reward 1300.0, memory_length 2000, epsilon 0.10131609457415063 total_time 730\n",
      "episode 4589, reward 911.0, memory_length 2000, epsilon 0.10081077844434586 total_time 734\n",
      "episode 4599, reward 1024.0, memory_length 2000, epsilon 0.10030798258925279 total_time 724\n",
      "Saving Model 4600\n",
      "episode 4609, reward 862.0, memory_length 2000, epsilon 0.09980769443894884 total_time 724\n",
      "episode 4619, reward 1087.0, memory_length 2000, epsilon 0.0993099014862042 total_time 724\n",
      "episode 4629, reward 1118.0, memory_length 2000, epsilon 0.09881459128616905 total_time 725\n",
      "episode 4639, reward 794.0, memory_length 2000, epsilon 0.09832175145606269 total_time 725\n",
      "episode 4649, reward 1257.0, memory_length 2000, epsilon 0.09783136967486368 total_time 726\n",
      "episode 4659, reward 1217.0, memory_length 2000, epsilon 0.09734343368300191 total_time 725\n",
      "episode 4669, reward 1176.0, memory_length 2000, epsilon 0.09685793128205217 total_time 726\n",
      "episode 4679, reward 1227.0, memory_length 2000, epsilon 0.09637485033442919 total_time 723\n",
      "episode 4689, reward 1310.0, memory_length 2000, epsilon 0.0958941787630841 total_time 728\n",
      "episode 4699, reward 1205.0, memory_length 2000, epsilon 0.0954159045512026 total_time 722\n",
      "Saving Model 4700\n",
      "episode 4709, reward 1002.0, memory_length 2000, epsilon 0.0949400157419044 total_time 723\n",
      "episode 4719, reward 1545.0, memory_length 2000, epsilon 0.09446650043794459 total_time 726\n",
      "episode 4729, reward 1165.0, memory_length 2000, epsilon 0.09399534680141587 total_time 721\n",
      "episode 4739, reward 1233.0, memory_length 2000, epsilon 0.09352654305345277 total_time 729\n",
      "episode 4749, reward 1033.0, memory_length 2000, epsilon 0.0930600774739372 total_time 724\n",
      "episode 4759, reward 1019.0, memory_length 2000, epsilon 0.09259593840120531 total_time 725\n",
      "episode 4769, reward 1381.0, memory_length 2000, epsilon 0.0921341142317562 total_time 721\n",
      "episode 4779, reward 1293.0, memory_length 2000, epsilon 0.09167459341996154 total_time 726\n",
      "episode 4789, reward 925.0, memory_length 2000, epsilon 0.0912173644777771 total_time 724\n",
      "episode 4799, reward 840.0, memory_length 2000, epsilon 0.09076241597445547 total_time 723\n",
      "Saving Model 4800\n",
      "episode 4809, reward 1416.0, memory_length 2000, epsilon 0.09030973653626047 total_time 723\n",
      "episode 4819, reward 813.0, memory_length 2000, epsilon 0.0898593148461825 total_time 723\n",
      "episode 4829, reward 1078.0, memory_length 2000, epsilon 0.08941113964365587 total_time 724\n",
      "episode 4839, reward 1159.0, memory_length 2000, epsilon 0.08896519972427712 total_time 724\n",
      "episode 4849, reward 1024.0, memory_length 2000, epsilon 0.08852148393952511 total_time 724\n",
      "episode 4859, reward 1060.0, memory_length 2000, epsilon 0.08807998119648211 total_time 724\n",
      "episode 4869, reward 1290.0, memory_length 2000, epsilon 0.0876406804575565 total_time 723\n",
      "episode 4879, reward 1210.0, memory_length 2000, epsilon 0.08720357074020693 total_time 721\n",
      "episode 4889, reward 1101.0, memory_length 2000, epsilon 0.08676864111666777 total_time 732\n",
      "episode 4899, reward 1192.0, memory_length 2000, epsilon 0.0863358807136757 total_time 730\n",
      "Saving Model 4900\n",
      "episode 4909, reward 1399.0, memory_length 2000, epsilon 0.08590527871219816 total_time 721\n",
      "episode 4919, reward 1699.0, memory_length 2000, epsilon 0.08547682434716262 total_time 733\n",
      "episode 4929, reward 1012.0, memory_length 2000, epsilon 0.08505050690718771 total_time 721\n",
      "episode 4939, reward 1316.0, memory_length 2000, epsilon 0.08462631573431521 total_time 725\n",
      "episode 4949, reward 1240.0, memory_length 2000, epsilon 0.08420424022374369 total_time 724\n",
      "episode 4959, reward 739.0, memory_length 2000, epsilon 0.08378426982356336 total_time 727\n",
      "episode 4969, reward 1174.0, memory_length 2000, epsilon 0.08336639403449243 total_time 721\n",
      "episode 4979, reward 1194.0, memory_length 2000, epsilon 0.08295060240961435 total_time 726\n",
      "episode 4989, reward 988.0, memory_length 2000, epsilon 0.08253688455411688 total_time 724\n",
      "episode 4999, reward 1300.0, memory_length 2000, epsilon 0.08212523012503205 total_time 721\n",
      "Saving Model 5000\n",
      "episode 5009, reward 868.0, memory_length 2000, epsilon 0.08171562883097767 total_time 721\n",
      "episode 5019, reward 1102.0, memory_length 2000, epsilon 0.08130807043190014 total_time 721\n",
      "episode 5029, reward 1128.0, memory_length 2000, epsilon 0.0809025447388182 total_time 723\n",
      "episode 5039, reward 1372.0, memory_length 2000, epsilon 0.08049904161356838 total_time 721\n",
      "episode 5049, reward 1106.0, memory_length 2000, epsilon 0.08009755096855156 total_time 722\n",
      "episode 5059, reward 1300.0, memory_length 2000, epsilon 0.07969806276648073 total_time 730\n",
      "episode 5069, reward 1219.0, memory_length 2000, epsilon 0.07930056702013001 total_time 721\n",
      "episode 5079, reward 1480.0, memory_length 2000, epsilon 0.07890505379208503 total_time 721\n",
      "episode 5089, reward 1144.0, memory_length 2000, epsilon 0.07851151319449445 total_time 727\n",
      "episode 5099, reward 1253.0, memory_length 2000, epsilon 0.07811993538882292 total_time 725\n",
      "Saving Model 5100\n",
      "episode 5109, reward 1455.0, memory_length 2000, epsilon 0.07773031058560487 total_time 726\n",
      "episode 5119, reward 1425.0, memory_length 2000, epsilon 0.07734262904419989 total_time 723\n",
      "episode 5129, reward 1034.0, memory_length 2000, epsilon 0.07695688107254926 total_time 722\n",
      "episode 5139, reward 1118.0, memory_length 2000, epsilon 0.07657305702693368 total_time 725\n",
      "episode 5149, reward 1466.0, memory_length 2000, epsilon 0.07619114731173192 total_time 722\n",
      "episode 5159, reward 1344.0, memory_length 2000, epsilon 0.07581114237918127 total_time 723\n",
      "episode 5169, reward 792.0, memory_length 2000, epsilon 0.07543303272913854 total_time 729\n",
      "episode 5179, reward 835.0, memory_length 2000, epsilon 0.07505680890884289 total_time 724\n",
      "episode 5189, reward 1151.0, memory_length 2000, epsilon 0.07468246151267918 total_time 722\n",
      "episode 5199, reward 961.0, memory_length 2000, epsilon 0.074309981181943 total_time 733\n",
      "Saving Model 5200\n",
      "episode 5209, reward 1707.0, memory_length 2000, epsilon 0.07393935860460665 total_time 726\n",
      "episode 5219, reward 1118.0, memory_length 2000, epsilon 0.07357058451508645 total_time 725\n",
      "episode 5229, reward 1542.0, memory_length 2000, epsilon 0.07320364969401096 total_time 723\n",
      "episode 5239, reward 984.0, memory_length 2000, epsilon 0.07283854496799048 total_time 732\n",
      "episode 5249, reward 921.0, memory_length 2000, epsilon 0.0724752612093879 total_time 723\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 5259, reward 1252.0, memory_length 2000, epsilon 0.07211378933609025 total_time 727\n",
      "episode 5269, reward 812.0, memory_length 2000, epsilon 0.07175412031128199 total_time 725\n",
      "episode 5279, reward 922.0, memory_length 2000, epsilon 0.0713962451432187 total_time 721\n",
      "episode 5289, reward -332.0, memory_length 2000, epsilon 0.07104015488500255 total_time 727\n",
      "episode 5299, reward 490.0, memory_length 2000, epsilon 0.07068584063435851 total_time 721\n",
      "Saving Model 5300\n",
      "episode 5309, reward 674.0, memory_length 2000, epsilon 0.07033329353341192 total_time 722\n",
      "episode 5319, reward 519.0, memory_length 2000, epsilon 0.06998250476846683 total_time 726\n",
      "episode 5329, reward 953.0, memory_length 2000, epsilon 0.0696334655697859 total_time 722\n",
      "episode 5339, reward 822.0, memory_length 2000, epsilon 0.06928616721137094 total_time 723\n",
      "episode 5349, reward 1158.0, memory_length 2000, epsilon 0.06894060101074495 total_time 726\n",
      "episode 5359, reward 1441.0, memory_length 2000, epsilon 0.06859675832873488 total_time 727\n",
      "episode 5369, reward 1262.0, memory_length 2000, epsilon 0.06825463056925578 total_time 725\n",
      "episode 5379, reward 1073.0, memory_length 2000, epsilon 0.06791420917909581 total_time 725\n",
      "episode 5389, reward 1239.0, memory_length 2000, epsilon 0.06757548564770255 total_time 726\n",
      "episode 5399, reward 1132.0, memory_length 2000, epsilon 0.06723845150697004 total_time 724\n",
      "Saving Model 5400\n",
      "episode 5409, reward 1438.0, memory_length 2000, epsilon 0.06690309833102723 total_time 724\n",
      "episode 5419, reward 836.0, memory_length 2000, epsilon 0.06656941773602718 total_time 731\n",
      "episode 5429, reward 1202.0, memory_length 2000, epsilon 0.06623740137993772 total_time 728\n",
      "episode 5439, reward 790.0, memory_length 2000, epsilon 0.06590704096233263 total_time 724\n",
      "episode 5449, reward 1145.0, memory_length 2000, epsilon 0.06557832822418427 total_time 725\n",
      "episode 5459, reward 1519.0, memory_length 2000, epsilon 0.06525125494765702 total_time 724\n",
      "episode 5469, reward 1087.0, memory_length 2000, epsilon 0.064925812955902 total_time 724\n",
      "episode 5479, reward 1465.0, memory_length 2000, epsilon 0.06460199411285243 total_time 724\n",
      "episode 5489, reward 1424.0, memory_length 2000, epsilon 0.06427979032302036 total_time 725\n",
      "episode 5499, reward 1300.0, memory_length 2000, epsilon 0.06395919353129426 total_time 721\n",
      "Saving Model 5500\n",
      "episode 5509, reward 962.0, memory_length 2000, epsilon 0.06364019572273769 total_time 722\n",
      "episode 5519, reward 743.0, memory_length 2000, epsilon 0.06332278892238877 total_time 728\n",
      "episode 5529, reward 1120.0, memory_length 2000, epsilon 0.06300696519506098 total_time 721\n",
      "episode 5539, reward 1334.0, memory_length 2000, epsilon 0.06269271664514467 total_time 725\n",
      "episode 5549, reward 1111.0, memory_length 2000, epsilon 0.06238003541640971 total_time 721\n",
      "episode 5559, reward 1012.0, memory_length 2000, epsilon 0.06206891369180917 total_time 730\n",
      "episode 5569, reward 1065.0, memory_length 2000, epsilon 0.061759343693283675 total_time 723\n",
      "episode 5579, reward 1477.0, memory_length 2000, epsilon 0.06145131768156714 total_time 727\n",
      "episode 5589, reward 1393.0, memory_length 2000, epsilon 0.061144827955993214 total_time 724\n",
      "episode 5599, reward 1202.0, memory_length 2000, epsilon 0.06083986685430284 total_time 728\n",
      "Saving Model 5600\n",
      "episode 5609, reward 1502.0, memory_length 2000, epsilon 0.06053642675245258 total_time 722\n",
      "episode 5619, reward 1199.0, memory_length 2000, epsilon 0.06023450006442407 total_time 725\n",
      "episode 5629, reward 1335.0, memory_length 2000, epsilon 0.059934079242034345 total_time 723\n",
      "episode 5639, reward 685.0, memory_length 2000, epsilon 0.05963515677474728 total_time 727\n",
      "episode 5649, reward 1009.0, memory_length 2000, epsilon 0.05933772518948558 total_time 727\n",
      "episode 5659, reward 1101.0, memory_length 2000, epsilon 0.05904177705044413 total_time 723\n",
      "episode 5669, reward 809.0, memory_length 2000, epsilon 0.05874730495890401 total_time 722\n",
      "episode 5679, reward 1191.0, memory_length 2000, epsilon 0.05845430155304764 total_time 723\n",
      "episode 5689, reward 905.0, memory_length 2000, epsilon 0.05816275950777461 total_time 728\n",
      "episode 5699, reward 1273.0, memory_length 2000, epsilon 0.05787267153451857 total_time 721\n",
      "Saving Model 5700\n",
      "episode 5709, reward 1281.0, memory_length 2000, epsilon 0.05758403038106508 total_time 723\n",
      "episode 5719, reward 1133.0, memory_length 2000, epsilon 0.05729682883137031 total_time 722\n",
      "episode 5729, reward 1108.0, memory_length 2000, epsilon 0.057011059705380535 total_time 727\n",
      "episode 5739, reward 1165.0, memory_length 2000, epsilon 0.05672671585885272 total_time 721\n",
      "episode 5749, reward 1263.0, memory_length 2000, epsilon 0.05644379018317588 total_time 723\n",
      "episode 5759, reward 1245.0, memory_length 2000, epsilon 0.056162275605193414 total_time 723\n",
      "episode 5769, reward 1389.0, memory_length 2000, epsilon 0.05588216508702621 total_time 723\n",
      "episode 5779, reward 1089.0, memory_length 2000, epsilon 0.055603451625896715 total_time 729\n",
      "episode 5789, reward 1208.0, memory_length 2000, epsilon 0.05532612825395388 total_time 725\n",
      "episode 5799, reward 1043.0, memory_length 2000, epsilon 0.055050188038098934 total_time 722\n",
      "Saving Model 5800\n",
      "episode 5809, reward 1363.0, memory_length 2000, epsilon 0.05477562407981217 total_time 721\n",
      "episode 5819, reward 1238.0, memory_length 2000, epsilon 0.0545024295149803 total_time 728\n",
      "episode 5829, reward 1642.0, memory_length 2000, epsilon 0.054230597513724985 total_time 721\n",
      "episode 5839, reward 899.0, memory_length 2000, epsilon 0.05396012128023198 total_time 722\n",
      "episode 5849, reward 1186.0, memory_length 2000, epsilon 0.05369099405258145 total_time 724\n",
      "episode 5859, reward 1158.0, memory_length 2000, epsilon 0.05342320910257864 total_time 726\n",
      "episode 5869, reward 1145.0, memory_length 2000, epsilon 0.05315675973558585 total_time 725\n",
      "episode 5879, reward 1011.0, memory_length 2000, epsilon 0.05289163929035501 total_time 723\n",
      "episode 5889, reward 1324.0, memory_length 2000, epsilon 0.05262784113886122 total_time 727\n",
      "episode 5899, reward 1246.0, memory_length 2000, epsilon 0.05236535868613695 total_time 721\n",
      "Saving Model 5900\n",
      "episode 5909, reward 925.0, memory_length 2000, epsilon 0.0521041853701072 total_time 724\n",
      "episode 5919, reward 1000.0, memory_length 2000, epsilon 0.05184431466142543 total_time 727\n",
      "episode 5929, reward 1104.0, memory_length 2000, epsilon 0.051585740063310445 total_time 726\n",
      "episode 5939, reward 1417.0, memory_length 2000, epsilon 0.051328455111383814 total_time 721\n",
      "episode 5949, reward 1236.0, memory_length 2000, epsilon 0.05107245337350832 total_time 723\n",
      "episode 5959, reward 1269.0, memory_length 2000, epsilon 0.05081772844962717 total_time 729\n",
      "episode 5969, reward 1007.0, memory_length 2000, epsilon 0.05056427397160404 total_time 731\n",
      "episode 5979, reward 1444.0, memory_length 2000, epsilon 0.05031208360306376 total_time 721\n",
      "episode 5989, reward 1322.0, memory_length 2000, epsilon 0.050061151039233975 total_time 722\n",
      "episode 5999, reward 998.0, memory_length 2000, epsilon 0.049811470006787505 total_time 722\n",
      "Saving Model 6000\n",
      "episode 6009, reward 1003.0, memory_length 2000, epsilon 0.04956303426368557 total_time 721\n",
      "episode 6019, reward 1221.0, memory_length 2000, epsilon 0.04931583759902165 total_time 726\n",
      "episode 6029, reward 925.0, memory_length 2000, epsilon 0.049069873832866234 total_time 724\n",
      "episode 6039, reward 1156.0, memory_length 2000, epsilon 0.04882513681611236 total_time 721\n",
      "episode 6049, reward 1339.0, memory_length 2000, epsilon 0.04858162043032186 total_time 724\n",
      "episode 6059, reward 984.0, memory_length 2000, epsilon 0.04833931858757242 total_time 723\n",
      "episode 6069, reward 1472.0, memory_length 2000, epsilon 0.04809822523030535 total_time 728\n",
      "episode 6079, reward 989.0, memory_length 2000, epsilon 0.04785833433117416 total_time 722\n",
      "episode 6089, reward 1452.0, memory_length 2000, epsilon 0.04761963989289384 total_time 723\n",
      "episode 6099, reward 1311.0, memory_length 2000, epsilon 0.04738213594809106 total_time 726\n",
      "Saving Model 6100\n",
      "episode 6109, reward 1358.0, memory_length 2000, epsilon 0.04714581655915481 total_time 722\n",
      "episode 6119, reward 1282.0, memory_length 2000, epsilon 0.04691067581808805 total_time 721\n",
      "episode 6129, reward 1124.0, memory_length 2000, epsilon 0.04667670784635998 total_time 722\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 6139, reward 1295.0, memory_length 2000, epsilon 0.046443906794759175 total_time 731\n",
      "episode 6149, reward 1632.0, memory_length 2000, epsilon 0.046212266843247196 total_time 723\n",
      "episode 6159, reward 1201.0, memory_length 2000, epsilon 0.04598178220081319 total_time 730\n",
      "episode 6169, reward 731.0, memory_length 2000, epsilon 0.04575244710532907 total_time 725\n",
      "episode 6179, reward 1161.0, memory_length 2000, epsilon 0.045524255823405545 total_time 729\n",
      "episode 6189, reward 903.0, memory_length 2000, epsilon 0.04529720265024866 total_time 723\n",
      "episode 6199, reward 1258.0, memory_length 2000, epsilon 0.045071281909517265 total_time 724\n",
      "Saving Model 6200\n",
      "episode 6209, reward 1276.0, memory_length 2000, epsilon 0.04484648795318105 total_time 733\n",
      "episode 6219, reward 1246.0, memory_length 2000, epsilon 0.04462281516137944 total_time 721\n",
      "episode 6229, reward 922.0, memory_length 2000, epsilon 0.044400257942280974 total_time 721\n",
      "episode 6239, reward 958.0, memory_length 2000, epsilon 0.04417881073194358 total_time 721\n",
      "episode 6249, reward 897.0, memory_length 2000, epsilon 0.04395846799417545 total_time 726\n",
      "episode 6259, reward 1286.0, memory_length 2000, epsilon 0.043739224220396694 total_time 722\n",
      "episode 6269, reward 952.0, memory_length 2000, epsilon 0.04352107392950154 total_time 724\n",
      "episode 6279, reward 1448.0, memory_length 2000, epsilon 0.04330401166772134 total_time 722\n",
      "episode 6289, reward 1489.0, memory_length 2000, epsilon 0.04308803200848826 total_time 730\n",
      "episode 6299, reward 1112.0, memory_length 2000, epsilon 0.042873129552299535 total_time 728\n",
      "Saving Model 6300\n",
      "episode 6309, reward 1496.0, memory_length 2000, epsilon 0.04265929892658262 total_time 725\n",
      "episode 6319, reward 1565.0, memory_length 2000, epsilon 0.04244653478556071 total_time 722\n",
      "episode 6329, reward 1328.0, memory_length 2000, epsilon 0.042234831810119194 total_time 728\n",
      "episode 6339, reward 1135.0, memory_length 2000, epsilon 0.04202418470767265 total_time 727\n",
      "episode 6349, reward 1340.0, memory_length 2000, epsilon 0.04181458821203258 total_time 722\n",
      "episode 6359, reward 1371.0, memory_length 2000, epsilon 0.04160603708327565 total_time 723\n",
      "episode 6369, reward 1282.0, memory_length 2000, epsilon 0.041398526107612785 total_time 721\n",
      "episode 6379, reward 1461.0, memory_length 2000, epsilon 0.041192050097258764 total_time 723\n",
      "episode 6389, reward 1286.0, memory_length 2000, epsilon 0.04098660389030262 total_time 722\n",
      "episode 6399, reward 1447.0, memory_length 2000, epsilon 0.04078218235057845 total_time 724\n",
      "Saving Model 6400\n",
      "episode 6409, reward 1075.0, memory_length 2000, epsilon 0.04057878036753712 total_time 721\n",
      "episode 6419, reward 762.0, memory_length 2000, epsilon 0.04037639285611844 total_time 726\n",
      "episode 6429, reward 1140.0, memory_length 2000, epsilon 0.04017501475662412 total_time 726\n",
      "episode 6439, reward 1038.0, memory_length 2000, epsilon 0.03997464103459117 total_time 723\n",
      "episode 6449, reward 1102.0, memory_length 2000, epsilon 0.039775266680666096 total_time 721\n",
      "episode 6459, reward 1132.0, memory_length 2000, epsilon 0.039576886710479646 total_time 724\n",
      "episode 6469, reward 1390.0, memory_length 2000, epsilon 0.03937949616452228 total_time 721\n",
      "episode 6479, reward 1043.0, memory_length 2000, epsilon 0.03918309010802005 total_time 722\n",
      "episode 6489, reward 1478.0, memory_length 2000, epsilon 0.03898766363081129 total_time 725\n",
      "episode 6499, reward 1363.0, memory_length 2000, epsilon 0.0387932118472239 total_time 721\n",
      "Saving Model 6500\n",
      "episode 6509, reward 1039.0, memory_length 2000, epsilon 0.0385997298959532 total_time 721\n",
      "episode 6519, reward 1344.0, memory_length 2000, epsilon 0.03840721293994029 total_time 723\n",
      "episode 6529, reward 1448.0, memory_length 2000, epsilon 0.03821565616625126 total_time 722\n",
      "episode 6539, reward 1453.0, memory_length 2000, epsilon 0.03802505478595679 total_time 721\n",
      "episode 6549, reward 1171.0, memory_length 2000, epsilon 0.03783540403401242 total_time 727\n",
      "episode 6559, reward 1065.0, memory_length 2000, epsilon 0.03764669916913952 total_time 723\n",
      "episode 6569, reward 1420.0, memory_length 2000, epsilon 0.037458935473706614 total_time 724\n",
      "episode 6579, reward 1498.0, memory_length 2000, epsilon 0.03727210825361153 total_time 721\n",
      "episode 6589, reward 1192.0, memory_length 2000, epsilon 0.03708621283816403 total_time 721\n",
      "episode 6599, reward 1576.0, memory_length 2000, epsilon 0.03690124457996908 total_time 727\n",
      "Saving Model 6600\n",
      "episode 6609, reward 1322.0, memory_length 2000, epsilon 0.036717198854810576 total_time 722\n",
      "episode 6619, reward 1204.0, memory_length 2000, epsilon 0.036534071061535785 total_time 724\n",
      "episode 6629, reward 1178.0, memory_length 2000, epsilon 0.03635185662194034 total_time 722\n",
      "episode 6639, reward 1488.0, memory_length 2000, epsilon 0.03617055098065379 total_time 723\n",
      "episode 6649, reward 1064.0, memory_length 2000, epsilon 0.03599014960502563 total_time 725\n",
      "episode 6659, reward 1668.0, memory_length 2000, epsilon 0.035810647985012094 total_time 723\n",
      "episode 6669, reward 1411.0, memory_length 2000, epsilon 0.03563204163306331 total_time 724\n",
      "episode 6679, reward 1273.0, memory_length 2000, epsilon 0.035454326084011195 total_time 721\n",
      "episode 6689, reward 1525.0, memory_length 2000, epsilon 0.03527749689495777 total_time 721\n",
      "episode 6699, reward 1795.0, memory_length 2000, epsilon 0.03510154964516409 total_time 721\n",
      "Saving Model 6700\n",
      "episode 6709, reward 1403.0, memory_length 2000, epsilon 0.03492647993593973 total_time 722\n",
      "episode 6719, reward 1439.0, memory_length 2000, epsilon 0.034752283390532865 total_time 722\n",
      "episode 6729, reward 1433.0, memory_length 2000, epsilon 0.03457895565402079 total_time 725\n",
      "episode 6739, reward 1500.0, memory_length 2000, epsilon 0.03440649239320105 total_time 726\n",
      "episode 6749, reward 1353.0, memory_length 2000, epsilon 0.03423488929648313 total_time 723\n",
      "episode 6759, reward 1795.0, memory_length 2000, epsilon 0.0340641420737807 total_time 721\n",
      "episode 6769, reward 1343.0, memory_length 2000, epsilon 0.0338942464564043 total_time 725\n",
      "episode 6779, reward 1714.0, memory_length 2000, epsilon 0.03372519819695464 total_time 721\n",
      "episode 6789, reward 1449.0, memory_length 2000, epsilon 0.03355699306921642 total_time 729\n",
      "episode 6799, reward 1363.0, memory_length 2000, epsilon 0.03338962686805266 total_time 721\n",
      "Saving Model 6800\n",
      "episode 6809, reward 1244.0, memory_length 2000, epsilon 0.033223095409299686 total_time 725\n",
      "episode 6819, reward 998.0, memory_length 2000, epsilon 0.03305739452966231 total_time 722\n",
      "episode 6829, reward 1542.0, memory_length 2000, epsilon 0.032892520086609915 total_time 723\n",
      "episode 6839, reward 1587.0, memory_length 2000, epsilon 0.03272846795827282 total_time 723\n",
      "episode 6849, reward 1159.0, memory_length 2000, epsilon 0.0325652340433393 total_time 724\n",
      "episode 6859, reward 1020.0, memory_length 2000, epsilon 0.03240281426095298 total_time 723\n",
      "episode 6869, reward 1290.0, memory_length 2000, epsilon 0.03224120455061084 total_time 723\n",
      "episode 6879, reward 814.0, memory_length 2000, epsilon 0.03208040087206167 total_time 730\n",
      "episode 6889, reward 1034.0, memory_length 2000, epsilon 0.03192039920520517 total_time 722\n",
      "episode 6899, reward 1366.0, memory_length 2000, epsilon 0.03176119554999133 total_time 724\n",
      "Saving Model 6900\n",
      "episode 6909, reward 1255.0, memory_length 2000, epsilon 0.031602785926320466 total_time 721\n",
      "episode 6919, reward 1091.0, memory_length 2000, epsilon 0.03144516637394371 total_time 725\n",
      "episode 6929, reward 1097.0, memory_length 2000, epsilon 0.03128833295236411 total_time 722\n",
      "episode 6939, reward 1043.0, memory_length 2000, epsilon 0.031132281740737917 total_time 722\n",
      "episode 6949, reward 1268.0, memory_length 2000, epsilon 0.030977008837776713 total_time 722\n",
      "episode 6959, reward 1456.0, memory_length 2000, epsilon 0.030822510361649826 total_time 724\n",
      "episode 6969, reward 1279.0, memory_length 2000, epsilon 0.030668782449887338 total_time 727\n",
      "episode 6979, reward 1237.0, memory_length 2000, epsilon 0.03051582125928343 total_time 721\n",
      "episode 6989, reward 1167.0, memory_length 2000, epsilon 0.030363622965800367 total_time 726\n",
      "episode 6999, reward 1079.0, memory_length 2000, epsilon 0.030212183764472877 total_time 722\n",
      "Saving Model 7000\n",
      "episode 7009, reward 951.0, memory_length 2000, epsilon 0.030061499869313068 total_time 726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 7019, reward 1237.0, memory_length 2000, epsilon 0.029911567513215692 total_time 721\n",
      "episode 7029, reward 1530.0, memory_length 2000, epsilon 0.029762382947864045 total_time 729\n",
      "episode 7039, reward 1312.0, memory_length 2000, epsilon 0.029613942443636205 total_time 724\n",
      "episode 7049, reward 1326.0, memory_length 2000, epsilon 0.029466242289511866 total_time 723\n",
      "episode 7059, reward 1038.0, memory_length 2000, epsilon 0.029319278792979464 total_time 723\n",
      "episode 7069, reward 958.0, memory_length 2000, epsilon 0.029173048279943936 total_time 721\n",
      "episode 7079, reward 1389.0, memory_length 2000, epsilon 0.029027547094634832 total_time 723\n",
      "episode 7089, reward 1487.0, memory_length 2000, epsilon 0.02888277159951494 total_time 725\n",
      "episode 7099, reward 1102.0, memory_length 2000, epsilon 0.028738718175189356 total_time 730\n",
      "Saving Model 7100\n",
      "episode 7109, reward 895.0, memory_length 2000, epsilon 0.028595383220314963 total_time 721\n",
      "episode 7119, reward 790.0, memory_length 2000, epsilon 0.02845276315151042 total_time 724\n",
      "episode 7129, reward 1079.0, memory_length 2000, epsilon 0.028310854403266573 total_time 722\n",
      "episode 7139, reward 1135.0, memory_length 2000, epsilon 0.028169653427857343 total_time 727\n",
      "episode 7149, reward 1201.0, memory_length 2000, epsilon 0.028029156695250978 total_time 721\n",
      "episode 7159, reward 1507.0, memory_length 2000, epsilon 0.027889360693021847 total_time 721\n",
      "episode 7169, reward 1302.0, memory_length 2000, epsilon 0.027750261926262603 total_time 726\n",
      "episode 7179, reward 1248.0, memory_length 2000, epsilon 0.027611856917496857 total_time 726\n",
      "episode 7189, reward 1210.0, memory_length 2000, epsilon 0.027474142206592167 total_time 721\n",
      "episode 7199, reward 1343.0, memory_length 2000, epsilon 0.027337114350673587 total_time 725\n",
      "Saving Model 7200\n",
      "episode 7209, reward 1408.0, memory_length 2000, epsilon 0.02720076992403757 total_time 721\n",
      "episode 7219, reward 1128.0, memory_length 2000, epsilon 0.027065105518066374 total_time 723\n",
      "episode 7229, reward 1258.0, memory_length 2000, epsilon 0.026930117741142772 total_time 724\n",
      "episode 7239, reward 792.0, memory_length 2000, epsilon 0.026795803218565308 total_time 729\n",
      "episode 7249, reward 1331.0, memory_length 2000, epsilon 0.026662158592463917 total_time 722\n",
      "episode 7259, reward 1303.0, memory_length 2000, epsilon 0.026529180521716 total_time 724\n",
      "episode 7269, reward 1057.0, memory_length 2000, epsilon 0.02639686568186286 total_time 721\n",
      "episode 7279, reward 1105.0, memory_length 2000, epsilon 0.026265210765026602 total_time 724\n",
      "episode 7289, reward 951.0, memory_length 2000, epsilon 0.02613421247982744 total_time 726\n",
      "episode 7299, reward 872.0, memory_length 2000, epsilon 0.02600386755130144 total_time 722\n",
      "Saving Model 7300\n",
      "episode 7309, reward 1309.0, memory_length 2000, epsilon 0.02587417272081859 total_time 721\n",
      "episode 7319, reward 1194.0, memory_length 2000, epsilon 0.02574512474600138 total_time 726\n",
      "episode 7329, reward 986.0, memory_length 2000, epsilon 0.02561672040064371 total_time 728\n",
      "episode 7339, reward 1438.0, memory_length 2000, epsilon 0.025488956474630255 total_time 724\n",
      "episode 7349, reward 1097.0, memory_length 2000, epsilon 0.025361829773856225 total_time 722\n",
      "episode 7359, reward 1489.0, memory_length 2000, epsilon 0.02523533712014747 total_time 721\n",
      "episode 7369, reward 1336.0, memory_length 2000, epsilon 0.02510947535118106 total_time 721\n",
      "episode 7379, reward 1434.0, memory_length 2000, epsilon 0.024984241320406206 total_time 723\n",
      "episode 7389, reward 1124.0, memory_length 2000, epsilon 0.024859631896965637 total_time 722\n",
      "episode 7399, reward 1120.0, memory_length 2000, epsilon 0.02473564396561726 total_time 721\n",
      "Saving Model 7400\n",
      "episode 7409, reward 1386.0, memory_length 2000, epsilon 0.024612274426656346 total_time 729\n",
      "episode 7419, reward 1264.0, memory_length 2000, epsilon 0.02448952019583798 total_time 721\n",
      "episode 7429, reward 1493.0, memory_length 2000, epsilon 0.024367378204300013 total_time 722\n",
      "episode 7439, reward 997.0, memory_length 2000, epsilon 0.024245845398486288 total_time 724\n",
      "episode 7449, reward 1045.0, memory_length 2000, epsilon 0.024124918740070334 total_time 727\n",
      "episode 7459, reward 1069.0, memory_length 2000, epsilon 0.024004595205879373 total_time 724\n",
      "episode 7469, reward 1122.0, memory_length 2000, epsilon 0.023884871787818816 total_time 726\n",
      "episode 7479, reward 943.0, memory_length 2000, epsilon 0.023765745492796957 total_time 724\n",
      "episode 7489, reward 1255.0, memory_length 2000, epsilon 0.023647213342650217 total_time 721\n",
      "episode 7499, reward 1630.0, memory_length 2000, epsilon 0.023529272374068662 total_time 727\n",
      "Saving Model 7500\n",
      "episode 7509, reward 1040.0, memory_length 2000, epsilon 0.02341191963852195 total_time 728\n",
      "episode 7519, reward 1196.0, memory_length 2000, epsilon 0.023295152202185577 total_time 722\n",
      "episode 7529, reward 1309.0, memory_length 2000, epsilon 0.023178967145867545 total_time 721\n",
      "episode 7539, reward 1375.0, memory_length 2000, epsilon 0.02306336156493539 total_time 724\n",
      "episode 7549, reward 1317.0, memory_length 2000, epsilon 0.022948332569243588 total_time 732\n",
      "episode 7559, reward 1354.0, memory_length 2000, epsilon 0.02283387728306124 total_time 721\n",
      "episode 7569, reward 1325.0, memory_length 2000, epsilon 0.022719992845000238 total_time 725\n",
      "episode 7579, reward 1250.0, memory_length 2000, epsilon 0.022606676407943692 total_time 722\n",
      "episode 7589, reward 1574.0, memory_length 2000, epsilon 0.022493925138974767 total_time 722\n",
      "episode 7599, reward 1561.0, memory_length 2000, epsilon 0.022381736219305885 total_time 721\n",
      "Saving Model 7600\n",
      "episode 7609, reward 1650.0, memory_length 2000, epsilon 0.022270106844208205 total_time 723\n",
      "episode 7619, reward 1520.0, memory_length 2000, epsilon 0.02215903422294153 total_time 722\n",
      "episode 7629, reward 1218.0, memory_length 2000, epsilon 0.022048515578684535 total_time 723\n",
      "episode 7639, reward 1420.0, memory_length 2000, epsilon 0.021938548148465385 total_time 724\n",
      "episode 7649, reward 1425.0, memory_length 2000, epsilon 0.02182912918309257 total_time 732\n",
      "episode 7659, reward 1462.0, memory_length 2000, epsilon 0.021720255947086275 total_time 721\n",
      "episode 7669, reward 1405.0, memory_length 2000, epsilon 0.02161192571860991 total_time 727\n",
      "episode 7679, reward 1148.0, memory_length 2000, epsilon 0.02150413578940214 total_time 728\n",
      "episode 7689, reward 1281.0, memory_length 2000, epsilon 0.021396883464709117 total_time 723\n",
      "episode 7699, reward 1096.0, memory_length 2000, epsilon 0.02129016606321713 total_time 724\n",
      "Saving Model 7700\n",
      "episode 7709, reward 1123.0, memory_length 2000, epsilon 0.02118398091698558 total_time 733\n",
      "episode 7719, reward 911.0, memory_length 2000, epsilon 0.021078325371380293 total_time 725\n",
      "episode 7729, reward 1433.0, memory_length 2000, epsilon 0.020973196785007125 total_time 725\n",
      "episode 7739, reward 1381.0, memory_length 2000, epsilon 0.020868592529645933 total_time 721\n",
      "episode 7749, reward 1470.0, memory_length 2000, epsilon 0.020764509990184882 total_time 723\n",
      "episode 7759, reward 1531.0, memory_length 2000, epsilon 0.020660946564555086 total_time 727\n",
      "episode 7769, reward 1717.0, memory_length 2000, epsilon 0.020557899663665488 total_time 724\n",
      "episode 7779, reward 1360.0, memory_length 2000, epsilon 0.02045536671133821 total_time 727\n",
      "episode 7789, reward 1507.0, memory_length 2000, epsilon 0.020353345144244087 total_time 730\n",
      "episode 7799, reward 920.0, memory_length 2000, epsilon 0.020251832411838658 total_time 725\n",
      "Saving Model 7800\n",
      "episode 7809, reward 756.0, memory_length 2000, epsilon 0.0201508259762983 total_time 729\n",
      "episode 7819, reward 1217.0, memory_length 2000, epsilon 0.020050323312456878 total_time 725\n",
      "episode 7829, reward 1047.0, memory_length 2000, epsilon 0.019950321907742555 total_time 723\n",
      "episode 7839, reward 1102.0, memory_length 2000, epsilon 0.019850819262114995 total_time 721\n",
      "episode 7849, reward 1334.0, memory_length 2000, epsilon 0.019751812888002897 total_time 725\n",
      "episode 7859, reward 1047.0, memory_length 2000, epsilon 0.019653300310241737 total_time 723\n",
      "episode 7869, reward 1255.0, memory_length 2000, epsilon 0.019555279066011948 total_time 721\n",
      "episode 7879, reward 1501.0, memory_length 2000, epsilon 0.0194577467047773 total_time 724\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 7889, reward 1186.0, memory_length 2000, epsilon 0.01936070078822371 total_time 724\n",
      "episode 7899, reward 1354.0, memory_length 2000, epsilon 0.019264138890198193 total_time 730\n",
      "Saving Model 7900\n",
      "episode 7909, reward 1272.0, memory_length 2000, epsilon 0.019168058596648274 total_time 723\n",
      "episode 7919, reward 1798.0, memory_length 2000, epsilon 0.0190724575055616 total_time 724\n",
      "episode 7929, reward 1173.0, memory_length 2000, epsilon 0.018977333226905934 total_time 723\n",
      "episode 7939, reward 1555.0, memory_length 2000, epsilon 0.018882683382569338 total_time 724\n",
      "episode 7949, reward 1439.0, memory_length 2000, epsilon 0.018788505606300788 total_time 722\n",
      "episode 7959, reward 1381.0, memory_length 2000, epsilon 0.01869479754365095 total_time 730\n",
      "episode 7969, reward 1608.0, memory_length 2000, epsilon 0.0186015568519134 total_time 726\n",
      "episode 7979, reward 1230.0, memory_length 2000, epsilon 0.018508781200065983 total_time 726\n",
      "episode 7989, reward 1340.0, memory_length 2000, epsilon 0.018416468268712564 total_time 722\n",
      "episode 7999, reward 1487.0, memory_length 2000, epsilon 0.018324615750025048 total_time 725\n",
      "Saving Model 8000\n",
      "episode 8009, reward 1263.0, memory_length 2000, epsilon 0.018233221347685697 total_time 723\n",
      "episode 8019, reward 1380.0, memory_length 2000, epsilon 0.018142282776829687 total_time 723\n",
      "episode 8029, reward 791.0, memory_length 2000, epsilon 0.01805179776398801 total_time 722\n",
      "episode 8039, reward 1025.0, memory_length 2000, epsilon 0.01796176404703063 total_time 722\n",
      "episode 8049, reward 1383.0, memory_length 2000, epsilon 0.017872179375109938 total_time 726\n",
      "episode 8059, reward 954.0, memory_length 2000, epsilon 0.01778304150860445 total_time 729\n",
      "episode 8069, reward 1095.0, memory_length 2000, epsilon 0.01769434821906289 total_time 726\n",
      "episode 8079, reward 1678.0, memory_length 2000, epsilon 0.017606097289148394 total_time 721\n",
      "episode 8089, reward 1217.0, memory_length 2000, epsilon 0.017518286512583105 total_time 725\n",
      "episode 8099, reward 1484.0, memory_length 2000, epsilon 0.01743091369409305 total_time 722\n",
      "Saving Model 8100\n",
      "episode 8109, reward 1649.0, memory_length 2000, epsilon 0.017343976649353204 total_time 725\n",
      "episode 8119, reward 1500.0, memory_length 2000, epsilon 0.017257473204932924 total_time 726\n",
      "episode 8129, reward 1179.0, memory_length 2000, epsilon 0.017171401198241596 total_time 729\n",
      "episode 8139, reward 1402.0, memory_length 2000, epsilon 0.017085758477474566 total_time 724\n",
      "episode 8149, reward 1209.0, memory_length 2000, epsilon 0.017000542901559345 total_time 723\n",
      "episode 8159, reward 1326.0, memory_length 2000, epsilon 0.016915752340102123 total_time 723\n",
      "episode 8169, reward 1217.0, memory_length 2000, epsilon 0.01683138467333443 total_time 725\n",
      "episode 8179, reward 1521.0, memory_length 2000, epsilon 0.016747437792060213 total_time 729\n",
      "episode 8189, reward 1789.0, memory_length 2000, epsilon 0.01666390959760305 total_time 724\n",
      "episode 8199, reward 1204.0, memory_length 2000, epsilon 0.016580798001753747 total_time 724\n",
      "Saving Model 8200\n",
      "episode 8209, reward 1285.0, memory_length 2000, epsilon 0.016498100926718072 total_time 724\n",
      "episode 8219, reward 1277.0, memory_length 2000, epsilon 0.016415816305064838 total_time 722\n",
      "episode 8229, reward 1213.0, memory_length 2000, epsilon 0.016333942079674212 total_time 724\n",
      "episode 8239, reward 1147.0, memory_length 2000, epsilon 0.016252476203686316 total_time 721\n",
      "episode 8249, reward 1322.0, memory_length 2000, epsilon 0.016171416640449996 total_time 722\n",
      "episode 8259, reward 1485.0, memory_length 2000, epsilon 0.01609076136347195 total_time 729\n",
      "episode 8269, reward 1687.0, memory_length 2000, epsilon 0.016010508356366054 total_time 721\n",
      "episode 8279, reward 1376.0, memory_length 2000, epsilon 0.015930655612802946 total_time 731\n",
      "episode 8289, reward 1671.0, memory_length 2000, epsilon 0.01585120113645988 total_time 726\n",
      "episode 8299, reward 1632.0, memory_length 2000, epsilon 0.01577214294097081 total_time 723\n",
      "Saving Model 8300\n",
      "episode 8309, reward 1669.0, memory_length 2000, epsilon 0.015693479049876717 total_time 721\n",
      "episode 8319, reward 1677.0, memory_length 2000, epsilon 0.015615207496576253 total_time 723\n",
      "episode 8329, reward 1201.0, memory_length 2000, epsilon 0.015537326324276499 total_time 721\n",
      "episode 8339, reward 1398.0, memory_length 2000, epsilon 0.015459833585944086 total_time 723\n",
      "episode 8349, reward 913.0, memory_length 2000, epsilon 0.015382727344256523 total_time 721\n",
      "episode 8359, reward 1445.0, memory_length 2000, epsilon 0.015306005671553751 total_time 728\n",
      "episode 8369, reward 1057.0, memory_length 2000, epsilon 0.015229666649789956 total_time 721\n",
      "episode 8379, reward 1588.0, memory_length 2000, epsilon 0.015153708370485616 total_time 721\n",
      "episode 8389, reward 1579.0, memory_length 2000, epsilon 0.015078128934679799 total_time 721\n",
      "episode 8399, reward 1153.0, memory_length 2000, epsilon 0.015002926452882651 total_time 727\n",
      "Saving Model 8400\n",
      "episode 8409, reward 962.0, memory_length 2000, epsilon 0.014928099045028245 total_time 722\n",
      "episode 8419, reward 1038.0, memory_length 2000, epsilon 0.014853644840427468 total_time 723\n",
      "episode 8429, reward 1353.0, memory_length 2000, epsilon 0.014779561977721331 total_time 723\n",
      "episode 8439, reward 1246.0, memory_length 2000, epsilon 0.014705848604834405 total_time 721\n",
      "episode 8449, reward 1346.0, memory_length 2000, epsilon 0.014632502878928533 total_time 728\n",
      "episode 8459, reward 1255.0, memory_length 2000, epsilon 0.014559522966356741 total_time 721\n",
      "episode 8469, reward 1436.0, memory_length 2000, epsilon 0.014486907042617419 total_time 728\n",
      "episode 8479, reward 1604.0, memory_length 2000, epsilon 0.014414653292308677 total_time 725\n",
      "episode 8489, reward 971.0, memory_length 2000, epsilon 0.014342759909083017 total_time 722\n",
      "episode 8499, reward 1125.0, memory_length 2000, epsilon 0.014271225095602106 total_time 729\n",
      "Saving Model 8500\n",
      "episode 8509, reward 1425.0, memory_length 2000, epsilon 0.014200047063491879 total_time 732\n",
      "episode 8519, reward 1222.0, memory_length 2000, epsilon 0.014129224033297824 total_time 724\n",
      "episode 8529, reward 1155.0, memory_length 2000, epsilon 0.014058754234440498 total_time 723\n",
      "episode 8539, reward 947.0, memory_length 2000, epsilon 0.013988635905171262 total_time 725\n",
      "episode 8549, reward 1339.0, memory_length 2000, epsilon 0.013918867292528232 total_time 724\n",
      "episode 8559, reward 1547.0, memory_length 2000, epsilon 0.013849446652292442 total_time 722\n",
      "episode 8569, reward 1102.0, memory_length 2000, epsilon 0.0137803722489443 total_time 721\n",
      "episode 8579, reward 1317.0, memory_length 2000, epsilon 0.013711642355620108 total_time 723\n",
      "episode 8589, reward 1181.0, memory_length 2000, epsilon 0.013643255254068955 total_time 725\n",
      "episode 8599, reward 835.0, memory_length 2000, epsilon 0.013575209234609741 total_time 724\n",
      "Saving Model 8600\n",
      "episode 8609, reward 1245.0, memory_length 2000, epsilon 0.013507502596088435 total_time 723\n",
      "episode 8619, reward 1363.0, memory_length 2000, epsilon 0.013440133645835548 total_time 730\n",
      "episode 8629, reward 1300.0, memory_length 2000, epsilon 0.013373100699623814 total_time 721\n",
      "episode 8639, reward 1263.0, memory_length 2000, epsilon 0.013306402081626088 total_time 723\n",
      "episode 8649, reward 1329.0, memory_length 2000, epsilon 0.013240036124373432 total_time 726\n",
      "episode 8659, reward 1146.0, memory_length 2000, epsilon 0.013174001168713484 total_time 723\n",
      "episode 8669, reward 1342.0, memory_length 2000, epsilon 0.013108295563768897 total_time 727\n",
      "episode 8679, reward 1281.0, memory_length 2000, epsilon 0.013042917666896131 total_time 723\n",
      "episode 8689, reward 1547.0, memory_length 2000, epsilon 0.012977865843644357 total_time 722\n",
      "episode 8699, reward 1326.0, memory_length 2000, epsilon 0.012913138467714604 total_time 723\n",
      "Saving Model 8700\n",
      "episode 8709, reward 1727.0, memory_length 2000, epsilon 0.012848733920919106 total_time 722\n",
      "episode 8719, reward 1695.0, memory_length 2000, epsilon 0.012784650593140833 total_time 723\n",
      "episode 8729, reward 1198.0, memory_length 2000, epsilon 0.012720886882293246 total_time 727\n",
      "episode 8739, reward 998.0, memory_length 2000, epsilon 0.012657441194280276 total_time 722\n",
      "episode 8749, reward 1523.0, memory_length 2000, epsilon 0.012594311942956406 total_time 725\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 8759, reward 1610.0, memory_length 2000, epsilon 0.012531497550087062 total_time 722\n",
      "episode 8769, reward 1247.0, memory_length 2000, epsilon 0.012468996445309154 total_time 728\n",
      "episode 8779, reward 1606.0, memory_length 2000, epsilon 0.012406807066091805 total_time 721\n",
      "episode 8789, reward 1232.0, memory_length 2000, epsilon 0.012344927857697297 total_time 722\n",
      "episode 8799, reward 1045.0, memory_length 2000, epsilon 0.012283357273142198 total_time 727\n",
      "Saving Model 8800\n",
      "episode 8809, reward 1127.0, memory_length 2000, epsilon 0.012222093773158674 total_time 725\n",
      "episode 8819, reward 895.0, memory_length 2000, epsilon 0.012161135826156058 total_time 721\n",
      "episode 8829, reward 1070.0, memory_length 2000, epsilon 0.01210048190818249 total_time 722\n",
      "episode 8839, reward 929.0, memory_length 2000, epsilon 0.01204013050288686 total_time 725\n",
      "episode 8849, reward 1048.0, memory_length 2000, epsilon 0.011980080101480892 total_time 721\n",
      "episode 8859, reward 968.0, memory_length 2000, epsilon 0.011920329202701425 total_time 728\n",
      "episode 8869, reward 1329.0, memory_length 2000, epsilon 0.011860876312772876 total_time 726\n",
      "episode 8879, reward 1166.0, memory_length 2000, epsilon 0.011801719945369903 total_time 728\n",
      "episode 8889, reward 1025.0, memory_length 2000, epsilon 0.011742858621580235 total_time 722\n",
      "episode 8899, reward 841.0, memory_length 2000, epsilon 0.011684290869867704 total_time 721\n",
      "Saving Model 8900\n",
      "episode 8909, reward 1162.0, memory_length 2000, epsilon 0.011626015226035489 total_time 727\n",
      "episode 8919, reward 1204.0, memory_length 2000, epsilon 0.011568030233189445 total_time 724\n",
      "episode 8929, reward 1426.0, memory_length 2000, epsilon 0.011510334441701735 total_time 721\n",
      "episode 8939, reward 897.0, memory_length 2000, epsilon 0.011452926409174561 total_time 726\n",
      "episode 8949, reward 1240.0, memory_length 2000, epsilon 0.011395804700404126 total_time 724\n",
      "episode 8959, reward 1502.0, memory_length 2000, epsilon 0.011338967887344734 total_time 722\n",
      "episode 8969, reward 1093.0, memory_length 2000, epsilon 0.011282414549073095 total_time 721\n",
      "episode 8979, reward 1111.0, memory_length 2000, epsilon 0.011226143271752802 total_time 721\n",
      "episode 8989, reward 880.0, memory_length 2000, epsilon 0.011170152648599007 total_time 724\n",
      "episode 8999, reward 1292.0, memory_length 2000, epsilon 0.011114441279843205 total_time 728\n",
      "Saving Model 9000\n",
      "episode 9009, reward 1542.0, memory_length 2000, epsilon 0.011059007772698278 total_time 723\n",
      "episode 9019, reward 1242.0, memory_length 2000, epsilon 0.011003850741323658 total_time 729\n",
      "episode 9029, reward 1024.0, memory_length 2000, epsilon 0.01094896880679069 total_time 724\n",
      "episode 9039, reward 1196.0, memory_length 2000, epsilon 0.01089436059704815 total_time 722\n",
      "episode 9049, reward 1242.0, memory_length 2000, epsilon 0.010840024746887951 total_time 729\n",
      "episode 9059, reward 1110.0, memory_length 2000, epsilon 0.010785959897911 total_time 723\n",
      "episode 9069, reward 1131.0, memory_length 2000, epsilon 0.010732164698493278 total_time 726\n",
      "episode 9079, reward 1130.0, memory_length 2000, epsilon 0.010678637803751981 total_time 728\n",
      "episode 9089, reward 1246.0, memory_length 2000, epsilon 0.010625377875511962 total_time 721\n",
      "episode 9099, reward 1280.0, memory_length 2000, epsilon 0.010572383582272233 total_time 725\n",
      "Saving Model 9100\n",
      "episode 9109, reward 1137.0, memory_length 2000, epsilon 0.010519653599172708 total_time 723\n",
      "episode 9119, reward 1063.0, memory_length 2000, epsilon 0.010467186607961062 total_time 727\n",
      "episode 9129, reward 1399.0, memory_length 2000, epsilon 0.01041498129695978 total_time 721\n",
      "episode 9139, reward 1090.0, memory_length 2000, epsilon 0.010363036361033369 total_time 727\n",
      "episode 9149, reward 1156.0, memory_length 2000, epsilon 0.010311350501555717 total_time 721\n",
      "episode 9159, reward 485.0, memory_length 2000, epsilon 0.010259922426377662 total_time 722\n",
      "episode 9169, reward 839.0, memory_length 2000, epsilon 0.01020875084979464 total_time 725\n",
      "episode 9179, reward 331.0, memory_length 2000, epsilon 0.010157834492514568 total_time 724\n",
      "episode 9189, reward 472.0, memory_length 2000, epsilon 0.010107172081625863 total_time 721\n",
      "episode 9199, reward 560.0, memory_length 2000, epsilon 0.010056762350565615 total_time 725\n",
      "Saving Model 9200\n",
      "episode 9209, reward 508.0, memory_length 2000, epsilon 0.010006604039087921 total_time 721\n",
      "episode 9219, reward 781.0, memory_length 2000, epsilon 0.009956695893232382 total_time 724\n",
      "episode 9229, reward 683.0, memory_length 2000, epsilon 0.009907036665292744 total_time 722\n",
      "episode 9239, reward 238.0, memory_length 2000, epsilon 0.009857625113785738 total_time 721\n",
      "episode 9249, reward 768.0, memory_length 2000, epsilon 0.009808460003419995 total_time 723\n",
      "episode 9259, reward 817.0, memory_length 2000, epsilon 0.009759540105065195 total_time 724\n",
      "episode 9269, reward 1192.0, memory_length 2000, epsilon 0.009710864195721333 total_time 721\n",
      "episode 9279, reward 1551.0, memory_length 2000, epsilon 0.009662431058488137 total_time 723\n",
      "episode 9289, reward 1510.0, memory_length 2000, epsilon 0.009614239482534655 total_time 724\n",
      "episode 9299, reward 1331.0, memory_length 2000, epsilon 0.009566288263068979 total_time 722\n",
      "Saving Model 9300\n",
      "episode 9309, reward 1443.0, memory_length 2000, epsilon 0.009518576201308117 total_time 732\n",
      "episode 9319, reward 1793.0, memory_length 2000, epsilon 0.009471102104448055 total_time 725\n",
      "episode 9329, reward 1327.0, memory_length 2000, epsilon 0.009423864785633892 total_time 721\n",
      "episode 9339, reward 1191.0, memory_length 2000, epsilon 0.009376863063930195 total_time 723\n",
      "episode 9349, reward 985.0, memory_length 2000, epsilon 0.009330095764291474 total_time 721\n",
      "episode 9359, reward 1349.0, memory_length 2000, epsilon 0.009283561717532807 total_time 722\n",
      "episode 9369, reward 1623.0, memory_length 2000, epsilon 0.009237259760300594 total_time 723\n",
      "episode 9379, reward 1380.0, memory_length 2000, epsilon 0.009191188735043496 total_time 723\n",
      "episode 9389, reward 1354.0, memory_length 2000, epsilon 0.009145347489983484 total_time 721\n",
      "episode 9399, reward 1312.0, memory_length 2000, epsilon 0.009099734879087034 total_time 724\n",
      "Saving Model 9400\n",
      "episode 9409, reward 1244.0, memory_length 2000, epsilon 0.009054349762036513 total_time 725\n",
      "episode 9419, reward 1660.0, memory_length 2000, epsilon 0.009009191004201625 total_time 721\n",
      "episode 9429, reward 1555.0, memory_length 2000, epsilon 0.008964257476611073 total_time 724\n",
      "episode 9439, reward 1406.0, memory_length 2000, epsilon 0.008919548055924322 total_time 725\n",
      "episode 9449, reward 1552.0, memory_length 2000, epsilon 0.00887506162440353 total_time 721\n",
      "episode 9459, reward 1491.0, memory_length 2000, epsilon 0.008830797069885592 total_time 726\n",
      "episode 9469, reward 1091.0, memory_length 2000, epsilon 0.008786753285754338 total_time 725\n",
      "episode 9479, reward 1474.0, memory_length 2000, epsilon 0.008742929170912865 total_time 724\n",
      "episode 9489, reward 1327.0, memory_length 2000, epsilon 0.008699323629756034 total_time 721\n",
      "episode 9499, reward 1824.0, memory_length 2000, epsilon 0.008655935572143034 total_time 726\n",
      "Saving Model 9500\n",
      "episode 9509, reward 1650.0, memory_length 2000, epsilon 0.008612763913370172 total_time 723\n",
      "episode 9519, reward 1403.0, memory_length 2000, epsilon 0.008569807574143724 total_time 722\n",
      "episode 9529, reward 1952.0, memory_length 2000, epsilon 0.008527065480552974 total_time 722\n",
      "episode 9539, reward 1897.0, memory_length 2000, epsilon 0.008484536564043358 total_time 724\n",
      "episode 9549, reward 1620.0, memory_length 2000, epsilon 0.008442219761389744 total_time 729\n",
      "episode 9559, reward 1713.0, memory_length 2000, epsilon 0.008400114014669856 total_time 723\n",
      "episode 9569, reward 1515.0, memory_length 2000, epsilon 0.00835821827123785 total_time 723\n",
      "episode 9579, reward 1560.0, memory_length 2000, epsilon 0.008316531483697952 total_time 723\n",
      "episode 9589, reward 1470.0, memory_length 2000, epsilon 0.008275052609878295 total_time 723\n",
      "episode 9599, reward 1167.0, memory_length 2000, epsilon 0.00823378061280488 total_time 726\n",
      "Saving Model 9600\n",
      "episode 9609, reward 1398.0, memory_length 2000, epsilon 0.008192714460675628 total_time 723\n",
      "episode 9619, reward 1219.0, memory_length 2000, epsilon 0.008151853126834597 total_time 721\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 9629, reward 1266.0, memory_length 2000, epsilon 0.00811119558974631 total_time 726\n",
      "episode 9639, reward 1847.0, memory_length 2000, epsilon 0.008070740832970229 total_time 725\n",
      "episode 9649, reward 1313.0, memory_length 2000, epsilon 0.008030487845135315 total_time 722\n",
      "episode 9659, reward 1378.0, memory_length 2000, epsilon 0.007990435619914792 total_time 727\n",
      "episode 9669, reward 1824.0, memory_length 2000, epsilon 0.007950583156000935 total_time 726\n",
      "episode 9679, reward 1255.0, memory_length 2000, epsilon 0.007910929457080072 total_time 721\n",
      "episode 9689, reward 1385.0, memory_length 2000, epsilon 0.007871473531807663 total_time 722\n",
      "episode 9699, reward 1462.0, memory_length 2000, epsilon 0.007832214393783524 total_time 721\n",
      "Saving Model 9700\n",
      "episode 9709, reward 1780.0, memory_length 2000, epsilon 0.007793151061527156 total_time 724\n",
      "episode 9719, reward 1204.0, memory_length 2000, epsilon 0.00775428255845322 total_time 724\n",
      "episode 9729, reward 1230.0, memory_length 2000, epsilon 0.007715607912847108 total_time 726\n",
      "episode 9739, reward 1322.0, memory_length 2000, epsilon 0.007677126157840679 total_time 722\n",
      "episode 9749, reward 1493.0, memory_length 2000, epsilon 0.007638836331388046 total_time 722\n",
      "episode 9759, reward 1426.0, memory_length 2000, epsilon 0.007600737476241555 total_time 721\n",
      "episode 9769, reward 1004.0, memory_length 2000, epsilon 0.007562828639927842 total_time 728\n",
      "episode 9779, reward 1034.0, memory_length 2000, epsilon 0.007525108874724024 total_time 722\n",
      "episode 9789, reward 1120.0, memory_length 2000, epsilon 0.0074875772376340076 total_time 721\n",
      "episode 9799, reward 1057.0, memory_length 2000, epsilon 0.007450232790364911 total_time 721\n",
      "Saving Model 9800\n",
      "episode 9809, reward 969.0, memory_length 2000, epsilon 0.0074130745993036 total_time 726\n",
      "episode 9819, reward 599.0, memory_length 2000, epsilon 0.007376101735493376 total_time 728\n",
      "episode 9829, reward 958.0, memory_length 2000, epsilon 0.007339313274610711 total_time 721\n",
      "episode 9839, reward 688.0, memory_length 2000, epsilon 0.007302708296942168 total_time 721\n",
      "episode 9849, reward 505.0, memory_length 2000, epsilon 0.007266285887361399 total_time 727\n",
      "episode 9859, reward 322.0, memory_length 2000, epsilon 0.007230045135306265 total_time 733\n",
      "episode 9869, reward 378.0, memory_length 2000, epsilon 0.0071939851347560795 total_time 729\n",
      "episode 9879, reward 261.0, memory_length 2000, epsilon 0.007158104984208951 total_time 729\n",
      "episode 9889, reward 709.0, memory_length 2000, epsilon 0.007122403786659245 total_time 724\n",
      "episode 9899, reward 792.0, memory_length 2000, epsilon 0.007086880649575158 total_time 729\n",
      "Saving Model 9900\n",
      "episode 9909, reward 1086.0, memory_length 2000, epsilon 0.0070515346848764255 total_time 726\n",
      "episode 9919, reward 989.0, memory_length 2000, epsilon 0.007016365008912083 total_time 722\n",
      "episode 9929, reward 1155.0, memory_length 2000, epsilon 0.006981370742438399 total_time 723\n",
      "episode 9939, reward 844.0, memory_length 2000, epsilon 0.006946551010596889 total_time 724\n",
      "episode 9949, reward 971.0, memory_length 2000, epsilon 0.006911904942892444 total_time 722\n",
      "episode 9959, reward 683.0, memory_length 2000, epsilon 0.006877431673171567 total_time 731\n",
      "episode 9969, reward 959.0, memory_length 2000, epsilon 0.006843130339600718 total_time 728\n",
      "episode 9979, reward 633.0, memory_length 2000, epsilon 0.006809000084644768 total_time 723\n",
      "episode 9989, reward 328.0, memory_length 2000, epsilon 0.006775040055045574 total_time 721\n",
      "episode 9999, reward 1006.0, memory_length 2000, epsilon 0.006741249401800625 total_time 724\n",
      "Saving Model 10000\n",
      "episode 10009, reward 647.0, memory_length 2000, epsilon 0.006707627280141827 total_time 722\n",
      "episode 10019, reward 906.0, memory_length 2000, epsilon 0.0066741728495143884 total_time 726\n",
      "episode 10029, reward 1198.0, memory_length 2000, epsilon 0.006640885273555802 total_time 727\n",
      "episode 10039, reward 1427.0, memory_length 2000, epsilon 0.006607763720074933 total_time 728\n",
      "episode 10049, reward 1183.0, memory_length 2000, epsilon 0.006574807361031221 total_time 721\n",
      "episode 10059, reward 772.0, memory_length 2000, epsilon 0.006542015372513967 total_time 724\n",
      "episode 10069, reward 800.0, memory_length 2000, epsilon 0.0065093869347217625 total_time 722\n",
      "episode 10079, reward 1142.0, memory_length 2000, epsilon 0.006476921231941956 total_time 722\n",
      "episode 10089, reward 1219.0, memory_length 2000, epsilon 0.006444617452530289 total_time 721\n",
      "episode 10099, reward 927.0, memory_length 2000, epsilon 0.006412474788890592 total_time 729\n",
      "Saving Model 10100\n",
      "episode 10109, reward 931.0, memory_length 2000, epsilon 0.006380492437454601 total_time 721\n",
      "episode 10119, reward 947.0, memory_length 2000, epsilon 0.0063486695986618635 total_time 725\n",
      "episode 10129, reward 512.0, memory_length 2000, epsilon 0.006317005476939753 total_time 722\n",
      "episode 10139, reward 1029.0, memory_length 2000, epsilon 0.006285499280683576 total_time 723\n",
      "episode 10149, reward 1399.0, memory_length 2000, epsilon 0.006254150222236782 total_time 721\n",
      "episode 10159, reward 865.0, memory_length 2000, epsilon 0.006222957517871287 total_time 727\n",
      "episode 10169, reward 844.0, memory_length 2000, epsilon 0.00619192038776785 total_time 724\n",
      "episode 10179, reward 1118.0, memory_length 2000, epsilon 0.006161038055996604 total_time 725\n",
      "episode 10189, reward 1204.0, memory_length 2000, epsilon 0.006130309750497645 total_time 724\n",
      "episode 10199, reward 833.0, memory_length 2000, epsilon 0.006099734703061736 total_time 728\n",
      "Saving Model 10200\n",
      "episode 10209, reward 1174.0, memory_length 2000, epsilon 0.0060693121493110985 total_time 721\n",
      "episode 10219, reward 1057.0, memory_length 2000, epsilon 0.0060390413286803045 total_time 721\n",
      "episode 10229, reward 863.0, memory_length 2000, epsilon 0.006008921484397255 total_time 722\n",
      "episode 10239, reward 1426.0, memory_length 2000, epsilon 0.005978951863464286 total_time 721\n",
      "episode 10249, reward 1030.0, memory_length 2000, epsilon 0.0059491317166393085 total_time 721\n",
      "episode 10259, reward 872.0, memory_length 2000, epsilon 0.005919460298417096 total_time 722\n",
      "episode 10269, reward 1304.0, memory_length 2000, epsilon 0.005889936867010651 total_time 722\n",
      "episode 10279, reward 1171.0, memory_length 2000, epsilon 0.005860560684332649 total_time 727\n",
      "episode 10289, reward 1194.0, memory_length 2000, epsilon 0.005831331015976992 total_time 726\n",
      "episode 10299, reward 910.0, memory_length 2000, epsilon 0.005802247131200451 total_time 727\n",
      "Saving Model 10300\n",
      "episode 10309, reward 988.0, memory_length 2000, epsilon 0.005773308302904384 total_time 724\n",
      "episode 10319, reward 1171.0, memory_length 2000, epsilon 0.005744513807616589 total_time 727\n",
      "episode 10329, reward 1042.0, memory_length 2000, epsilon 0.0057158629254731785 total_time 724\n",
      "episode 10339, reward 982.0, memory_length 2000, epsilon 0.005687354940200605 total_time 727\n",
      "episode 10349, reward 1182.0, memory_length 2000, epsilon 0.005658989139097755 total_time 723\n",
      "episode 10359, reward 1402.0, memory_length 2000, epsilon 0.005630764813018121 total_time 724\n",
      "episode 10369, reward 1160.0, memory_length 2000, epsilon 0.005602681256352081 total_time 722\n",
      "episode 10379, reward 1464.0, memory_length 2000, epsilon 0.005574737767009257 total_time 726\n",
      "episode 10389, reward 1030.0, memory_length 2000, epsilon 0.005546933646400958 total_time 721\n",
      "episode 10399, reward 917.0, memory_length 2000, epsilon 0.00551926819942272 total_time 731\n",
      "Saving Model 10400\n",
      "episode 10409, reward 847.0, memory_length 2000, epsilon 0.0054917407344369324 total_time 727\n",
      "episode 10419, reward 1232.0, memory_length 2000, epsilon 0.005464350563255534 total_time 722\n",
      "episode 10429, reward 1304.0, memory_length 2000, epsilon 0.00543709700112282 total_time 722\n",
      "episode 10439, reward 1560.0, memory_length 2000, epsilon 0.0054099793666983155 total_time 723\n",
      "episode 10449, reward 1201.0, memory_length 2000, epsilon 0.00538299698203975 total_time 721\n",
      "episode 10459, reward 1167.0, memory_length 2000, epsilon 0.005356149172586098 total_time 726\n",
      "episode 10469, reward 868.0, memory_length 2000, epsilon 0.005329435267140728 total_time 721\n",
      "episode 10479, reward 1082.0, memory_length 2000, epsilon 0.005302854597854607 total_time 725\n",
      "episode 10489, reward 1583.0, memory_length 2000, epsilon 0.005276406500209628 total_time 722\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 10499, reward 1426.0, memory_length 2000, epsilon 0.005250090313001966 total_time 721\n",
      "Saving Model 10500\n",
      "episode 10509, reward 867.0, memory_length 2000, epsilon 0.005223905378325572 total_time 723\n",
      "episode 10519, reward 1372.0, memory_length 2000, epsilon 0.005197851041555715 total_time 721\n",
      "episode 10529, reward 1243.0, memory_length 2000, epsilon 0.005171926651332619 total_time 727\n",
      "episode 10539, reward 1416.0, memory_length 2000, epsilon 0.005146131559545177 total_time 723\n",
      "episode 10549, reward 1266.0, memory_length 2000, epsilon 0.005120465121314752 total_time 726\n",
      "episode 10559, reward 1273.0, memory_length 2000, epsilon 0.005094926694979046 total_time 721\n",
      "episode 10569, reward 1097.0, memory_length 2000, epsilon 0.00506951564207608 total_time 722\n",
      "episode 10579, reward 1183.0, memory_length 2000, epsilon 0.005044231327328204 total_time 721\n",
      "episode 10589, reward 1218.0, memory_length 2000, epsilon 0.005019073118626231 total_time 723\n",
      "episode 10599, reward 1573.0, memory_length 2000, epsilon 0.004994040387013635 total_time 724\n",
      "Saving Model 10600\n",
      "episode 10609, reward 1144.0, memory_length 2000, epsilon 0.00496913250667082 total_time 727\n",
      "episode 10619, reward 1370.0, memory_length 2000, epsilon 0.004944348854899481 total_time 725\n",
      "episode 10629, reward 1543.0, memory_length 2000, epsilon 0.004919688812107034 total_time 721\n",
      "episode 10639, reward 1547.0, memory_length 2000, epsilon 0.004895151761791122 total_time 722\n",
      "episode 10649, reward 1042.0, memory_length 2000, epsilon 0.004870737090524206 total_time 724\n",
      "episode 10659, reward 1337.0, memory_length 2000, epsilon 0.004846444187938244 total_time 728\n",
      "episode 10669, reward 1381.0, memory_length 2000, epsilon 0.0048222724467093985 total_time 721\n",
      "episode 10679, reward 1237.0, memory_length 2000, epsilon 0.004798221262542881 total_time 721\n",
      "episode 10689, reward 863.0, memory_length 2000, epsilon 0.004774290034157834 total_time 722\n",
      "episode 10699, reward 980.0, memory_length 2000, epsilon 0.0047504781632723035 total_time 722\n",
      "Saving Model 10700\n",
      "episode 10709, reward 875.0, memory_length 2000, epsilon 0.004726785054588276 total_time 725\n",
      "episode 10719, reward 1217.0, memory_length 2000, epsilon 0.004703210115776799 total_time 734\n",
      "episode 10729, reward 1176.0, memory_length 2000, epsilon 0.004679752757463171 total_time 726\n",
      "episode 10739, reward 942.0, memory_length 2000, epsilon 0.004656412393212222 total_time 726\n",
      "episode 10749, reward 1151.0, memory_length 2000, epsilon 0.004633188439513625 total_time 722\n",
      "episode 10759, reward 1471.0, memory_length 2000, epsilon 0.004610080315767327 total_time 721\n",
      "episode 10769, reward 1407.0, memory_length 2000, epsilon 0.004587087444269032 total_time 723\n",
      "episode 10779, reward 1423.0, memory_length 2000, epsilon 0.004564209250195755 total_time 727\n",
      "episode 10789, reward 1183.0, memory_length 2000, epsilon 0.004541445161591452 total_time 721\n",
      "episode 10799, reward 994.0, memory_length 2000, epsilon 0.004518794609352723 total_time 721\n",
      "Saving Model 10800\n",
      "episode 10809, reward 1460.0, memory_length 2000, epsilon 0.004496257027214578 total_time 725\n",
      "episode 10819, reward 1453.0, memory_length 2000, epsilon 0.004473831851736298 total_time 721\n",
      "episode 10829, reward 1354.0, memory_length 2000, epsilon 0.0044515185222873226 total_time 721\n",
      "episode 10839, reward 1439.0, memory_length 2000, epsilon 0.004429316481033255 total_time 722\n",
      "episode 10849, reward 1183.0, memory_length 2000, epsilon 0.004407225172921907 total_time 721\n",
      "episode 10859, reward 1129.0, memory_length 2000, epsilon 0.004385244045669425 total_time 721\n",
      "episode 10869, reward 1302.0, memory_length 2000, epsilon 0.004363372549746483 total_time 726\n",
      "episode 10879, reward 1281.0, memory_length 2000, epsilon 0.004341610138364544 total_time 723\n",
      "episode 10889, reward 1477.0, memory_length 2000, epsilon 0.00431995626746219 total_time 727\n",
      "episode 10899, reward 994.0, memory_length 2000, epsilon 0.004298410395691517 total_time 721\n",
      "Saving Model 10900\n",
      "episode 10909, reward 1280.0, memory_length 2000, epsilon 0.004276971984404615 total_time 725\n",
      "episode 10919, reward 1362.0, memory_length 2000, epsilon 0.0042556404976400826 total_time 723\n",
      "episode 10929, reward 975.0, memory_length 2000, epsilon 0.004234415402109639 total_time 723\n",
      "episode 10939, reward 1353.0, memory_length 2000, epsilon 0.004213296167184791 total_time 732\n",
      "episode 10949, reward 1165.0, memory_length 2000, epsilon 0.004192282264883566 total_time 721\n",
      "episode 10959, reward 1149.0, memory_length 2000, epsilon 0.00417137316985731 total_time 726\n",
      "episode 10969, reward 1309.0, memory_length 2000, epsilon 0.004150568359377561 total_time 730\n",
      "episode 10979, reward 1392.0, memory_length 2000, epsilon 0.004129867313322968 total_time 726\n",
      "episode 10989, reward 1417.0, memory_length 2000, epsilon 0.004109269514166309 total_time 721\n",
      "episode 10999, reward 1065.0, memory_length 2000, epsilon 0.004088774446961528 total_time 723\n",
      "Saving Model 11000\n",
      "episode 11009, reward 1012.0, memory_length 2000, epsilon 0.0040683815993308795 total_time 721\n",
      "episode 11019, reward 1128.0, memory_length 2000, epsilon 0.004048090461452108 total_time 723\n",
      "episode 11029, reward 1335.0, memory_length 2000, epsilon 0.004027900526045712 total_time 723\n",
      "episode 11039, reward 1444.0, memory_length 2000, epsilon 0.004007811288362254 total_time 721\n",
      "episode 11049, reward 898.0, memory_length 2000, epsilon 0.0039878222461697446 total_time 724\n",
      "episode 11059, reward 1671.0, memory_length 2000, epsilon 0.003967932899741086 total_time 726\n",
      "episode 11069, reward 1001.0, memory_length 2000, epsilon 0.003948142751841587 total_time 725\n",
      "episode 11079, reward 1084.0, memory_length 2000, epsilon 0.003928451307716517 total_time 721\n",
      "episode 11089, reward 1294.0, memory_length 2000, epsilon 0.003908858075078747 total_time 724\n",
      "episode 11099, reward 1129.0, memory_length 2000, epsilon 0.0038893625640964405 total_time 721\n",
      "Saving Model 11100\n",
      "episode 11109, reward 1302.0, memory_length 2000, epsilon 0.0038699642873808076 total_time 726\n",
      "episode 11119, reward 1168.0, memory_length 2000, epsilon 0.0038506627599739197 total_time 724\n",
      "episode 11129, reward 1623.0, memory_length 2000, epsilon 0.0038314574993365868 total_time 723\n",
      "episode 11139, reward 1441.0, memory_length 2000, epsilon 0.0038123480253362927 total_time 727\n",
      "episode 11149, reward 1282.0, memory_length 2000, epsilon 0.0037933338602351885 total_time 721\n",
      "episode 11159, reward 1510.0, memory_length 2000, epsilon 0.003774414528678163 total_time 724\n",
      "episode 11169, reward 1470.0, memory_length 2000, epsilon 0.003755589557680939 total_time 723\n",
      "episode 11179, reward 1140.0, memory_length 2000, epsilon 0.003736858476618261 total_time 726\n",
      "episode 11189, reward 1221.0, memory_length 2000, epsilon 0.0037182208172121265 total_time 726\n",
      "episode 11199, reward 874.0, memory_length 2000, epsilon 0.003699676113520079 total_time 727\n",
      "Saving Model 11200\n",
      "episode 11209, reward 988.0, memory_length 2000, epsilon 0.003681223901923562 total_time 733\n",
      "episode 11219, reward 1112.0, memory_length 2000, epsilon 0.0036628637211163235 total_time 728\n",
      "episode 11229, reward 913.0, memory_length 2000, epsilon 0.0036445951120928836 total_time 721\n",
      "episode 11239, reward 823.0, memory_length 2000, epsilon 0.0036264176181370726 total_time 721\n",
      "episode 11249, reward 1262.0, memory_length 2000, epsilon 0.003608330784810591 total_time 725\n",
      "episode 11259, reward 1073.0, memory_length 2000, epsilon 0.0035903341599416634 total_time 725\n",
      "episode 11269, reward 1079.0, memory_length 2000, epsilon 0.0035724272936137314 total_time 722\n",
      "episode 11279, reward 1444.0, memory_length 2000, epsilon 0.003554609738154204 total_time 721\n",
      "episode 11289, reward 1367.0, memory_length 2000, epsilon 0.003536881048123266 total_time 722\n",
      "episode 11299, reward 1048.0, memory_length 2000, epsilon 0.003519240780302744 total_time 730\n",
      "Saving Model 11300\n",
      "episode 11309, reward 1372.0, memory_length 2000, epsilon 0.00350168849368502 total_time 721\n",
      "episode 11319, reward 935.0, memory_length 2000, epsilon 0.003484223749462022 total_time 731\n",
      "episode 11329, reward 1604.0, memory_length 2000, epsilon 0.00346684611101423 total_time 725\n",
      "episode 11339, reward 1449.0, memory_length 2000, epsilon 0.0034495551438997784 total_time 729\n",
      "episode 11349, reward 1369.0, memory_length 2000, epsilon 0.003432350415843589 total_time 727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 11359, reward 1244.0, memory_length 2000, epsilon 0.003415231496726564 total_time 725\n",
      "episode 11369, reward 1182.0, memory_length 2000, epsilon 0.0033981979585748336 total_time 723\n",
      "episode 11379, reward 1367.0, memory_length 2000, epsilon 0.0033812493755490574 total_time 722\n",
      "episode 11389, reward 785.0, memory_length 2000, epsilon 0.003364385323933774 total_time 725\n",
      "episode 11399, reward 1221.0, memory_length 2000, epsilon 0.0033476053821268207 total_time 726\n",
      "Saving Model 11400\n",
      "episode 11409, reward 946.0, memory_length 2000, epsilon 0.0033309091306287742 total_time 727\n",
      "episode 11419, reward 1282.0, memory_length 2000, epsilon 0.0033142961520324795 total_time 721\n",
      "episode 11429, reward 1007.0, memory_length 2000, epsilon 0.0032977660310126045 total_time 722\n",
      "episode 11439, reward 1204.0, memory_length 2000, epsilon 0.0032813183543152643 total_time 724\n",
      "episode 11449, reward 1192.0, memory_length 2000, epsilon 0.003264952710747684 total_time 721\n",
      "episode 11459, reward 1210.0, memory_length 2000, epsilon 0.003248668691167922 total_time 721\n",
      "episode 11469, reward 984.0, memory_length 2000, epsilon 0.0032324658884746406 total_time 723\n",
      "episode 11479, reward 1003.0, memory_length 2000, epsilon 0.0032163438975969265 total_time 721\n",
      "episode 11489, reward 1361.0, memory_length 2000, epsilon 0.0032003023154841726 total_time 725\n",
      "episode 11499, reward 913.0, memory_length 2000, epsilon 0.0031843407410959887 total_time 721\n",
      "Saving Model 11500\n",
      "episode 11509, reward 1444.0, memory_length 2000, epsilon 0.0031684587753921835 total_time 721\n",
      "episode 11519, reward 1296.0, memory_length 2000, epsilon 0.003152656021322787 total_time 729\n",
      "episode 11529, reward 1226.0, memory_length 2000, epsilon 0.003136932083818124 total_time 725\n",
      "episode 11539, reward 1002.0, memory_length 2000, epsilon 0.0031212865697789398 total_time 723\n",
      "episode 11549, reward 1420.0, memory_length 2000, epsilon 0.003105719088066566 total_time 724\n",
      "episode 11559, reward 943.0, memory_length 2000, epsilon 0.0030902292494931483 total_time 724\n",
      "episode 11569, reward 1104.0, memory_length 2000, epsilon 0.0030748166668119197 total_time 726\n",
      "episode 11579, reward 1052.0, memory_length 2000, epsilon 0.003059480954707508 total_time 731\n",
      "episode 11589, reward 923.0, memory_length 2000, epsilon 0.0030442217297863123 total_time 728\n",
      "episode 11599, reward 1071.0, memory_length 2000, epsilon 0.0030290386105669147 total_time 729\n",
      "Saving Model 11600\n",
      "episode 11609, reward 787.0, memory_length 2000, epsilon 0.0030139312174705443 total_time 730\n",
      "episode 11619, reward 1448.0, memory_length 2000, epsilon 0.002998899172811586 total_time 722\n",
      "episode 11629, reward 890.0, memory_length 2000, epsilon 0.0029839421007881407 total_time 722\n",
      "episode 11639, reward 1376.0, memory_length 2000, epsilon 0.002969059627472626 total_time 722\n",
      "episode 11649, reward 1156.0, memory_length 2000, epsilon 0.00295425138080244 total_time 721\n",
      "episode 11659, reward 886.0, memory_length 2000, epsilon 0.002939516990570641 total_time 721\n",
      "episode 11669, reward 1300.0, memory_length 2000, epsilon 0.0029248560884167062 total_time 721\n",
      "episode 11679, reward 1331.0, memory_length 2000, epsilon 0.0029102683078173187 total_time 722\n",
      "episode 11689, reward 993.0, memory_length 2000, epsilon 0.0028957532840772028 total_time 723\n",
      "episode 11699, reward 872.0, memory_length 2000, epsilon 0.0028813106543200094 total_time 722\n",
      "Saving Model 11700\n",
      "episode 11709, reward 1014.0, memory_length 2000, epsilon 0.002866940057479243 total_time 726\n",
      "episode 11719, reward 886.0, memory_length 2000, epsilon 0.0028526411342892325 total_time 721\n",
      "episode 11729, reward 1507.0, memory_length 2000, epsilon 0.0028384135272761526 total_time 721\n",
      "episode 11739, reward 1192.0, memory_length 2000, epsilon 0.0028242568807490907 total_time 721\n",
      "episode 11749, reward 885.0, memory_length 2000, epsilon 0.002810170840791145 total_time 723\n",
      "episode 11759, reward 980.0, memory_length 2000, epsilon 0.002796155055250582 total_time 722\n",
      "episode 11769, reward 1151.0, memory_length 2000, epsilon 0.0027822091737320334 total_time 722\n",
      "episode 11779, reward 1218.0, memory_length 2000, epsilon 0.0027683328475877353 total_time 723\n",
      "episode 11789, reward 2072.0, memory_length 2000, epsilon 0.0027545257299088103 total_time 725\n",
      "episode 11799, reward 1205.0, memory_length 2000, epsilon 0.002740787475516599 total_time 722\n",
      "Saving Model 11800\n",
      "episode 11809, reward 1236.0, memory_length 2000, epsilon 0.002727117740954022 total_time 723\n",
      "episode 11819, reward 1119.0, memory_length 2000, epsilon 0.0027135161844770088 total_time 723\n",
      "episode 11829, reward 1516.0, memory_length 2000, epsilon 0.0026999824660459367 total_time 721\n",
      "episode 11839, reward 1154.0, memory_length 2000, epsilon 0.0026865162473171398 total_time 725\n",
      "episode 11849, reward 1159.0, memory_length 2000, epsilon 0.0026731171916344492 total_time 724\n",
      "episode 11859, reward 1408.0, memory_length 2000, epsilon 0.0026597849640207735 total_time 721\n",
      "episode 11869, reward 1528.0, memory_length 2000, epsilon 0.00264651923116973 total_time 724\n",
      "episode 11879, reward 1390.0, memory_length 2000, epsilon 0.002633319661437305 total_time 721\n",
      "episode 11889, reward 1423.0, memory_length 2000, epsilon 0.0026201859248335653 total_time 727\n",
      "episode 11899, reward 1411.0, memory_length 2000, epsilon 0.0026071176930144175 total_time 724\n",
      "Saving Model 11900\n",
      "episode 11909, reward 902.0, memory_length 2000, epsilon 0.0025941146392733823 total_time 725\n",
      "episode 11919, reward 1072.0, memory_length 2000, epsilon 0.002581176438533439 total_time 727\n",
      "episode 11929, reward 1106.0, memory_length 2000, epsilon 0.0025683027673388957 total_time 722\n",
      "episode 11939, reward 1213.0, memory_length 2000, epsilon 0.0025554933038473013 total_time 724\n",
      "episode 11949, reward 1011.0, memory_length 2000, epsilon 0.0025427477278214023 total_time 723\n",
      "episode 11959, reward 1484.0, memory_length 2000, epsilon 0.0025300657206211337 total_time 722\n",
      "episode 11969, reward 1153.0, memory_length 2000, epsilon 0.0025174469651956547 total_time 727\n",
      "episode 11979, reward 1246.0, memory_length 2000, epsilon 0.002504891146075421 total_time 721\n",
      "episode 11989, reward 1403.0, memory_length 2000, epsilon 0.0024923979493643037 total_time 722\n",
      "episode 11999, reward 1093.0, memory_length 2000, epsilon 0.0024799670627317335 total_time 730\n",
      "Saving Model 12000\n",
      "episode 12009, reward 1397.0, memory_length 2000, epsilon 0.002467598175404897 total_time 725\n",
      "episode 12019, reward 1465.0, memory_length 2000, epsilon 0.002455290978160966 total_time 724\n",
      "episode 12029, reward 1435.0, memory_length 2000, epsilon 0.002443045163319369 total_time 721\n",
      "episode 12039, reward 1385.0, memory_length 2000, epsilon 0.0024308604247340973 total_time 722\n",
      "episode 12049, reward 1278.0, memory_length 2000, epsilon 0.002418736457786051 total_time 729\n",
      "episode 12059, reward 1166.0, memory_length 2000, epsilon 0.002406672959375423 total_time 728\n",
      "episode 12069, reward 1200.0, memory_length 2000, epsilon 0.00239466962791413 total_time 732\n",
      "episode 12079, reward 1210.0, memory_length 2000, epsilon 0.002382726163318257 total_time 721\n",
      "episode 12089, reward 1090.0, memory_length 2000, epsilon 0.0023708422670005672 total_time 727\n",
      "episode 12099, reward 1319.0, memory_length 2000, epsilon 0.0023590176418630334 total_time 728\n",
      "Saving Model 12100\n",
      "episode 12109, reward 985.0, memory_length 2000, epsilon 0.002347251992289413 total_time 721\n",
      "episode 12119, reward 1314.0, memory_length 2000, epsilon 0.0023355450241378515 total_time 729\n",
      "episode 12129, reward 848.0, memory_length 2000, epsilon 0.002323896444733537 total_time 725\n",
      "episode 12139, reward 1320.0, memory_length 2000, epsilon 0.002312305962861375 total_time 726\n",
      "episode 12149, reward 851.0, memory_length 2000, epsilon 0.002300773288758719 total_time 728\n",
      "episode 12159, reward 1484.0, memory_length 2000, epsilon 0.0022892981341081143 total_time 722\n",
      "episode 12169, reward 1214.0, memory_length 2000, epsilon 0.002277880212030097 total_time 722\n",
      "episode 12179, reward 1069.0, memory_length 2000, epsilon 0.00226651923707602 total_time 724\n",
      "episode 12189, reward 1291.0, memory_length 2000, epsilon 0.002255214925220918 total_time 721\n",
      "episode 12199, reward 1138.0, memory_length 2000, epsilon 0.0022439669938564056 total_time 721\n",
      "Saving Model 12200\n",
      "episode 12209, reward 1249.0, memory_length 2000, epsilon 0.0022327751617836128 total_time 724\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 12219, reward 889.0, memory_length 2000, epsilon 0.002221639149206155 total_time 724\n",
      "episode 12229, reward 1316.0, memory_length 2000, epsilon 0.002210558677723136 total_time 725\n",
      "episode 12239, reward 1051.0, memory_length 2000, epsilon 0.0021995334703221957 total_time 733\n",
      "episode 12249, reward 1038.0, memory_length 2000, epsilon 0.002188563251372572 total_time 723\n",
      "episode 12259, reward 753.0, memory_length 2000, epsilon 0.002177647746618221 total_time 726\n",
      "episode 12269, reward 1348.0, memory_length 2000, epsilon 0.0021667866831709542 total_time 724\n",
      "episode 12279, reward 1069.0, memory_length 2000, epsilon 0.00215597978950362 total_time 724\n",
      "episode 12289, reward 1035.0, memory_length 2000, epsilon 0.0021452267954433146 total_time 729\n",
      "episode 12299, reward 1323.0, memory_length 2000, epsilon 0.002134527432164626 total_time 729\n",
      "Saving Model 12300\n",
      "episode 12309, reward 1029.0, memory_length 2000, epsilon 0.002123881432182913 total_time 723\n",
      "episode 12319, reward 1261.0, memory_length 2000, epsilon 0.0021132885293476253 total_time 727\n",
      "episode 12329, reward 998.0, memory_length 2000, epsilon 0.002102748458835638 total_time 722\n",
      "episode 12339, reward 1330.0, memory_length 2000, epsilon 0.0020922609571446408 total_time 724\n",
      "episode 12349, reward 967.0, memory_length 2000, epsilon 0.0020818257620865434 total_time 721\n",
      "episode 12359, reward 1030.0, memory_length 2000, epsilon 0.0020714426127809273 total_time 721\n",
      "episode 12369, reward 1325.0, memory_length 2000, epsilon 0.0020611112496485176 total_time 734\n",
      "episode 12379, reward 1448.0, memory_length 2000, epsilon 0.0020508314144046997 total_time 722\n",
      "episode 12389, reward 1367.0, memory_length 2000, epsilon 0.002040602850053054 total_time 722\n",
      "episode 12399, reward 1192.0, memory_length 2000, epsilon 0.0020304253008789426 total_time 721\n",
      "Saving Model 12400\n",
      "episode 12409, reward 1182.0, memory_length 2000, epsilon 0.0020202985124431047 total_time 723\n",
      "episode 12419, reward 1214.0, memory_length 2000, epsilon 0.0020102222315753018 total_time 722\n",
      "episode 12429, reward 1285.0, memory_length 2000, epsilon 0.002000196206367988 total_time 724\n",
      "episode 12439, reward 1311.0, memory_length 2000, epsilon 0.00199022018617001 total_time 726\n",
      "episode 12449, reward 1303.0, memory_length 2000, epsilon 0.0019802939215803434 total_time 724\n",
      "episode 12459, reward 1543.0, memory_length 2000, epsilon 0.001970417164441857 total_time 721\n",
      "episode 12469, reward 1237.0, memory_length 2000, epsilon 0.0019605896678351075 total_time 721\n",
      "episode 12479, reward 1034.0, memory_length 2000, epsilon 0.0019508111860721666 total_time 722\n",
      "episode 12489, reward 1281.0, memory_length 2000, epsilon 0.0019410814746904836 total_time 723\n",
      "episode 12499, reward 1340.0, memory_length 2000, epsilon 0.001931400290446766 total_time 722\n",
      "Saving Model 12500\n",
      "episode 12509, reward 1534.0, memory_length 2000, epsilon 0.0019217673913109036 total_time 730\n",
      "episode 12519, reward 1335.0, memory_length 2000, epsilon 0.0019121825364599159 total_time 723\n",
      "episode 12529, reward 1186.0, memory_length 2000, epsilon 0.001902645486271933 total_time 724\n",
      "episode 12539, reward 1057.0, memory_length 2000, epsilon 0.0018931560023202028 total_time 721\n",
      "episode 12549, reward 805.0, memory_length 2000, epsilon 0.0018837138473671326 total_time 721\n",
      "episode 12559, reward 1388.0, memory_length 2000, epsilon 0.0018743187853583552 total_time 725\n",
      "episode 12569, reward 1396.0, memory_length 2000, epsilon 0.001864970581416834 total_time 727\n",
      "episode 12579, reward 1376.0, memory_length 2000, epsilon 0.0018556690018369825 total_time 722\n",
      "episode 12589, reward 1511.0, memory_length 2000, epsilon 0.0018464138140788264 total_time 722\n",
      "episode 12599, reward 1488.0, memory_length 2000, epsilon 0.0018372047867621895 total_time 723\n",
      "Saving Model 12600\n",
      "episode 12609, reward 1204.0, memory_length 2000, epsilon 0.0018280416896609096 total_time 724\n",
      "episode 12619, reward 1515.0, memory_length 2000, epsilon 0.0018189242936970818 total_time 732\n",
      "episode 12629, reward 944.0, memory_length 2000, epsilon 0.0018098523709353322 total_time 722\n",
      "episode 12639, reward 1178.0, memory_length 2000, epsilon 0.0018008256945771176 total_time 722\n",
      "episode 12649, reward 1176.0, memory_length 2000, epsilon 0.001791844038955062 total_time 726\n",
      "episode 12659, reward 1097.0, memory_length 2000, epsilon 0.0017829071795273058 total_time 731\n",
      "episode 12669, reward 1265.0, memory_length 2000, epsilon 0.0017740148928718975 total_time 728\n",
      "episode 12679, reward 1099.0, memory_length 2000, epsilon 0.0017651669566812074 total_time 727\n",
      "episode 12689, reward 1331.0, memory_length 2000, epsilon 0.0017563631497563707 total_time 722\n",
      "episode 12699, reward 1246.0, memory_length 2000, epsilon 0.0017476032520017547 total_time 721\n",
      "Saving Model 12700\n",
      "episode 12709, reward 1314.0, memory_length 2000, epsilon 0.0017388870444194602 total_time 729\n",
      "episode 12719, reward 1351.0, memory_length 2000, epsilon 0.001730214309103843 total_time 727\n",
      "episode 12729, reward 1073.0, memory_length 2000, epsilon 0.0017215848292360676 total_time 725\n",
      "episode 12739, reward 565.0, memory_length 2000, epsilon 0.0017129983890786904 total_time 724\n",
      "episode 12749, reward 1354.0, memory_length 2000, epsilon 0.001704454773970259 total_time 721\n",
      "episode 12759, reward 1556.0, memory_length 2000, epsilon 0.0016959537703199504 total_time 722\n",
      "episode 12769, reward 1302.0, memory_length 2000, epsilon 0.0016874951656022312 total_time 726\n",
      "episode 12779, reward 974.0, memory_length 2000, epsilon 0.001679078748351542 total_time 725\n",
      "episode 12789, reward 1057.0, memory_length 2000, epsilon 0.001670704308157014 total_time 721\n",
      "episode 12799, reward 1372.0, memory_length 2000, epsilon 0.0016623716356572059 total_time 721\n",
      "Saving Model 12800\n",
      "episode 12809, reward 1167.0, memory_length 2000, epsilon 0.0016540805225348694 total_time 726\n",
      "episode 12819, reward 1237.0, memory_length 2000, epsilon 0.0016458307615117482 total_time 721\n",
      "episode 12829, reward 1312.0, memory_length 2000, epsilon 0.001637622146343385 total_time 724\n",
      "episode 12839, reward 1164.0, memory_length 2000, epsilon 0.001629454471813973 total_time 723\n",
      "episode 12849, reward 1048.0, memory_length 2000, epsilon 0.0016213275337312245 total_time 721\n",
      "episode 12859, reward 1262.0, memory_length 2000, epsilon 0.001613241128921263 total_time 734\n",
      "episode 12869, reward 1455.0, memory_length 2000, epsilon 0.0016051950552235475 total_time 726\n",
      "episode 12879, reward 1453.0, memory_length 2000, epsilon 0.0015971891114858168 total_time 721\n",
      "episode 12889, reward 1102.0, memory_length 2000, epsilon 0.0015892230975590588 total_time 721\n",
      "episode 12899, reward 1084.0, memory_length 2000, epsilon 0.0015812968142925135 total_time 721\n",
      "Saving Model 12900\n",
      "episode 12909, reward 1201.0, memory_length 2000, epsilon 0.0015734100635286844 total_time 721\n",
      "episode 12919, reward 1194.0, memory_length 2000, epsilon 0.0015655626480983924 total_time 726\n",
      "episode 12929, reward 1012.0, memory_length 2000, epsilon 0.0015577543718158424 total_time 721\n",
      "episode 12939, reward 1325.0, memory_length 2000, epsilon 0.001549985039473721 total_time 725\n",
      "episode 12949, reward 1649.0, memory_length 2000, epsilon 0.0015422544568383146 total_time 725\n",
      "episode 12959, reward 1384.0, memory_length 2000, epsilon 0.0015345624306446553 total_time 724\n",
      "episode 12969, reward 1183.0, memory_length 2000, epsilon 0.0015269087685916875 total_time 730\n",
      "episode 12979, reward 1012.0, memory_length 2000, epsilon 0.0015192932793374593 total_time 721\n",
      "episode 12989, reward 1462.0, memory_length 2000, epsilon 0.001511715772494346 total_time 730\n",
      "episode 12999, reward 1300.0, memory_length 2000, epsilon 0.0015041760586242804 total_time 721\n",
      "Saving Model 13000\n",
      "episode 13009, reward 1096.0, memory_length 2000, epsilon 0.0014966739492340226 total_time 724\n",
      "episode 13019, reward 1302.0, memory_length 2000, epsilon 0.0014892092567704478 total_time 726\n",
      "episode 13029, reward 1232.0, memory_length 2000, epsilon 0.0014817817946158553 total_time 722\n",
      "episode 13039, reward 1417.0, memory_length 2000, epsilon 0.0014743913770833043 total_time 721\n",
      "episode 13049, reward 1417.0, memory_length 2000, epsilon 0.0014670378194119717 total_time 721\n",
      "episode 13059, reward 777.0, memory_length 2000, epsilon 0.0014597209377625313 total_time 723\n",
      "episode 13069, reward 1538.0, memory_length 2000, epsilon 0.0014524405492125636 total_time 722\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 13079, reward 1391.0, memory_length 2000, epsilon 0.0014451964717519742 total_time 728\n",
      "episode 13089, reward 1492.0, memory_length 2000, epsilon 0.0014379885242784493 total_time 724\n",
      "episode 13099, reward 1196.0, memory_length 2000, epsilon 0.0014308165265929267 total_time 722\n",
      "Saving Model 13100\n",
      "episode 13109, reward 1385.0, memory_length 2000, epsilon 0.0014236802993950906 total_time 722\n",
      "episode 13119, reward 1097.0, memory_length 2000, epsilon 0.0014165796642788893 total_time 722\n",
      "episode 13129, reward 1442.0, memory_length 2000, epsilon 0.0014095144437280755 total_time 725\n",
      "episode 13139, reward 1408.0, memory_length 2000, epsilon 0.0014024844611117656 total_time 721\n",
      "episode 13149, reward 1281.0, memory_length 2000, epsilon 0.0013954895406800313 total_time 723\n",
      "episode 13159, reward 1307.0, memory_length 2000, epsilon 0.0013885295075594956 total_time 725\n",
      "episode 13169, reward 1384.0, memory_length 2000, epsilon 0.001381604187748968 total_time 724\n",
      "episode 13179, reward 1266.0, memory_length 2000, epsilon 0.001374713408115093 total_time 726\n",
      "episode 13189, reward 1377.0, memory_length 2000, epsilon 0.0013678569963880207 total_time 729\n",
      "episode 13199, reward 1390.0, memory_length 2000, epsilon 0.0013610347811571003 total_time 721\n",
      "Saving Model 13200\n",
      "episode 13209, reward 1329.0, memory_length 2000, epsilon 0.0013542465918665965 total_time 726\n",
      "episode 13219, reward 1370.0, memory_length 2000, epsilon 0.0013474922588114229 total_time 725\n",
      "episode 13229, reward 929.0, memory_length 2000, epsilon 0.0013407716131329003 total_time 725\n",
      "episode 13239, reward 1463.0, memory_length 2000, epsilon 0.0013340844868145393 total_time 728\n",
      "episode 13249, reward 1473.0, memory_length 2000, epsilon 0.001327430712677832 total_time 726\n",
      "episode 13259, reward 1471.0, memory_length 2000, epsilon 0.001320810124378079 total_time 721\n",
      "episode 13269, reward 1402.0, memory_length 2000, epsilon 0.0013142225564002276 total_time 724\n",
      "episode 13279, reward 1428.0, memory_length 2000, epsilon 0.0013076678440547354 total_time 726\n",
      "episode 13289, reward 1229.0, memory_length 2000, epsilon 0.0013011458234734523 total_time 728\n",
      "episode 13299, reward 1446.0, memory_length 2000, epsilon 0.001294656331605524 total_time 726\n",
      "Saving Model 13300\n",
      "episode 13309, reward 1201.0, memory_length 2000, epsilon 0.001288199206213315 total_time 721\n",
      "episode 13319, reward 1034.0, memory_length 2000, epsilon 0.001281774285868356 total_time 722\n",
      "episode 13329, reward 1382.0, memory_length 2000, epsilon 0.0012753814099473028 total_time 728\n",
      "episode 13339, reward 1560.0, memory_length 2000, epsilon 0.0012690204186279247 total_time 723\n",
      "episode 13349, reward 1354.0, memory_length 2000, epsilon 0.001262691152885107 total_time 721\n",
      "episode 13359, reward 1412.0, memory_length 2000, epsilon 0.0012563934544868767 total_time 722\n",
      "episode 13369, reward 1394.0, memory_length 2000, epsilon 0.001250127165990446 total_time 722\n",
      "episode 13379, reward 1453.0, memory_length 2000, epsilon 0.0012438921307382756 total_time 721\n",
      "episode 13389, reward 1065.0, memory_length 2000, epsilon 0.0012376881928541587 total_time 723\n",
      "episode 13399, reward 1178.0, memory_length 2000, epsilon 0.0012315151972393274 total_time 722\n",
      "Saving Model 13400\n",
      "episode 13409, reward 1134.0, memory_length 2000, epsilon 0.0012253729895685685 total_time 729\n",
      "episode 13419, reward 1417.0, memory_length 2000, epsilon 0.0012192614162863703 total_time 721\n",
      "episode 13429, reward 1169.0, memory_length 2000, epsilon 0.0012131803246030824 total_time 722\n",
      "episode 13439, reward 1570.0, memory_length 2000, epsilon 0.0012071295624910964 total_time 721\n",
      "episode 13449, reward 840.0, memory_length 2000, epsilon 0.0012011089786810438 total_time 723\n",
      "episode 13459, reward 1309.0, memory_length 2000, epsilon 0.001195118422658016 total_time 721\n",
      "episode 13469, reward 1129.0, memory_length 2000, epsilon 0.0011891577446578006 total_time 721\n",
      "episode 13479, reward 1204.0, memory_length 2000, epsilon 0.001183226795663136 total_time 724\n",
      "episode 13489, reward 742.0, memory_length 2000, epsilon 0.0011773254273999905 total_time 721\n",
      "episode 13499, reward 844.0, memory_length 2000, epsilon 0.0011714534923338489 total_time 724\n",
      "Saving Model 13500\n",
      "episode 13509, reward 1491.0, memory_length 2000, epsilon 0.0011656108436660288 total_time 726\n",
      "episode 13519, reward 1297.0, memory_length 2000, epsilon 0.0011597973353300096 total_time 727\n",
      "episode 13529, reward 1057.0, memory_length 2000, epsilon 0.0011540128219877798 total_time 721\n",
      "episode 13539, reward 1216.0, memory_length 2000, epsilon 0.0011482571590262043 total_time 727\n",
      "episode 13549, reward 1245.0, memory_length 2000, epsilon 0.0011425302025534097 total_time 723\n",
      "episode 13559, reward 1380.0, memory_length 2000, epsilon 0.0011368318093951848 total_time 723\n",
      "episode 13569, reward 1223.0, memory_length 2000, epsilon 0.001131161837091406 total_time 722\n",
      "episode 13579, reward 1344.0, memory_length 2000, epsilon 0.001125520143892469 total_time 723\n",
      "episode 13589, reward 1473.0, memory_length 2000, epsilon 0.00111990658875575 total_time 726\n",
      "episode 13599, reward 1114.0, memory_length 2000, epsilon 0.0011143210313420788 total_time 724\n",
      "Saving Model 13600\n",
      "episode 13609, reward 1300.0, memory_length 2000, epsilon 0.0011087633320122285 total_time 721\n",
      "episode 13619, reward 1414.0, memory_length 2000, epsilon 0.0011032333518234269 total_time 727\n",
      "episode 13629, reward 1430.0, memory_length 2000, epsilon 0.001097730952525881 total_time 722\n",
      "episode 13639, reward 1393.0, memory_length 2000, epsilon 0.0010922559965593204 total_time 724\n",
      "episode 13649, reward 1794.0, memory_length 2000, epsilon 0.0010868083470495634 total_time 723\n",
      "episode 13659, reward 1188.0, memory_length 2000, epsilon 0.0010813878678050874 total_time 729\n",
      "episode 13669, reward 1461.0, memory_length 2000, epsilon 0.0010759944233136285 total_time 723\n",
      "episode 13679, reward 1452.0, memory_length 2000, epsilon 0.0010706278787387942 total_time 723\n",
      "episode 13689, reward 1302.0, memory_length 2000, epsilon 0.0010652880999166901 total_time 726\n",
      "episode 13699, reward 1339.0, memory_length 2000, epsilon 0.001059974953352568 total_time 724\n",
      "Saving Model 13700\n",
      "episode 13709, reward 1156.0, memory_length 2000, epsilon 0.0010546883062174865 total_time 721\n",
      "episode 13719, reward 1201.0, memory_length 2000, epsilon 0.0010494280263449924 total_time 721\n",
      "episode 13729, reward 1279.0, memory_length 2000, epsilon 0.0010441939822278133 total_time 727\n",
      "episode 13739, reward 677.0, memory_length 2000, epsilon 0.0010389860430145765 total_time 725\n",
      "episode 13749, reward 1489.0, memory_length 2000, epsilon 0.0010338040785065287 total_time 721\n",
      "episode 13759, reward 1142.0, memory_length 2000, epsilon 0.0010286479591542876 total_time 722\n",
      "episode 13769, reward 1110.0, memory_length 2000, epsilon 0.0010235175560546008 total_time 723\n",
      "episode 13779, reward 1073.0, memory_length 2000, epsilon 0.0010184127409471235 total_time 725\n",
      "episode 13789, reward 966.0, memory_length 2000, epsilon 0.0010133333862112125 total_time 723\n",
      "episode 13799, reward 1497.0, memory_length 2000, epsilon 0.0010082793648627346 total_time 723\n",
      "Saving Model 13800\n",
      "episode 13809, reward 1312.0, memory_length 2000, epsilon 0.0010032505505508918 total_time 724\n",
      "episode 13819, reward 1051.0, memory_length 2000, epsilon 0.0009982468175550663 total_time 724\n",
      "episode 13829, reward 1545.0, memory_length 2000, epsilon 0.000993268040781672 total_time 726\n",
      "episode 13839, reward 1365.0, memory_length 2000, epsilon 0.0009883140957610299 total_time 726\n",
      "episode 13849, reward 1182.0, memory_length 2000, epsilon 0.0009833848586442563 total_time 723\n",
      "episode 13859, reward 661.0, memory_length 2000, epsilon 0.000978480206200167 total_time 721\n",
      "episode 13869, reward 1214.0, memory_length 2000, epsilon 0.0009736000158121954 total_time 722\n",
      "episode 13879, reward 1024.0, memory_length 2000, epsilon 0.0009687441654753273 total_time 724\n",
      "episode 13889, reward 1160.0, memory_length 2000, epsilon 0.0009639125337930508 total_time 722\n",
      "episode 13899, reward 1147.0, memory_length 2000, epsilon 0.0009591049999743237 total_time 721\n",
      "Saving Model 13900\n",
      "episode 13909, reward 1183.0, memory_length 2000, epsilon 0.0009543214438305494 total_time 721\n",
      "episode 13919, reward 1167.0, memory_length 2000, epsilon 0.0009495617457725752 total_time 726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 13929, reward 1295.0, memory_length 2000, epsilon 0.0009448257868077017 total_time 731\n",
      "episode 13939, reward 1003.0, memory_length 2000, epsilon 0.0009401134485367081 total_time 721\n",
      "episode 13949, reward 992.0, memory_length 2000, epsilon 0.0009354246131508923 total_time 725\n",
      "episode 13959, reward 1376.0, memory_length 2000, epsilon 0.0009307591634291251 total_time 722\n",
      "episode 13969, reward 1165.0, memory_length 2000, epsilon 0.0009261169827349209 total_time 721\n",
      "episode 13979, reward 1070.0, memory_length 2000, epsilon 0.0009214979550135194 total_time 722\n",
      "episode 13989, reward 1366.0, memory_length 2000, epsilon 0.0009169019647889888 total_time 724\n",
      "episode 13999, reward 1245.0, memory_length 2000, epsilon 0.0009123288971613334 total_time 723\n",
      "Saving Model 14000\n",
      "episode 14009, reward 1477.0, memory_length 2000, epsilon 0.0009077786378036242 total_time 727\n",
      "episode 14019, reward 1545.0, memory_length 2000, epsilon 0.0009032510729591402 total_time 726\n",
      "episode 14029, reward 1018.0, memory_length 2000, epsilon 0.0008987460894385246 total_time 727\n",
      "episode 14039, reward 1254.0, memory_length 2000, epsilon 0.0008942635746169547 total_time 723\n",
      "episode 14049, reward 1164.0, memory_length 2000, epsilon 0.0008898034164313264 total_time 723\n",
      "episode 14059, reward 1032.0, memory_length 2000, epsilon 0.0008853655033774521 total_time 735\n",
      "episode 14069, reward 1394.0, memory_length 2000, epsilon 0.0008809497245072759 total_time 722\n",
      "episode 14079, reward 981.0, memory_length 2000, epsilon 0.0008765559694260952 total_time 729\n",
      "episode 14089, reward 1168.0, memory_length 2000, epsilon 0.000872184128289804 total_time 724\n",
      "episode 14099, reward 1235.0, memory_length 2000, epsilon 0.0008678340918021465 total_time 725\n",
      "Saving Model 14100\n",
      "episode 14109, reward 1092.0, memory_length 2000, epsilon 0.0008635057512119837 total_time 723\n",
      "episode 14119, reward 1297.0, memory_length 2000, epsilon 0.0008591989983105755 total_time 727\n",
      "episode 14129, reward 1187.0, memory_length 2000, epsilon 0.0008549137254288751 total_time 731\n",
      "episode 14139, reward 1453.0, memory_length 2000, epsilon 0.0008506498254348365 total_time 721\n",
      "episode 14149, reward 1470.0, memory_length 2000, epsilon 0.0008464071917307392 total_time 723\n",
      "episode 14159, reward 1093.0, memory_length 2000, epsilon 0.0008421857182505188 total_time 730\n",
      "episode 14169, reward 1326.0, memory_length 2000, epsilon 0.0008379852994571187 total_time 723\n",
      "episode 14179, reward 1210.0, memory_length 2000, epsilon 0.00083380583033985 total_time 721\n",
      "episode 14189, reward 1114.0, memory_length 2000, epsilon 0.0008296472064117673 total_time 724\n",
      "episode 14199, reward 910.0, memory_length 2000, epsilon 0.0008255093237070557 total_time 727\n",
      "Saving Model 14200\n",
      "episode 14209, reward 1039.0, memory_length 2000, epsilon 0.0008213920787784321 total_time 721\n",
      "episode 14219, reward 1669.0, memory_length 2000, epsilon 0.0008172953686945588 total_time 721\n",
      "episode 14229, reward 1395.0, memory_length 2000, epsilon 0.0008132190910374698 total_time 729\n",
      "episode 14239, reward 1358.0, memory_length 2000, epsilon 0.0008091631439000125 total_time 731\n",
      "episode 14249, reward 1114.0, memory_length 2000, epsilon 0.0008051274258832966 total_time 724\n",
      "episode 14259, reward 1191.0, memory_length 2000, epsilon 0.0008011118360941616 total_time 723\n",
      "episode 14269, reward 1255.0, memory_length 2000, epsilon 0.0007971162741426536 total_time 721\n",
      "episode 14279, reward 1740.0, memory_length 2000, epsilon 0.0007931406401395156 total_time 723\n",
      "episode 14289, reward 1096.0, memory_length 2000, epsilon 0.0007891848346936906 total_time 724\n",
      "episode 14299, reward 1475.0, memory_length 2000, epsilon 0.0007852487589098364 total_time 722\n",
      "Saving Model 14300\n",
      "episode 14309, reward 1262.0, memory_length 2000, epsilon 0.0007813323143858526 total_time 734\n",
      "episode 14319, reward 1135.0, memory_length 2000, epsilon 0.0007774354032104235 total_time 727\n",
      "episode 14329, reward 1716.0, memory_length 2000, epsilon 0.0007735579279605663 total_time 726\n",
      "episode 14339, reward 1501.0, memory_length 2000, epsilon 0.0007696997916991974 total_time 724\n",
      "episode 14349, reward 1318.0, memory_length 2000, epsilon 0.0007658608979727096 total_time 721\n",
      "episode 14359, reward 1119.0, memory_length 2000, epsilon 0.0007620411508085598 total_time 723\n",
      "episode 14369, reward 831.0, memory_length 2000, epsilon 0.00075824045471287 total_time 723\n",
      "episode 14379, reward 1050.0, memory_length 2000, epsilon 0.0007544587146680395 total_time 726\n",
      "episode 14389, reward 1417.0, memory_length 2000, epsilon 0.0007506958361303699 total_time 721\n",
      "episode 14399, reward 1214.0, memory_length 2000, epsilon 0.0007469517250277031 total_time 722\n",
      "Saving Model 14400\n",
      "episode 14409, reward 962.0, memory_length 2000, epsilon 0.0007432262877570657 total_time 722\n",
      "episode 14419, reward 1066.0, memory_length 2000, epsilon 0.0007395194311823318 total_time 721\n",
      "episode 14429, reward 1263.0, memory_length 2000, epsilon 0.0007358310626318943 total_time 723\n",
      "episode 14439, reward 1102.0, memory_length 2000, epsilon 0.0007321610898963471 total_time 721\n",
      "episode 14449, reward 1318.0, memory_length 2000, epsilon 0.0007285094212261808 total_time 721\n",
      "episode 14459, reward 912.0, memory_length 2000, epsilon 0.0007248759653294883 total_time 723\n",
      "episode 14469, reward 1123.0, memory_length 2000, epsilon 0.0007212606313696831 total_time 724\n",
      "episode 14479, reward 1635.0, memory_length 2000, epsilon 0.0007176633289632272 total_time 726\n",
      "episode 14489, reward 1444.0, memory_length 2000, epsilon 0.0007140839681773742 total_time 721\n",
      "episode 14499, reward 1281.0, memory_length 2000, epsilon 0.0007105224595279177 total_time 723\n",
      "Saving Model 14500\n",
      "episode 14509, reward 1123.0, memory_length 2000, epsilon 0.0007069787139769558 total_time 724\n",
      "episode 14519, reward 1057.0, memory_length 2000, epsilon 0.0007034526429306651 total_time 721\n",
      "episode 14529, reward 1543.0, memory_length 2000, epsilon 0.0006999441582370858 total_time 721\n",
      "episode 14539, reward 1259.0, memory_length 2000, epsilon 0.0006964531721839179 total_time 722\n",
      "episode 14549, reward 1036.0, memory_length 2000, epsilon 0.0006929795974963283 total_time 727\n",
      "episode 14559, reward 1192.0, memory_length 2000, epsilon 0.0006895233473347682 total_time 721\n",
      "episode 14569, reward 824.0, memory_length 2000, epsilon 0.0006860843352928048 total_time 728\n",
      "episode 14579, reward 1680.0, memory_length 2000, epsilon 0.0006826624753949572 total_time 726\n",
      "episode 14589, reward 1337.0, memory_length 2000, epsilon 0.0006792576820945501 total_time 728\n",
      "episode 14599, reward 1103.0, memory_length 2000, epsilon 0.0006758698702715732 total_time 728\n",
      "Saving Model 14600\n",
      "episode 14609, reward 1096.0, memory_length 2000, epsilon 0.0006724989552305546 total_time 733\n",
      "episode 14619, reward 1012.0, memory_length 2000, epsilon 0.0006691448526984429 total_time 721\n",
      "episode 14629, reward 1442.0, memory_length 2000, epsilon 0.0006658074788224999 total_time 725\n",
      "episode 14639, reward 1353.0, memory_length 2000, epsilon 0.0006624867501682045 total_time 723\n",
      "episode 14649, reward 1282.0, memory_length 2000, epsilon 0.0006591825837171684 total_time 730\n",
      "episode 14659, reward 1403.0, memory_length 2000, epsilon 0.0006558948968650576 total_time 722\n",
      "episode 14669, reward 1597.0, memory_length 2000, epsilon 0.0006526236074195298 total_time 730\n",
      "episode 14679, reward 1380.0, memory_length 2000, epsilon 0.0006493686335981781 total_time 723\n",
      "episode 14689, reward 1393.0, memory_length 2000, epsilon 0.0006461298940264879 total_time 724\n",
      "episode 14699, reward 1462.0, memory_length 2000, epsilon 0.0006429073077358008 total_time 721\n",
      "Saving Model 14700\n",
      "episode 14709, reward 1387.0, memory_length 2000, epsilon 0.000639700794161292 total_time 727\n",
      "episode 14719, reward 1124.0, memory_length 2000, epsilon 0.0006365102731399544 total_time 722\n",
      "episode 14729, reward 1437.0, memory_length 2000, epsilon 0.0006333356649085975 total_time 726\n",
      "episode 14739, reward 1267.0, memory_length 2000, epsilon 0.0006301768901018495 total_time 724\n",
      "episode 14749, reward 1383.0, memory_length 2000, epsilon 0.000627033869750176 total_time 726\n",
      "episode 14759, reward 1354.0, memory_length 2000, epsilon 0.0006239065252779041 total_time 721\n",
      "episode 14769, reward 1464.0, memory_length 2000, epsilon 0.0006207947785012593 total_time 726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 14779, reward 1026.0, memory_length 2000, epsilon 0.0006176985516264101 total_time 729\n",
      "episode 14789, reward 1282.0, memory_length 2000, epsilon 0.0006146177672475235 total_time 721\n",
      "episode 14799, reward 1456.0, memory_length 2000, epsilon 0.0006115523483448293 total_time 724\n",
      "Saving Model 14800\n",
      "episode 14809, reward 1163.0, memory_length 2000, epsilon 0.0006085022182826951 total_time 725\n",
      "episode 14819, reward 1299.0, memory_length 2000, epsilon 0.0006054673008077113 total_time 723\n",
      "episode 14829, reward 1318.0, memory_length 2000, epsilon 0.0006024475200467823 total_time 721\n",
      "episode 14839, reward 1352.0, memory_length 2000, epsilon 0.0005994428005052322 total_time 725\n",
      "episode 14849, reward 1254.0, memory_length 2000, epsilon 0.0005964530670649156 total_time 723\n",
      "episode 14859, reward 1205.0, memory_length 2000, epsilon 0.0005934782449823409 total_time 722\n",
      "episode 14869, reward 1435.0, memory_length 2000, epsilon 0.0005905182598868013 total_time 721\n",
      "episode 14879, reward 1096.0, memory_length 2000, epsilon 0.0005875730377785148 total_time 724\n",
      "episode 14889, reward 1432.0, memory_length 2000, epsilon 0.0005846425050267752 total_time 727\n",
      "episode 14899, reward 1154.0, memory_length 2000, epsilon 0.0005817265883681118 total_time 725\n",
      "Saving Model 14900\n",
      "episode 14909, reward 1338.0, memory_length 2000, epsilon 0.000578825214904456 total_time 726\n",
      "episode 14919, reward 1532.0, memory_length 2000, epsilon 0.00057593831210132 total_time 725\n",
      "episode 14929, reward 1321.0, memory_length 2000, epsilon 0.0005730658077859833 total_time 724\n",
      "episode 14939, reward 1196.0, memory_length 2000, epsilon 0.0005702076301456883 total_time 731\n",
      "episode 14949, reward 1231.0, memory_length 2000, epsilon 0.0005673637077258456 total_time 724\n",
      "episode 14959, reward 973.0, memory_length 2000, epsilon 0.0005645339694282461 total_time 727\n",
      "episode 14969, reward 1470.0, memory_length 2000, epsilon 0.0005617183445092846 total_time 723\n",
      "episode 14979, reward 1496.0, memory_length 2000, epsilon 0.0005589167625781924 total_time 725\n",
      "episode 14989, reward 839.0, memory_length 2000, epsilon 0.0005561291535952752 total_time 725\n",
      "episode 14999, reward 1146.0, memory_length 2000, epsilon 0.0005533554478701629 total_time 723\n",
      "Saving Model 15000\n",
      "episode 15009, reward 1156.0, memory_length 2000, epsilon 0.0005505955760600679 total_time 721\n",
      "episode 15019, reward 1192.0, memory_length 2000, epsilon 0.0005478494691680513 total_time 721\n",
      "episode 15029, reward 1452.0, memory_length 2000, epsilon 0.0005451170585412978 total_time 723\n",
      "episode 15039, reward 1268.0, memory_length 2000, epsilon 0.0005423982758693993 total_time 722\n",
      "episode 15049, reward 1078.0, memory_length 2000, epsilon 0.0005396930531826475 total_time 724\n",
      "episode 15059, reward 1505.0, memory_length 2000, epsilon 0.0005370013228503338 total_time 725\n",
      "episode 15069, reward 1127.0, memory_length 2000, epsilon 0.0005343230175790607 total_time 725\n",
      "episode 15079, reward 1376.0, memory_length 2000, epsilon 0.0005316580704110564 total_time 722\n",
      "episode 15089, reward 1349.0, memory_length 2000, epsilon 0.0005290064147225029 total_time 722\n",
      "episode 15099, reward 1508.0, memory_length 2000, epsilon 0.0005263679842218699 total_time 728\n",
      "Saving Model 15100\n",
      "episode 15109, reward 1350.0, memory_length 2000, epsilon 0.0005237427129482576 total_time 729\n",
      "episode 15119, reward 1130.0, memory_length 2000, epsilon 0.0005211305352697472 total_time 728\n",
      "episode 15129, reward 1436.0, memory_length 2000, epsilon 0.0005185313858817608 total_time 728\n",
      "episode 15139, reward 1356.0, memory_length 2000, epsilon 0.0005159451998054278 total_time 726\n",
      "episode 15149, reward 841.0, memory_length 2000, epsilon 0.0005133719123859626 total_time 721\n",
      "episode 15159, reward 1118.0, memory_length 2000, epsilon 0.0005108114592910452 total_time 725\n",
      "episode 15169, reward 899.0, memory_length 2000, epsilon 0.0005082637765092149 total_time 722\n",
      "episode 15179, reward 1461.0, memory_length 2000, epsilon 0.0005057288003482693 total_time 723\n",
      "episode 15189, reward 1074.0, memory_length 2000, epsilon 0.0005032064674336727 total_time 723\n",
      "episode 15199, reward 943.0, memory_length 2000, epsilon 0.0005006967147069704 total_time 724\n",
      "Saving Model 15200\n",
      "episode 15209, reward 1256.0, memory_length 2000, epsilon 0.0004981994794242138 total_time 728\n",
      "episode 15219, reward 1210.0, memory_length 2000, epsilon 0.0004957146991543903 total_time 721\n",
      "episode 15229, reward 1208.0, memory_length 2000, epsilon 0.0004932423117778646 total_time 725\n",
      "episode 15239, reward 1321.0, memory_length 2000, epsilon 0.0004907822554848231 total_time 724\n",
      "episode 15249, reward 1115.0, memory_length 2000, epsilon 0.0004883344687737302 total_time 722\n",
      "episode 15259, reward 1262.0, memory_length 2000, epsilon 0.0004858988904497909 total_time 725\n",
      "episode 15269, reward 1246.0, memory_length 2000, epsilon 0.0004834754596234201 total_time 721\n",
      "episode 15279, reward 1694.0, memory_length 2000, epsilon 0.00048106411570872083 total_time 725\n",
      "episode 15289, reward 1361.0, memory_length 2000, epsilon 0.00047866479842196977 total_time 734\n",
      "episode 15299, reward 1470.0, memory_length 2000, epsilon 0.0004762774477801097 total_time 723\n",
      "Saving Model 15300\n",
      "episode 15309, reward 1290.0, memory_length 2000, epsilon 0.00047390200409924986 total_time 723\n",
      "episode 15319, reward 1254.0, memory_length 2000, epsilon 0.00047153840799317535 total_time 723\n",
      "episode 15329, reward 1203.0, memory_length 2000, epsilon 0.00046918660037186 total_time 726\n",
      "episode 15339, reward 1156.0, memory_length 2000, epsilon 0.0004668465224399907 total_time 721\n",
      "episode 15349, reward 1673.0, memory_length 2000, epsilon 0.0004645181156954974 total_time 722\n",
      "episode 15359, reward 1458.0, memory_length 2000, epsilon 0.0004622013219280902 total_time 729\n",
      "episode 15369, reward 1713.0, memory_length 2000, epsilon 0.0004598960832178041 total_time 723\n",
      "episode 15379, reward 1118.0, memory_length 2000, epsilon 0.0004576023419335515 total_time 725\n",
      "episode 15389, reward 1349.0, memory_length 2000, epsilon 0.0004553200407316803 total_time 722\n",
      "episode 15399, reward 893.0, memory_length 2000, epsilon 0.00045304912255454227 total_time 725\n",
      "Saving Model 15400\n",
      "episode 15409, reward 1471.0, memory_length 2000, epsilon 0.00045078953062906456 total_time 721\n",
      "episode 15419, reward 913.0, memory_length 2000, epsilon 0.00044854120846533115 total_time 721\n",
      "episode 15429, reward 1207.0, memory_length 2000, epsilon 0.00044630409985517097 total_time 727\n",
      "episode 15439, reward 1299.0, memory_length 2000, epsilon 0.00044407814887075214 total_time 723\n",
      "episode 15449, reward 1223.0, memory_length 2000, epsilon 0.0004418632998631842 total_time 722\n",
      "episode 15459, reward 1084.0, memory_length 2000, epsilon 0.00043965949746112656 total_time 730\n",
      "episode 15469, reward 1258.0, memory_length 2000, epsilon 0.00043746668656940405 total_time 724\n",
      "episode 15479, reward 1277.0, memory_length 2000, epsilon 0.0004352848123676308 total_time 722\n",
      "episode 15489, reward 852.0, memory_length 2000, epsilon 0.00043311382030883794 total_time 735\n",
      "episode 15499, reward 1401.0, memory_length 2000, epsilon 0.00043095365611811083 total_time 726\n",
      "Saving Model 15500\n",
      "episode 15509, reward 1339.0, memory_length 2000, epsilon 0.00042880426579123215 total_time 724\n",
      "episode 15519, reward 985.0, memory_length 2000, epsilon 0.0004266655955933318 total_time 721\n",
      "episode 15529, reward 1408.0, memory_length 2000, epsilon 0.0004245375920575435 total_time 730\n",
      "episode 15539, reward 1262.0, memory_length 2000, epsilon 0.00042242020198366803 total_time 725\n",
      "episode 15549, reward 1381.0, memory_length 2000, epsilon 0.0004203133724368432 total_time 721\n",
      "episode 15559, reward 1137.0, memory_length 2000, epsilon 0.0004182170507462203 total_time 723\n",
      "episode 15569, reward 884.0, memory_length 2000, epsilon 0.0004161311845036485 total_time 725\n",
      "episode 15579, reward 1102.0, memory_length 2000, epsilon 0.00041405572156236284 total_time 721\n",
      "episode 15589, reward 835.0, memory_length 2000, epsilon 0.00041199061003568163 total_time 724\n",
      "episode 15599, reward 1155.0, memory_length 2000, epsilon 0.00040993579829570927 total_time 723\n",
      "Saving Model 15600\n",
      "episode 15609, reward 1435.0, memory_length 2000, epsilon 0.00040789123497204504 total_time 721\n",
      "episode 15619, reward 1210.0, memory_length 2000, epsilon 0.00040585686895049946 total_time 721\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 15629, reward 1002.0, memory_length 2000, epsilon 0.0004038326493718161 total_time 723\n",
      "episode 15639, reward 1112.0, memory_length 2000, epsilon 0.00040181852563039963 total_time 728\n",
      "episode 15649, reward 1093.0, memory_length 2000, epsilon 0.00039981444737305236 total_time 721\n",
      "episode 15659, reward 1273.0, memory_length 2000, epsilon 0.00039782036449771305 total_time 721\n",
      "episode 15669, reward 1093.0, memory_length 2000, epsilon 0.00039583622715220606 total_time 721\n",
      "episode 15679, reward 1320.0, memory_length 2000, epsilon 0.0003938619857329943 total_time 726\n",
      "episode 15689, reward 969.0, memory_length 2000, epsilon 0.0003918975908839396 total_time 726\n",
      "episode 15699, reward 1165.0, memory_length 2000, epsilon 0.00038994299349506833 total_time 730\n",
      "Saving Model 15700\n",
      "episode 15709, reward 1118.0, memory_length 2000, epsilon 0.000387998144701344 total_time 725\n",
      "episode 15719, reward 1078.0, memory_length 2000, epsilon 0.0003860629958814451 total_time 724\n",
      "episode 15729, reward 1296.0, memory_length 2000, epsilon 0.00038413749865655095 total_time 729\n",
      "episode 15739, reward 1115.0, memory_length 2000, epsilon 0.0003822216048891305 total_time 731\n",
      "episode 15749, reward 1525.0, memory_length 2000, epsilon 0.0003803152666817396 total_time 721\n",
      "episode 15759, reward 957.0, memory_length 2000, epsilon 0.000378418436375824 total_time 723\n",
      "episode 15769, reward 1445.0, memory_length 2000, epsilon 0.00037653106655052696 total_time 728\n",
      "episode 15779, reward 1205.0, memory_length 2000, epsilon 0.00037465311002150473 total_time 731\n",
      "episode 15789, reward 1055.0, memory_length 2000, epsilon 0.0003727845198397462 total_time 725\n",
      "episode 15799, reward 1223.0, memory_length 2000, epsilon 0.0003709252492903996 total_time 722\n",
      "Saving Model 15800\n",
      "episode 15809, reward 875.0, memory_length 2000, epsilon 0.00036907525189160394 total_time 725\n",
      "episode 15819, reward 1479.0, memory_length 2000, epsilon 0.00036723448139332855 total_time 723\n",
      "episode 15829, reward 1084.0, memory_length 2000, epsilon 0.00036540289177621485 total_time 730\n",
      "episode 15839, reward 1083.0, memory_length 2000, epsilon 0.00036358043725042696 total_time 723\n",
      "episode 15849, reward 1196.0, memory_length 2000, epsilon 0.00036176707225450683 total_time 722\n",
      "episode 15859, reward 1561.0, memory_length 2000, epsilon 0.0003599627514542351 total_time 721\n",
      "episode 15869, reward 1206.0, memory_length 2000, epsilon 0.00035816742974149787 total_time 729\n",
      "episode 15879, reward 1259.0, memory_length 2000, epsilon 0.00035638106223315864 total_time 722\n",
      "episode 15889, reward 890.0, memory_length 2000, epsilon 0.00035460360426993654 total_time 722\n",
      "episode 15899, reward 1633.0, memory_length 2000, epsilon 0.00035283501141529044 total_time 721\n",
      "Saving Model 15900\n",
      "episode 15909, reward 1335.0, memory_length 2000, epsilon 0.00035107523945430654 total_time 723\n",
      "episode 15919, reward 1364.0, memory_length 2000, epsilon 0.0003493242443925942 total_time 728\n",
      "episode 15929, reward 1698.0, memory_length 2000, epsilon 0.0003475819824551856 total_time 726\n",
      "episode 15939, reward 1287.0, memory_length 2000, epsilon 0.0003458484100854417 total_time 729\n",
      "episode 15949, reward 1168.0, memory_length 2000, epsilon 0.0003441234839439628 total_time 724\n",
      "episode 15959, reward 1300.0, memory_length 2000, epsilon 0.0003424071609075057 total_time 721\n",
      "episode 15969, reward 1149.0, memory_length 2000, epsilon 0.0003406993980679047 total_time 726\n",
      "episode 15979, reward 1343.0, memory_length 2000, epsilon 0.00033900015273100043 total_time 725\n",
      "episode 15989, reward 1284.0, memory_length 2000, epsilon 0.0003373093824155707 total_time 726\n",
      "episode 15999, reward 1642.0, memory_length 2000, epsilon 0.0003356270448522696 total_time 721\n",
      "Saving Model 16000\n",
      "episode 16009, reward 1448.0, memory_length 2000, epsilon 0.0003339530979825704 total_time 731\n",
      "episode 16019, reward 1363.0, memory_length 2000, epsilon 0.0003322874999577139 total_time 721\n",
      "episode 16029, reward 1595.0, memory_length 2000, epsilon 0.0003306302091376635 total_time 725\n",
      "episode 16039, reward 1117.0, memory_length 2000, epsilon 0.0003289811840900614 total_time 727\n",
      "episode 16049, reward 1172.0, memory_length 2000, epsilon 0.0003273403835891965 total_time 725\n",
      "episode 16059, reward 1210.0, memory_length 2000, epsilon 0.0003257077666149698 total_time 721\n",
      "episode 16069, reward 391.0, memory_length 2000, epsilon 0.000324083292351873 total_time 721\n",
      "episode 16079, reward 1342.0, memory_length 2000, epsilon 0.00032246692018796374 total_time 727\n",
      "episode 16089, reward 952.0, memory_length 2000, epsilon 0.0003208586097138549 total_time 724\n",
      "episode 16099, reward 1214.0, memory_length 2000, epsilon 0.0003192583207216998 total_time 722\n",
      "Saving Model 16100\n",
      "episode 16109, reward 1376.0, memory_length 2000, epsilon 0.00031766601320419076 total_time 722\n",
      "episode 16119, reward 1327.0, memory_length 2000, epsilon 0.00031608164735355754 total_time 721\n",
      "episode 16129, reward 1034.0, memory_length 2000, epsilon 0.0003145051835605702 total_time 731\n",
      "episode 16139, reward 1283.0, memory_length 2000, epsilon 0.0003129365824135529 total_time 728\n",
      "episode 16149, reward 1030.0, memory_length 2000, epsilon 0.0003113758046973942 total_time 721\n",
      "episode 16159, reward 1047.0, memory_length 2000, epsilon 0.00030982281139257093 total_time 723\n",
      "episode 16169, reward 1243.0, memory_length 2000, epsilon 0.00030827756367416857 total_time 727\n",
      "episode 16179, reward 1352.0, memory_length 2000, epsilon 0.0003067400229109142 total_time 725\n",
      "episode 16189, reward 1417.0, memory_length 2000, epsilon 0.00030521015066420923 total_time 721\n",
      "episode 16199, reward 1120.0, memory_length 2000, epsilon 0.00030368790868716666 total_time 721\n",
      "Saving Model 16200\n",
      "episode 16209, reward 1339.0, memory_length 2000, epsilon 0.00030217325892365897 total_time 724\n",
      "episode 16219, reward 1168.0, memory_length 2000, epsilon 0.00030066616350736194 total_time 724\n",
      "episode 16229, reward 1629.0, memory_length 2000, epsilon 0.0002991665847608129 total_time 729\n",
      "episode 16239, reward 1398.0, memory_length 2000, epsilon 0.000297674485194464 total_time 723\n",
      "episode 16249, reward 1433.0, memory_length 2000, epsilon 0.0002961898275057493 total_time 725\n",
      "episode 16259, reward 1480.0, memory_length 2000, epsilon 0.00029471257457814833 total_time 721\n",
      "episode 16269, reward 1121.0, memory_length 2000, epsilon 0.0002932426894802614 total_time 728\n",
      "episode 16279, reward 1072.0, memory_length 2000, epsilon 0.000291780135464885 total_time 727\n",
      "episode 16289, reward 1200.0, memory_length 2000, epsilon 0.00029032487596809174 total_time 723\n",
      "episode 16299, reward 1556.0, memory_length 2000, epsilon 0.00028887687460831923 total_time 722\n",
      "Saving Model 16300\n",
      "episode 16309, reward 1504.0, memory_length 2000, epsilon 0.00028743609518545714 total_time 727\n",
      "episode 16319, reward 1324.0, memory_length 2000, epsilon 0.0002860025016799458 total_time 727\n",
      "episode 16329, reward 1537.0, memory_length 2000, epsilon 0.00028457605825187195 total_time 724\n",
      "episode 16339, reward 1042.0, memory_length 2000, epsilon 0.0002831567292400766 total_time 724\n",
      "episode 16349, reward 1063.0, memory_length 2000, epsilon 0.00028174447916125945 total_time 727\n",
      "episode 16359, reward 1256.0, memory_length 2000, epsilon 0.0002803392727090956 total_time 728\n",
      "episode 16369, reward 1208.0, memory_length 2000, epsilon 0.0002789410747533509 total_time 725\n",
      "episode 16379, reward 1699.0, memory_length 2000, epsilon 0.0002775498503390028 total_time 724\n",
      "episode 16389, reward 1405.0, memory_length 2000, epsilon 0.00027616556468536936 total_time 727\n",
      "episode 16399, reward 1245.0, memory_length 2000, epsilon 0.0002747881831852362 total_time 723\n",
      "Saving Model 16400\n",
      "episode 16409, reward 1136.0, memory_length 2000, epsilon 0.0002734176714039951 total_time 725\n",
      "episode 16419, reward 1541.0, memory_length 2000, epsilon 0.00027205399507877916 total_time 725\n",
      "episode 16429, reward 1160.0, memory_length 2000, epsilon 0.0002706971201176096 total_time 722\n",
      "episode 16439, reward 1110.0, memory_length 2000, epsilon 0.0002693470125985423 total_time 723\n",
      "episode 16449, reward 1258.0, memory_length 2000, epsilon 0.00026800363876881806 total_time 724\n",
      "episode 16459, reward 1342.0, memory_length 2000, epsilon 0.000266666965044022 total_time 727\n",
      "episode 16469, reward 1318.0, memory_length 2000, epsilon 0.0002653369580072404 total_time 721\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 16479, reward 1452.0, memory_length 2000, epsilon 0.00026401358440822923 total_time 723\n",
      "episode 16489, reward 1349.0, memory_length 2000, epsilon 0.00026269681116257844 total_time 722\n",
      "episode 16499, reward 967.0, memory_length 2000, epsilon 0.0002613866053508893 total_time 721\n",
      "Saving Model 16500\n",
      "episode 16509, reward 1059.0, memory_length 2000, epsilon 0.0002600829342179475 total_time 726\n",
      "episode 16519, reward 1555.0, memory_length 2000, epsilon 0.000258785765171907 total_time 733\n",
      "episode 16529, reward 1201.0, memory_length 2000, epsilon 0.0002574950657834747 total_time 721\n",
      "episode 16539, reward 1274.0, memory_length 2000, epsilon 0.0002562108037850978 total_time 728\n",
      "episode 16549, reward 938.0, memory_length 2000, epsilon 0.00025493294707016034 total_time 725\n",
      "episode 16559, reward 985.0, memory_length 2000, epsilon 0.00025366146369217686 total_time 721\n",
      "episode 16569, reward 1456.0, memory_length 2000, epsilon 0.00025239632186399775 total_time 724\n",
      "episode 16579, reward 1354.0, memory_length 2000, epsilon 0.00025113748995701037 total_time 721\n",
      "episode 16589, reward 1462.0, memory_length 2000, epsilon 0.0002498849365003525 total_time 721\n",
      "episode 16599, reward 1267.0, memory_length 2000, epsilon 0.00024863863018012155 total_time 724\n",
      "Saving Model 16600\n",
      "episode 16609, reward 1425.0, memory_length 2000, epsilon 0.000247398539838595 total_time 723\n",
      "episode 16619, reward 1475.0, memory_length 2000, epsilon 0.0002461646344734503 total_time 722\n",
      "episode 16629, reward 1061.0, memory_length 2000, epsilon 0.00024493688323698796 total_time 731\n",
      "episode 16639, reward 1409.0, memory_length 2000, epsilon 0.0002437152554353642 total_time 728\n",
      "episode 16649, reward 1119.0, memory_length 2000, epsilon 0.0002424997205278194 total_time 723\n",
      "episode 16659, reward 995.0, memory_length 2000, epsilon 0.0002412902481259184 total_time 728\n",
      "episode 16669, reward 1037.0, memory_length 2000, epsilon 0.00024008680799278735 total_time 725\n",
      "episode 16679, reward 1248.0, memory_length 2000, epsilon 0.00023888937004236065 total_time 726\n",
      "episode 16689, reward 1677.0, memory_length 2000, epsilon 0.0002376979043386276 total_time 723\n",
      "episode 16699, reward 1548.0, memory_length 2000, epsilon 0.00023651238109488273 total_time 729\n",
      "Saving Model 16700\n",
      "episode 16709, reward 1159.0, memory_length 2000, epsilon 0.00023533277067298397 total_time 733\n",
      "episode 16719, reward 1193.0, memory_length 2000, epsilon 0.00023415904358260856 total_time 728\n",
      "episode 16729, reward 1516.0, memory_length 2000, epsilon 0.0002329911704805189 total_time 721\n",
      "episode 16739, reward 1315.0, memory_length 2000, epsilon 0.00023182912216982584 total_time 727\n",
      "episode 16749, reward 1331.0, memory_length 2000, epsilon 0.00023067286959926186 total_time 722\n",
      "episode 16759, reward 944.0, memory_length 2000, epsilon 0.0002295223838624517 total_time 722\n",
      "episode 16769, reward 1040.0, memory_length 2000, epsilon 0.00022837763619719238 total_time 728\n",
      "episode 16779, reward 1285.0, memory_length 2000, epsilon 0.0002272385979847331 total_time 724\n",
      "episode 16789, reward 1549.0, memory_length 2000, epsilon 0.00022610524074905835 total_time 727\n",
      "episode 16799, reward 1292.0, memory_length 2000, epsilon 0.00022497753615617906 total_time 728\n",
      "Saving Model 16800\n",
      "episode 16809, reward 1532.0, memory_length 2000, epsilon 0.0002238554560134209 total_time 725\n",
      "episode 16819, reward 1426.0, memory_length 2000, epsilon 0.00022273897226872258 total_time 721\n",
      "episode 16829, reward 1388.0, memory_length 2000, epsilon 0.0002216280570099316 total_time 725\n",
      "episode 16839, reward 1657.0, memory_length 2000, epsilon 0.00022052268246410938 total_time 727\n",
      "episode 16849, reward 1408.0, memory_length 2000, epsilon 0.00021942282099683398 total_time 721\n",
      "episode 16859, reward 1237.0, memory_length 2000, epsilon 0.00021832844511151175 total_time 721\n",
      "episode 16869, reward 1371.0, memory_length 2000, epsilon 0.00021723952744868896 total_time 723\n",
      "episode 16879, reward 865.0, memory_length 2000, epsilon 0.0002161560407853666 total_time 727\n",
      "episode 16889, reward 1457.0, memory_length 2000, epsilon 0.0002150779580343224 total_time 722\n",
      "episode 16899, reward 893.0, memory_length 2000, epsilon 0.00021400525224343065 total_time 725\n",
      "Saving Model 16900\n",
      "episode 16909, reward 1140.0, memory_length 2000, epsilon 0.00021293789659499149 total_time 726\n",
      "episode 16919, reward 1444.0, memory_length 2000, epsilon 0.0002118758644050573 total_time 721\n",
      "episode 16929, reward 1473.0, memory_length 2000, epsilon 0.00021081912912276852 total_time 726\n",
      "episode 16939, reward 1234.0, memory_length 2000, epsilon 0.00020976766432968832 total_time 727\n",
      "episode 16949, reward 1428.0, memory_length 2000, epsilon 0.0002087214437391414 total_time 726\n",
      "episode 16959, reward 1271.0, memory_length 2000, epsilon 0.00020768044119555924 total_time 725\n",
      "episode 16969, reward 1420.0, memory_length 2000, epsilon 0.00020664463067382333 total_time 724\n",
      "episode 16979, reward 1163.0, memory_length 2000, epsilon 0.00020561398627861737 total_time 725\n",
      "episode 16989, reward 1498.0, memory_length 2000, epsilon 0.00020458848224377707 total_time 721\n",
      "episode 16999, reward 1412.0, memory_length 2000, epsilon 0.00020356809293164887 total_time 722\n",
      "Saving Model 17000\n",
      "episode 17009, reward 1018.0, memory_length 2000, epsilon 0.00020255279283244615 total_time 727\n",
      "episode 17019, reward 981.0, memory_length 2000, epsilon 0.00020154255656361386 total_time 729\n",
      "episode 17029, reward 1307.0, memory_length 2000, epsilon 0.00020053735886919302 total_time 725\n",
      "episode 17039, reward 982.0, memory_length 2000, epsilon 0.00019953717461918823 total_time 727\n",
      "episode 17049, reward 1547.0, memory_length 2000, epsilon 0.00019854197880894185 total_time 722\n",
      "episode 17059, reward 1360.0, memory_length 2000, epsilon 0.00019755174655850606 total_time 727\n",
      "episode 17069, reward 1212.0, memory_length 2000, epsilon 0.00019656645311202377 total_time 726\n",
      "episode 17079, reward 1520.0, memory_length 2000, epsilon 0.00019558607383710677 total_time 722\n",
      "episode 17089, reward 1192.0, memory_length 2000, epsilon 0.0001946105842242228 total_time 721\n",
      "episode 17099, reward 1236.0, memory_length 2000, epsilon 0.0001936399598860801 total_time 723\n",
      "Saving Model 17100\n",
      "episode 17109, reward 993.0, memory_length 2000, epsilon 0.00019267417655701997 total_time 723\n",
      "episode 17119, reward 1025.0, memory_length 2000, epsilon 0.00019171321009240922 total_time 722\n",
      "episode 17129, reward 1499.0, memory_length 2000, epsilon 0.0001907570364680355 total_time 737\n",
      "episode 17139, reward 1055.0, memory_length 2000, epsilon 0.00018980563177950908 total_time 725\n",
      "episode 17149, reward 1285.0, memory_length 2000, epsilon 0.00018885897224166256 total_time 724\n",
      "episode 17159, reward 1158.0, memory_length 2000, epsilon 0.00018791703418795884 total_time 726\n",
      "episode 17169, reward 1354.0, memory_length 2000, epsilon 0.00018697979406989682 total_time 721\n",
      "episode 17179, reward 1093.0, memory_length 2000, epsilon 0.00018604722845642509 total_time 721\n",
      "episode 17189, reward 1300.0, memory_length 2000, epsilon 0.00018511931403335507 total_time 721\n",
      "episode 17199, reward 1264.0, memory_length 2000, epsilon 0.00018419602760277718 total_time 730\n",
      "Saving Model 17200\n",
      "episode 17209, reward 1058.0, memory_length 2000, epsilon 0.00018327734608248326 total_time 728\n",
      "episode 17219, reward 954.0, memory_length 2000, epsilon 0.00018236324650538674 total_time 729\n",
      "episode 17229, reward 1146.0, memory_length 2000, epsilon 0.0001814537060189513 total_time 723\n",
      "episode 17239, reward 1109.0, memory_length 2000, epsilon 0.00018054870188461675 total_time 725\n",
      "episode 17249, reward 1316.0, memory_length 2000, epsilon 0.00017964821147723318 total_time 725\n",
      "episode 17259, reward 1140.0, memory_length 2000, epsilon 0.00017875221228449295 total_time 726\n",
      "episode 17269, reward 962.0, memory_length 2000, epsilon 0.00017786068190636987 total_time 722\n",
      "episode 17279, reward 994.0, memory_length 2000, epsilon 0.00017697359805455827 total_time 721\n",
      "episode 17289, reward 1317.0, memory_length 2000, epsilon 0.00017609093855191517 total_time 723\n",
      "episode 17299, reward 1129.0, memory_length 2000, epsilon 0.00017521268133190756 total_time 721\n",
      "Saving Model 17300\n",
      "episode 17309, reward 1190.0, memory_length 2000, epsilon 0.0001743388044380586 total_time 725\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 17319, reward 1151.0, memory_length 2000, epsilon 0.00017346928602340108 total_time 722\n",
      "episode 17329, reward 1221.0, memory_length 2000, epsilon 0.00017260410434992868 total_time 735\n",
      "episode 17339, reward 1219.0, memory_length 2000, epsilon 0.00017174323778805517 total_time 721\n",
      "episode 17349, reward 1147.0, memory_length 2000, epsilon 0.00017088666481607099 total_time 721\n",
      "episode 17359, reward 1289.0, memory_length 2000, epsilon 0.0001700343640196076 total_time 725\n",
      "episode 17369, reward 1579.0, memory_length 2000, epsilon 0.0001691863140911009 total_time 721\n",
      "episode 17379, reward 1076.0, memory_length 2000, epsilon 0.00016834249382925804 total_time 728\n",
      "episode 17389, reward 1227.0, memory_length 2000, epsilon 0.00016750288213852904 total_time 723\n",
      "episode 17399, reward 1174.0, memory_length 2000, epsilon 0.0001666674580285773 total_time 721\n",
      "Saving Model 17400\n",
      "episode 17409, reward 1286.0, memory_length 2000, epsilon 0.0001658362006137572 total_time 722\n",
      "episode 17419, reward 1141.0, memory_length 2000, epsilon 0.00016500908911258944 total_time 724\n",
      "episode 17429, reward 1355.0, memory_length 2000, epsilon 0.00016418610284724375 total_time 728\n",
      "episode 17439, reward 1291.0, memory_length 2000, epsilon 0.00016336722124302088 total_time 721\n",
      "episode 17449, reward 1457.0, memory_length 2000, epsilon 0.0001625524238278375 total_time 722\n",
      "episode 17459, reward 1352.0, memory_length 2000, epsilon 0.0001617416902317164 total_time 725\n",
      "episode 17469, reward 976.0, memory_length 2000, epsilon 0.00016093500018627484 total_time 721\n",
      "episode 17479, reward 1515.0, memory_length 2000, epsilon 0.0001601323335242203 total_time 723\n",
      "episode 17489, reward 1340.0, memory_length 2000, epsilon 0.0001593336701788438 total_time 722\n",
      "episode 17499, reward 1406.0, memory_length 2000, epsilon 0.00015853899018352066 total_time 725\n",
      "Saving Model 17500\n",
      "episode 17509, reward 1488.0, memory_length 2000, epsilon 0.0001577482736712091 total_time 723\n",
      "episode 17519, reward 926.0, memory_length 2000, epsilon 0.00015696150087395538 total_time 722\n",
      "episode 17529, reward 1619.0, memory_length 2000, epsilon 0.00015617865212239887 total_time 722\n",
      "episode 17539, reward 1570.0, memory_length 2000, epsilon 0.00015539970784527945 total_time 721\n",
      "episode 17549, reward 1334.0, memory_length 2000, epsilon 0.0001546246485689502 total_time 725\n",
      "episode 17559, reward 976.0, memory_length 2000, epsilon 0.00015385345491688822 total_time 721\n",
      "episode 17569, reward 1459.0, memory_length 2000, epsilon 0.0001530861076092127 total_time 727\n",
      "episode 17579, reward 1223.0, memory_length 2000, epsilon 0.00015232258746220034 total_time 722\n",
      "episode 17589, reward 1516.0, memory_length 2000, epsilon 0.0001515628753878083 total_time 721\n",
      "episode 17599, reward 1408.0, memory_length 2000, epsilon 0.00015080695239319463 total_time 721\n",
      "Saving Model 17600\n",
      "episode 17609, reward 1100.0, memory_length 2000, epsilon 0.00015005479958024525 total_time 725\n",
      "episode 17619, reward 1417.0, memory_length 2000, epsilon 0.00014930639814510105 total_time 721\n",
      "episode 17629, reward 1070.0, memory_length 2000, epsilon 0.00014856172937768657 total_time 722\n",
      "episode 17639, reward 1348.0, memory_length 2000, epsilon 0.00014782077466124442 total_time 724\n",
      "episode 17649, reward 1005.0, memory_length 2000, epsilon 0.00014708351547186753 total_time 726\n",
      "episode 17659, reward 978.0, memory_length 2000, epsilon 0.0001463499333780383 total_time 726\n",
      "episode 17669, reward 1592.0, memory_length 2000, epsilon 0.00014562001004016564 total_time 722\n",
      "episode 17679, reward 1525.0, memory_length 2000, epsilon 0.00014489372721012843 total_time 721\n",
      "episode 17689, reward 1317.0, memory_length 2000, epsilon 0.00014417106673081823 total_time 723\n",
      "episode 17699, reward 1190.0, memory_length 2000, epsilon 0.00014345201053568498 total_time 725\n",
      "Saving Model 17700\n",
      "episode 17709, reward 1354.0, memory_length 2000, epsilon 0.00014273654064828682 total_time 721\n",
      "episode 17719, reward 1295.0, memory_length 2000, epsilon 0.00014202463918183887 total_time 722\n",
      "episode 17729, reward 1511.0, memory_length 2000, epsilon 0.00014131628833876777 total_time 722\n",
      "episode 17739, reward 1506.0, memory_length 2000, epsilon 0.00014061147041026517 total_time 723\n",
      "episode 17749, reward 980.0, memory_length 2000, epsilon 0.00013991016777584655 total_time 722\n",
      "episode 17759, reward 1446.0, memory_length 2000, epsilon 0.0001392123629029091 total_time 726\n",
      "episode 17769, reward 1633.0, memory_length 2000, epsilon 0.00013851803834629488 total_time 721\n",
      "episode 17779, reward 1370.0, memory_length 2000, epsilon 0.00013782717674785404 total_time 725\n",
      "episode 17789, reward 885.0, memory_length 2000, epsilon 0.00013713976083601015 total_time 723\n",
      "episode 17799, reward 1093.0, memory_length 2000, epsilon 0.00013645577342533014 total_time 730\n",
      "Saving Model 17800\n",
      "episode 17809, reward 1388.0, memory_length 2000, epsilon 0.00013577519741609254 total_time 725\n",
      "episode 17819, reward 1263.0, memory_length 2000, epsilon 0.00013509801579386226 total_time 723\n",
      "episode 17829, reward 1290.0, memory_length 2000, epsilon 0.00013442421162906295 total_time 723\n",
      "episode 17839, reward 1532.0, memory_length 2000, epsilon 0.00013375376807655585 total_time 725\n",
      "episode 17849, reward 1474.0, memory_length 2000, epsilon 0.00013308666837521678 total_time 724\n",
      "episode 17859, reward 1506.0, memory_length 2000, epsilon 0.00013242289584751869 total_time 723\n",
      "episode 17869, reward 1164.0, memory_length 2000, epsilon 0.00013176243389911404 total_time 723\n",
      "episode 17879, reward 1412.0, memory_length 2000, epsilon 0.0001311052660184193 total_time 722\n",
      "episode 17889, reward 1300.0, memory_length 2000, epsilon 0.00013045137577620365 total_time 730\n",
      "episode 17899, reward 1097.0, memory_length 2000, epsilon 0.0001298007468251765 total_time 722\n",
      "Saving Model 17900\n",
      "episode 17909, reward 1471.0, memory_length 2000, epsilon 0.00012915336289958068 total_time 721\n",
      "episode 17919, reward 1348.0, memory_length 2000, epsilon 0.0001285092078147839 total_time 724\n",
      "episode 17929, reward 1407.0, memory_length 2000, epsilon 0.00012786826546687564 total_time 723\n",
      "episode 17939, reward 1211.0, memory_length 2000, epsilon 0.0001272305198322641 total_time 728\n",
      "episode 17949, reward 1111.0, memory_length 2000, epsilon 0.00012659595496727474 total_time 721\n",
      "episode 17959, reward 849.0, memory_length 2000, epsilon 0.00012596455500775333 total_time 723\n",
      "episode 17969, reward 1076.0, memory_length 2000, epsilon 0.00012533630416866753 total_time 728\n",
      "episode 17979, reward 1452.0, memory_length 2000, epsilon 0.00012471118674371414 total_time 723\n",
      "episode 17989, reward 1106.0, memory_length 2000, epsilon 0.00012408918710492451 total_time 722\n",
      "episode 17999, reward 1160.0, memory_length 2000, epsilon 0.00012347028970227566 total_time 722\n",
      "Saving Model 18000\n",
      "episode 18009, reward 1309.0, memory_length 2000, epsilon 0.00012285447906329992 total_time 721\n",
      "episode 18019, reward 1523.0, memory_length 2000, epsilon 0.00012224173979269947 total_time 725\n",
      "episode 18029, reward 1147.0, memory_length 2000, epsilon 0.00012163205657196077 total_time 721\n",
      "episode 18039, reward 1475.0, memory_length 2000, epsilon 0.00012102541415897117 total_time 722\n",
      "episode 18049, reward 1555.0, memory_length 2000, epsilon 0.00012042179738763918 total_time 724\n",
      "episode 18059, reward 1316.0, memory_length 2000, epsilon 0.00011982119116751364 total_time 725\n",
      "episode 18069, reward 1432.0, memory_length 2000, epsilon 0.0001192235804834082 total_time 727\n",
      "episode 18079, reward 1258.0, memory_length 2000, epsilon 0.0001186289503950242 total_time 724\n",
      "episode 18089, reward 1506.0, memory_length 2000, epsilon 0.00011803728603657887 total_time 723\n",
      "episode 18099, reward 1459.0, memory_length 2000, epsilon 0.00011744857261643203 total_time 727\n",
      "Saving Model 18100\n",
      "episode 18109, reward 1461.0, memory_length 2000, epsilon 0.00011686279541671773 total_time 723\n",
      "episode 18119, reward 1358.0, memory_length 2000, epsilon 0.00011627993979297566 total_time 731\n",
      "episode 18129, reward 1621.0, memory_length 2000, epsilon 0.00011569999117378445 total_time 727\n",
      "episode 18139, reward 1093.0, memory_length 2000, epsilon 0.00011512293506039885 total_time 721\n",
      "episode 18149, reward 1144.0, memory_length 2000, epsilon 0.00011454875702638552 total_time 727\n",
      "episode 18159, reward 1766.0, memory_length 2000, epsilon 0.00011397744271726417 total_time 725\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 18169, reward 1322.0, memory_length 2000, epsilon 0.00011340897785014687 total_time 722\n",
      "episode 18179, reward 1448.0, memory_length 2000, epsilon 0.00011284334821338254 total_time 731\n",
      "episode 18189, reward 1653.0, memory_length 2000, epsilon 0.00011228053966620101 total_time 726\n",
      "episode 18199, reward 1381.0, memory_length 2000, epsilon 0.00011172053813835887 total_time 721\n",
      "Saving Model 18200\n",
      "episode 18209, reward 1570.0, memory_length 2000, epsilon 0.0001111633296297892 total_time 721\n",
      "episode 18219, reward 1010.0, memory_length 2000, epsilon 0.00011060890021024982 total_time 725\n",
      "episode 18229, reward 1103.0, memory_length 2000, epsilon 0.00011005723601897679 total_time 728\n",
      "episode 18239, reward 1349.0, memory_length 2000, epsilon 0.00010950832326433618 total_time 731\n",
      "episode 18249, reward 1380.0, memory_length 2000, epsilon 0.00010896214822348095 total_time 723\n",
      "episode 18259, reward 1447.0, memory_length 2000, epsilon 0.0001084186972420062 total_time 724\n",
      "episode 18269, reward 893.0, memory_length 2000, epsilon 0.00010787795673360934 total_time 725\n",
      "episode 18279, reward 1529.0, memory_length 2000, epsilon 0.00010733991317974966 total_time 722\n",
      "episode 18289, reward 863.0, memory_length 2000, epsilon 0.00010680455312930991 total_time 722\n",
      "episode 18299, reward 1200.0, memory_length 2000, epsilon 0.0001062718631982613 total_time 723\n",
      "Saving Model 18300\n",
      "episode 18309, reward 1399.0, memory_length 2000, epsilon 0.00010574183006932749 total_time 721\n",
      "episode 18319, reward 1259.0, memory_length 2000, epsilon 0.00010521444049165296 total_time 722\n",
      "episode 18329, reward 1241.0, memory_length 2000, epsilon 0.00010468968128047047 total_time 722\n",
      "episode 18339, reward 1379.0, memory_length 2000, epsilon 0.00010416753931677277 total_time 734\n",
      "episode 18349, reward 1162.0, memory_length 2000, epsilon 0.0001036480015469832 total_time 727\n",
      "episode 18359, reward 1331.0, memory_length 2000, epsilon 0.00010313105498263064 total_time 722\n",
      "episode 18369, reward 1304.0, memory_length 2000, epsilon 0.00010261668670002424 total_time 722\n",
      "episode 18379, reward 1175.0, memory_length 2000, epsilon 0.0001021048838399298 total_time 728\n",
      "episode 18389, reward 1092.0, memory_length 2000, epsilon 0.00010159563360724949 total_time 723\n",
      "episode 18399, reward 1405.0, memory_length 2000, epsilon 0.00010108892327070063 total_time 727\n",
      "Saving Model 18400\n",
      "episode 18409, reward 1257.0, memory_length 2000, epsilon 0.00010058474016249878 total_time 726\n",
      "episode 18419, reward 1130.0, memory_length 2000, epsilon 0.00010008307167803959 total_time 728\n",
      "episode 18429, reward 1538.0, memory_length 2000, epsilon 9.958390527558502e-05 total_time 731\n",
      "episode 18439, reward 1066.0, memory_length 2000, epsilon 9.90872284759492e-05 total_time 721\n",
      "episode 18449, reward 1210.0, memory_length 2000, epsilon 9.859302886218587e-05 total_time 721\n",
      "episode 18459, reward 1284.0, memory_length 2000, epsilon 9.810129407927935e-05 total_time 726\n",
      "episode 18469, reward 1273.0, memory_length 2000, epsilon 9.761201183383407e-05 total_time 721\n",
      "episode 18479, reward 1011.0, memory_length 2000, epsilon 9.712516989376877e-05 total_time 732\n",
      "episode 18489, reward 1391.0, memory_length 2000, epsilon 9.664075608800927e-05 total_time 728\n",
      "episode 18499, reward 976.0, memory_length 2000, epsilon 9.61587583061855e-05 total_time 721\n",
      "Saving Model 18500\n",
      "episode 18509, reward 1444.0, memory_length 2000, epsilon 9.567916449832749e-05 total_time 721\n",
      "episode 18519, reward 982.0, memory_length 2000, epsilon 9.520196267456524e-05 total_time 727\n",
      "episode 18529, reward 1030.0, memory_length 2000, epsilon 9.472714090482846e-05 total_time 721\n",
      "episode 18539, reward 1379.0, memory_length 2000, epsilon 9.425468731854784e-05 total_time 725\n",
      "episode 18549, reward 1590.0, memory_length 2000, epsilon 9.378459010435946e-05 total_time 726\n",
      "episode 18559, reward 1564.0, memory_length 2000, epsilon 9.331683750980813e-05 total_time 724\n",
      "episode 18569, reward 1085.0, memory_length 2000, epsilon 9.285141784105496e-05 total_time 728\n",
      "episode 18579, reward 1680.0, memory_length 2000, epsilon 9.238831946258369e-05 total_time 726\n",
      "episode 18589, reward 1511.0, memory_length 2000, epsilon 9.192753079691104e-05 total_time 722\n",
      "episode 18599, reward 1669.0, memory_length 2000, epsilon 9.146904032429603e-05 total_time 721\n",
      "Saving Model 18600\n",
      "episode 18609, reward 1245.0, memory_length 2000, epsilon 9.101283658245315e-05 total_time 723\n",
      "episode 18619, reward 1431.0, memory_length 2000, epsilon 9.055890816626525e-05 total_time 729\n",
      "episode 18629, reward 1174.0, memory_length 2000, epsilon 9.010724372749795e-05 total_time 721\n",
      "episode 18639, reward 1527.0, memory_length 2000, epsilon 8.96578319745171e-05 total_time 726\n",
      "episode 18649, reward 1353.0, memory_length 2000, epsilon 8.921066167200515e-05 total_time 723\n",
      "episode 18659, reward 938.0, memory_length 2000, epsilon 8.876572164068152e-05 total_time 725\n",
      "episode 18669, reward 1817.0, memory_length 2000, epsilon 8.8323000757022e-05 total_time 722\n",
      "episode 18679, reward 1125.0, memory_length 2000, epsilon 8.788248795298152e-05 total_time 729\n",
      "episode 18689, reward 1480.0, memory_length 2000, epsilon 8.744417221571728e-05 total_time 721\n",
      "episode 18699, reward 1358.0, memory_length 2000, epsilon 8.700804258731264e-05 total_time 731\n",
      "Saving Model 18700\n",
      "episode 18709, reward 1534.0, memory_length 2000, epsilon 8.657408816450452e-05 total_time 721\n",
      "episode 18719, reward 1513.0, memory_length 2000, epsilon 8.614229809840943e-05 total_time 727\n",
      "episode 18729, reward 1216.0, memory_length 2000, epsilon 8.571266159425355e-05 total_time 727\n",
      "episode 18739, reward 914.0, memory_length 2000, epsilon 8.528516791110156e-05 total_time 728\n",
      "episode 18749, reward 1082.0, memory_length 2000, epsilon 8.485980636158943e-05 total_time 725\n",
      "episode 18759, reward 1255.0, memory_length 2000, epsilon 8.4436566311656e-05 total_time 721\n",
      "episode 18769, reward 1286.0, memory_length 2000, epsilon 8.401543718027809e-05 total_time 722\n",
      "episode 18779, reward 1510.0, memory_length 2000, epsilon 8.359640843920564e-05 total_time 724\n",
      "episode 18789, reward 763.0, memory_length 2000, epsilon 8.317946961269802e-05 total_time 724\n",
      "episode 18799, reward 1331.0, memory_length 2000, epsilon 8.276461027726311e-05 total_time 722\n",
      "Saving Model 18800\n",
      "episode 18809, reward 683.0, memory_length 2000, epsilon 8.235182006139566e-05 total_time 722\n",
      "episode 18819, reward 904.0, memory_length 2000, epsilon 8.194108864531905e-05 total_time 721\n",
      "episode 18829, reward 1030.0, memory_length 2000, epsilon 8.15324057607262e-05 total_time 730\n",
      "episode 18839, reward 1109.0, memory_length 2000, epsilon 8.112576119052399e-05 total_time 725\n",
      "episode 18849, reward 1011.0, memory_length 2000, epsilon 8.07211447685767e-05 total_time 723\n",
      "episode 18859, reward 933.0, memory_length 2000, epsilon 8.031854637945286e-05 total_time 726\n",
      "episode 18869, reward 1601.0, memory_length 2000, epsilon 7.99179559581719e-05 total_time 722\n",
      "episode 18879, reward 1362.0, memory_length 2000, epsilon 7.951936348995216e-05 total_time 723\n",
      "episode 18889, reward 1299.0, memory_length 2000, epsilon 7.912275900996144e-05 total_time 723\n",
      "episode 18899, reward 868.0, memory_length 2000, epsilon 7.872813260306681e-05 total_time 721\n",
      "Saving Model 18900\n",
      "episode 18909, reward 758.0, memory_length 2000, epsilon 7.833547440358784e-05 total_time 725\n",
      "episode 18919, reward 1325.0, memory_length 2000, epsilon 7.794477459504877e-05 total_time 725\n",
      "episode 18929, reward 1057.0, memory_length 2000, epsilon 7.755602340993422e-05 total_time 721\n",
      "episode 18939, reward 1176.0, memory_length 2000, epsilon 7.716921112944443e-05 total_time 726\n",
      "episode 18949, reward 1164.0, memory_length 2000, epsilon 7.678432808325197e-05 total_time 723\n",
      "episode 18959, reward 674.0, memory_length 2000, epsilon 7.640136464926093e-05 total_time 731\n",
      "episode 18969, reward 1162.0, memory_length 2000, epsilon 7.602031125336521e-05 total_time 727\n",
      "episode 18979, reward 1465.0, memory_length 2000, epsilon 7.564115836921035e-05 total_time 724\n",
      "episode 18989, reward 1448.0, memory_length 2000, epsilon 7.526389651795426e-05 total_time 722\n",
      "episode 18999, reward 1624.0, memory_length 2000, epsilon 7.488851626803123e-05 total_time 721\n",
      "Saving Model 19000\n",
      "episode 19009, reward 1545.0, memory_length 2000, epsilon 7.451500823491522e-05 total_time 726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 19019, reward 1724.0, memory_length 2000, epsilon 7.414336308088607e-05 total_time 728\n",
      "episode 19029, reward 1295.0, memory_length 2000, epsilon 7.377357151479571e-05 total_time 722\n",
      "episode 19039, reward 1286.0, memory_length 2000, epsilon 7.340562429183548e-05 total_time 731\n",
      "episode 19049, reward 1254.0, memory_length 2000, epsilon 7.303951221330587e-05 total_time 723\n",
      "episode 19059, reward 1281.0, memory_length 2000, epsilon 7.267522612638562e-05 total_time 732\n",
      "episode 19069, reward 1059.0, memory_length 2000, epsilon 7.231275692390381e-05 total_time 726\n",
      "episode 19079, reward 1381.0, memory_length 2000, epsilon 7.195209554411128e-05 total_time 721\n",
      "episode 19089, reward 1482.0, memory_length 2000, epsilon 7.1593232970455e-05 total_time 726\n",
      "episode 19099, reward 967.0, memory_length 2000, epsilon 7.123616023135166e-05 total_time 721\n",
      "Saving Model 19100\n",
      "episode 19109, reward 1246.0, memory_length 2000, epsilon 7.088086839996432e-05 total_time 721\n",
      "episode 19119, reward 1520.0, memory_length 2000, epsilon 7.052734859397882e-05 total_time 722\n",
      "episode 19129, reward 1497.0, memory_length 2000, epsilon 7.017559197538135e-05 total_time 723\n",
      "episode 19139, reward 1506.0, memory_length 2000, epsilon 6.982558975023835e-05 total_time 723\n",
      "episode 19149, reward 1147.0, memory_length 2000, epsilon 6.947733316847577e-05 total_time 721\n",
      "episode 19159, reward 1085.0, memory_length 2000, epsilon 6.913081352366113e-05 total_time 728\n",
      "episode 19169, reward 1429.0, memory_length 2000, epsilon 6.8786022152785e-05 total_time 724\n",
      "episode 19179, reward 1101.0, memory_length 2000, epsilon 6.844295043604533e-05 total_time 723\n",
      "episode 19189, reward 1280.0, memory_length 2000, epsilon 6.81015897966314e-05 total_time 725\n",
      "episode 19199, reward 1019.0, memory_length 2000, epsilon 6.776193170050924e-05 total_time 725\n",
      "Saving Model 19200\n",
      "episode 19209, reward 1244.0, memory_length 2000, epsilon 6.742396765620898e-05 total_time 725\n",
      "episode 19219, reward 1480.0, memory_length 2000, epsilon 6.708768921461167e-05 total_time 721\n",
      "episode 19229, reward 1469.0, memory_length 2000, epsilon 6.6753087968739e-05 total_time 725\n",
      "episode 19239, reward 891.0, memory_length 2000, epsilon 6.642015555354215e-05 total_time 729\n",
      "episode 19249, reward 985.0, memory_length 2000, epsilon 6.608888364569364e-05 total_time 721\n",
      "episode 19259, reward 1387.0, memory_length 2000, epsilon 6.575926396337829e-05 total_time 727\n",
      "episode 19269, reward 1218.0, memory_length 2000, epsilon 6.543128826608699e-05 total_time 723\n",
      "episode 19279, reward 1399.0, memory_length 2000, epsilon 6.510494835441036e-05 total_time 721\n",
      "episode 19289, reward 1551.0, memory_length 2000, epsilon 6.478023606983333e-05 total_time 723\n",
      "episode 19299, reward 1699.0, memory_length 2000, epsilon 6.445714329453216e-05 total_time 724\n",
      "Saving Model 19300\n",
      "episode 19309, reward 1481.0, memory_length 2000, epsilon 6.413566195117036e-05 total_time 728\n",
      "episode 19319, reward 1102.0, memory_length 2000, epsilon 6.381578400269788e-05 total_time 721\n",
      "episode 19329, reward 1468.0, memory_length 2000, epsilon 6.349750145214908e-05 total_time 727\n",
      "episode 19339, reward 1615.0, memory_length 2000, epsilon 6.318080634244387e-05 total_time 721\n",
      "episode 19349, reward 1668.0, memory_length 2000, epsilon 6.286569075618777e-05 total_time 723\n",
      "episode 19359, reward 1658.0, memory_length 2000, epsilon 6.255214681547484e-05 total_time 725\n",
      "episode 19369, reward 1289.0, memory_length 2000, epsilon 6.224016668169033e-05 total_time 725\n",
      "episode 19379, reward 1321.0, memory_length 2000, epsilon 6.192974255531442e-05 total_time 724\n",
      "episode 19389, reward 1356.0, memory_length 2000, epsilon 6.162086667572802e-05 total_time 726\n",
      "episode 19399, reward 1288.0, memory_length 2000, epsilon 6.131353132101784e-05 total_time 727\n",
      "Saving Model 19400\n",
      "episode 19409, reward 1434.0, memory_length 2000, epsilon 6.10077288077842e-05 total_time 732\n",
      "episode 19419, reward 1302.0, memory_length 2000, epsilon 6.070345149094813e-05 total_time 726\n",
      "episode 19429, reward 1686.0, memory_length 2000, epsilon 6.040069176356098e-05 total_time 723\n",
      "episode 19439, reward 1748.0, memory_length 2000, epsilon 6.00994420566139e-05 total_time 725\n",
      "episode 19449, reward 1225.0, memory_length 2000, epsilon 5.979969483884831e-05 total_time 727\n",
      "episode 19459, reward 1042.0, memory_length 2000, epsilon 5.950144261656836e-05 total_time 724\n",
      "episode 19469, reward 1111.0, memory_length 2000, epsilon 5.920467793345276e-05 total_time 721\n",
      "episode 19479, reward 1039.0, memory_length 2000, epsilon 5.890939337036918e-05 total_time 721\n",
      "episode 19489, reward 1084.0, memory_length 2000, epsilon 5.8615581545187955e-05 total_time 721\n",
      "episode 19499, reward 1417.0, memory_length 2000, epsilon 5.8323235112598366e-05 total_time 721\n",
      "Saving Model 19500\n",
      "episode 19509, reward 1376.0, memory_length 2000, epsilon 5.803234676392415e-05 total_time 722\n",
      "episode 19519, reward 1276.0, memory_length 2000, epsilon 5.774290922694156e-05 total_time 724\n",
      "episode 19529, reward 1308.0, memory_length 2000, epsilon 5.7454915265697185e-05 total_time 723\n",
      "episode 19539, reward 993.0, memory_length 2000, epsilon 5.71683576803268e-05 total_time 723\n",
      "episode 19549, reward 1299.0, memory_length 2000, epsilon 5.6883229306876056e-05 total_time 732\n",
      "episode 19559, reward 1218.0, memory_length 2000, epsilon 5.659952301712054e-05 total_time 723\n",
      "episode 19569, reward 1309.0, memory_length 2000, epsilon 5.631723171838846e-05 total_time 721\n",
      "episode 19579, reward 1264.0, memory_length 2000, epsilon 5.603634835338242e-05 total_time 721\n",
      "episode 19589, reward 1399.0, memory_length 2000, epsilon 5.575686590000387e-05 total_time 721\n",
      "episode 19599, reward 1113.0, memory_length 2000, epsilon 5.547877737117674e-05 total_time 726\n",
      "Saving Model 19600\n",
      "episode 19609, reward 1361.0, memory_length 2000, epsilon 5.5202075814673405e-05 total_time 725\n",
      "episode 19619, reward 1183.0, memory_length 2000, epsilon 5.492675431294065e-05 total_time 721\n",
      "episode 19629, reward 844.0, memory_length 2000, epsilon 5.465280598292639e-05 total_time 724\n",
      "episode 19639, reward 1260.0, memory_length 2000, epsilon 5.43802239759083e-05 total_time 729\n",
      "episode 19649, reward 1313.0, memory_length 2000, epsilon 5.410900147732182e-05 total_time 722\n",
      "episode 19659, reward 1109.0, memory_length 2000, epsilon 5.383913170659055e-05 total_time 725\n",
      "episode 19669, reward 1090.0, memory_length 2000, epsilon 5.357060791695596e-05 total_time 727\n",
      "episode 19679, reward 1210.0, memory_length 2000, epsilon 5.330342339530945e-05 total_time 730\n",
      "episode 19689, reward 1279.0, memory_length 2000, epsilon 5.303757146202413e-05 total_time 727\n",
      "episode 19699, reward 1331.0, memory_length 2000, epsilon 5.277304547078765e-05 total_time 722\n",
      "Saving Model 19700\n",
      "episode 19709, reward 1146.0, memory_length 2000, epsilon 5.2509838808436624e-05 total_time 723\n",
      "episode 19719, reward 1192.0, memory_length 2000, epsilon 5.224794489479061e-05 total_time 721\n",
      "episode 19729, reward 1091.0, memory_length 2000, epsilon 5.198735718248831e-05 total_time 725\n",
      "episode 19739, reward 1086.0, memory_length 2000, epsilon 5.172806915682314e-05 total_time 726\n",
      "episode 19749, reward 1286.0, memory_length 2000, epsilon 5.1470074335581175e-05 total_time 722\n",
      "episode 19759, reward 1466.0, memory_length 2000, epsilon 5.1213366268878236e-05 total_time 722\n",
      "episode 19769, reward 1327.0, memory_length 2000, epsilon 5.095793853899938e-05 total_time 721\n",
      "episode 19779, reward 1321.0, memory_length 2000, epsilon 5.0703784760238156e-05 total_time 724\n",
      "episode 19789, reward 1682.0, memory_length 2000, epsilon 5.045089857873667e-05 total_time 722\n",
      "episode 19799, reward 1223.0, memory_length 2000, epsilon 5.01992736723274e-05 total_time 722\n",
      "Saving Model 19800\n",
      "episode 19809, reward 1365.0, memory_length 2000, epsilon 4.994890375037439e-05 total_time 726\n",
      "episode 19819, reward 1452.0, memory_length 2000, epsilon 4.969978255361674e-05 total_time 723\n",
      "episode 19829, reward 1403.0, memory_length 2000, epsilon 4.9451903854011375e-05 total_time 722\n",
      "episode 19839, reward 1001.0, memory_length 2000, epsilon 4.920526145457798e-05 total_time 725\n",
      "episode 19849, reward 1149.0, memory_length 2000, epsilon 4.8959849189243816e-05 total_time 726\n",
      "episode 19859, reward 1247.0, memory_length 2000, epsilon 4.871566092268928e-05 total_time 728\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 19869, reward 1080.0, memory_length 2000, epsilon 4.8472690550195184e-05 total_time 729\n",
      "episode 19879, reward 1115.0, memory_length 2000, epsilon 4.823093199748938e-05 total_time 722\n",
      "episode 19889, reward 1120.0, memory_length 2000, epsilon 4.7990379220595626e-05 total_time 721\n",
      "episode 19899, reward 805.0, memory_length 2000, epsilon 4.77510262056818e-05 total_time 721\n",
      "Saving Model 19900\n",
      "episode 19909, reward 1123.0, memory_length 2000, epsilon 4.751286696891023e-05 total_time 724\n",
      "episode 19919, reward 777.0, memory_length 2000, epsilon 4.7275895556287444e-05 total_time 723\n",
      "episode 19929, reward 1003.0, memory_length 2000, epsilon 4.7040106043515844e-05 total_time 721\n",
      "episode 19939, reward 1278.0, memory_length 2000, epsilon 4.6805492535845425e-05 total_time 729\n",
      "episode 19949, reward 1508.0, memory_length 2000, epsilon 4.6572049167926106e-05 total_time 728\n",
      "episode 19959, reward 987.0, memory_length 2000, epsilon 4.63397701036617e-05 total_time 726\n",
      "episode 19969, reward 1264.0, memory_length 2000, epsilon 4.6108649536063335e-05 total_time 721\n",
      "episode 19979, reward 1280.0, memory_length 2000, epsilon 4.587868168710495e-05 total_time 725\n",
      "episode 19989, reward 985.0, memory_length 2000, epsilon 4.564986080757817e-05 total_time 721\n",
      "episode 19999, reward 1146.0, memory_length 2000, epsilon 4.542218117694926e-05 total_time 723\n",
      "19787.066347837448\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "state_size = 36 # m + t + d value\n",
    "action_size = len(env.action_space)\n",
    "\n",
    "agent = DQNAgent(state_size, action_size)\n",
    "\n",
    "rewards_per_episode, episodes = [], []\n",
    "reward_initial_stat=[]\n",
    "score_track=[]\n",
    "\n",
    "for episode in range(Episodes):\n",
    "        done = False\n",
    "        score = 0\n",
    "        # total_time is variable to track total number of hours cab is running for defining terminal state\n",
    "        total_time=0\n",
    "        env = CabDriver()\n",
    "        action_space, state_space, state = env.reset()\n",
    "        \n",
    "        # Saving the initial state such that Reward can be tracked if initial state is [0,0,0]\n",
    "        initial_state = env.state_init\n",
    "        \n",
    "        while not done:\n",
    "            possible_act_idx,actions=env.requests(state)\n",
    "            #getting action via epsilon-greedy policy\n",
    "            action = agent.get_action(state,possible_act_idx)\n",
    "            #finding the next state,reward,time taken for current action from enviroment using step function\n",
    "            next_state,reward,curr_time_taken=env.step(state, env.action_space[action])\n",
    "\n",
    "            total_time+=curr_time_taken\n",
    "\n",
    "            if total_time>720:\n",
    "                #terminal state so turning done to true\n",
    "                done=True\n",
    "                #reward=0  #Terminal state\n",
    "            else:\n",
    "                pass\n",
    "            \n",
    "            #here we are tracking and appending terminal state to the memory buffer\n",
    "            agent.append_sample(state, action, reward, next_state,done)\n",
    "            agent.train_model()\n",
    "\n",
    "            score += reward\n",
    "            state = next_state\n",
    "            \n",
    "        rewards_per_episode.append(score)\n",
    "        episodes.append(episode)\n",
    "        #Epsilon value based on epsilon decay rate , new epsilon value is getting assigned to Agent object of DQNAgent class\n",
    "        agent.epsilon = (1 - 0.00001) * np.exp(agent.epsilon_decay * episode)\n",
    "        \n",
    "        if ((episode + 1) % 10 == 0):\n",
    "            print(\"episode {0}, reward {1}, memory_length {2}, epsilon {3} total_time {4}\".format(episode,\n",
    "                                                                         score,\n",
    "                                                                         len(agent.memory),\n",
    "                                                                         agent.epsilon, total_time)) \n",
    "        \n",
    "        \n",
    "        if ((episode + 1) % 5 == 0):            \n",
    "            agent.save_tracking_states()\n",
    "            #Tracking and saving state of (0,0,0) and action (0,4)\n",
    "\n",
    "    # Total rewards per episode\n",
    "        score_track.append(score)\n",
    "\n",
    "        if(episode % 100 == 0):\n",
    "            #saving model and weights every 100th episode\n",
    "            print(\"Saving Model {}\".format(episode))\n",
    "            agent.model.save_weights(\"model_weights.h5\")\n",
    "            agent.save(name=\"model_weights.pkl\")\n",
    "\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print(elapsed_time)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the final model and its weights\n",
    "agent.save(name=\"model_weights.pkl\")\n",
    "agent.model.save_weights(\"model_weights.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tracking Convergence of state(0,0,0) and action (0,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(0, figsize=(18,7))\n",
    "plt.title('Tracked Q_value for state (0,0,0) with action (0,4)')\n",
    "x_axis = np.asarray(range(0, len(agent.states_tracked)))\n",
    "plt.semilogy(x_axis,np.asarray(agent.states_tracked))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Q_Value: 377.72454833984375 and median is :375.3432312011719 \n",
      "\n",
      "[501.43567, 486.72144, 469.37552, 445.63824, 346.9328, 362.49515, 368.91068, 434.14166, 383.10733, 342.42654, 349.858, 326.36578, 330.51138, 289.4025, 334.68863, 454.6852, 474.71106, 413.5101, 324.9523, 347.7299, 382.16638, 455.28372, 379.1393, 353.05356, 350.34958, 325.7802, 315.06464, 307.35544, 417.0599, 392.90643, 583.2118, 456.98843, 397.1805, 394.48584, 397.89993, 361.3827, 380.07706, 501.6907, 433.64062, 407.56537, 458.68158, 399.40427, 371.6311, 400.3941, 317.17776, 369.9804, 397.51727, 390.74213, 381.4889, 375.00586, 359.2118, 331.97992, 401.72073, 399.9915, 340.75903, 496.35812, 423.82507, 563.6121, 518.0796, 377.25882, 392.46387, 357.7691, 300.92096, 286.8573, 326.90427, 338.56955, 354.2586, 317.11768, 302.15637, 512.6676, 483.3071, 334.9135, 292.80975, 296.3167, 339.32507, 394.79837, 361.1189, 468.5018, 417.7755, 483.59058, 443.1943, 419.64432, 467.3436, 414.2711, 402.54266, 427.89514, 407.76874, 433.4146, 419.5197, 358.254, 426.57785, 396.25436, 496.85635, 362.92438, 382.9887, 312.49454, 299.0567, 293.61343, 366.5761, 352.74155, 369.91504, 399.89612, 371.94562, 335.68442, 322.7362, 399.61877, 340.42096, 344.16846, 359.71332, 441.40628, 327.34042, 359.42062, 391.0129, 373.13898, 426.45526, 436.95016, 484.6226, 431.277, 376.42862, 392.27014, 369.51526, 409.62546, 397.51648, 389.7761, 349.1609, 319.80585, 347.72787, 333.79767, 369.28793, 360.40964, 374.1252, 389.9555, 367.4318, 381.09845, 351.40512, 373.2367, 351.8056, 401.11105, 348.4412, 312.0724, 360.80923, 343.77466, 387.80365, 352.26385, 341.1569, 399.18872, 398.9052, 342.63922, 341.36252, 293.37897, 365.49536, 473.33484, 483.81525, 435.54712, 411.96497, 334.59644, 364.02075, 360.90283, 326.68848, 321.08286, 332.913, 396.55374, 397.7049, 312.4773, 340.09668, 323.2768, 391.30682, 376.68274, 392.1117, 429.9678, 375.2586, 370.27853, 342.5244, 354.02344, 394.52017, 385.77014, 349.7528, 377.12726, 375.49615, 375.65314, 380.87897, 358.40915, 323.5825, 374.65616, 375.6977, 392.09866, 383.03317, 386.81055, 362.4665, 368.98572, 326.71375, 332.40637, 384.40936, 395.70407, 355.37326, 390.37042, 444.85532, 370.39713, 400.78403, 339.76273, 364.24152, 363.03992, 400.10156, 352.07993, 379.56656, 349.33875, 338.24564, 416.4861, 476.29514, 459.20694, 384.38757, 351.4963, 375.11685, 381.58905, 409.6083, 393.93814, 400.01257, 414.56186, 381.3272, 386.34128, 366.86902, 366.65057, 396.85022, 376.21072, 513.3652, 473.03754, 511.4568, 443.68213, 418.50977, 433.04163, 434.31628, 430.39694, 447.7612, 414.93765, 397.9463, 347.30252, 358.01056, 372.96405, 439.75122, 386.69016, 374.94543, 423.0141, 380.24673, 382.80704, 410.58276, 387.37357, 387.44058, 361.3833, 439.41827, 440.36642, 388.31424, 421.11758, 499.64993, 423.29712, 385.88492, 355.1143, 394.3199, 395.85138, 420.35562, 380.954, 341.95932, 352.05676, 421.4073, 441.70273, 386.2646, 357.7897, 289.81232, 329.38162, 352.47833, 386.40662, 376.34244, 366.20285, 470.10745, 389.8365, 399.57272, 428.93097, 401.88364, 390.21323, 415.98386, 431.87622, 433.65735, 377.87167, 348.93903, 376.44855, 348.81274, 346.4455, 333.2363, 370.57196, 379.2387, 344.16348, 359.07568, 359.51593, 342.01096, 343.17078, 424.81174, 406.22205, 364.8514, 377.1521, 389.02875, 379.10693, 404.32355, 387.7583, 373.5152, 360.00943, 472.2192, 439.38962, 415.8245, 377.95346, 438.0563, 402.92725, 383.07144, 373.78177, 370.07065, 373.68646, 408.81845, 399.47906, 378.47195, 382.82538, 374.305, 393.63693, 357.8957, 367.46487, 339.08118, 412.96292, 377.44473, 401.2851, 385.78918, 422.13754, 427.6724, 399.15036, 380.08838, 387.04034, 426.93253, 389.4512, 413.58353, 406.16998, 403.9616, 403.36777, 407.41885, 382.21295, 402.80777, 385.33655, 424.77454, 402.82062, 365.49118, 369.04416, 422.3588, 408.6246, 448.4916, 393.3708, 381.35852, 447.41522, 357.245, 329.49084, 413.8927, 397.0163, 350.9717, 350.12973, 371.55823, 379.2511, 382.1199, 350.8742, 380.04514, 429.92865, 449.8275, 391.04297, 438.6046, 391.82953, 437.2244, 366.02353, 346.15765, 323.16876, 316.88147, 353.57095, 361.99713, 376.84637, 359.47763, 367.92377, 415.26367, 406.34158, 368.01276, 357.58566, 360.26956, 395.61777, 413.0535, 378.31494, 362.82938, 371.79373, 385.32025, 411.4475, 388.74603, 384.0833, 366.06244, 406.81705, 376.44272, 365.92126, 330.588, 381.8564, 427.76718, 391.9324, 434.80826, 452.40707, 416.26312, 366.50906, 358.75693, 384.00644, 382.8866, 392.14423, 404.37985, 390.52063, 402.0298, 398.01987, 426.5114, 421.3019, 352.83325, 339.668, 385.77338, 363.85455, 387.25018, 325.8291, 340.29147, 346.8684, 388.26193, 433.17218, 359.79675, 358.29004, 370.61603, 366.76968, 372.11774, 344.9249, 334.58154, 353.44485, 336.04083, 332.95792, 368.36926, 381.9563, 421.72064, 440.1272, 377.5182, 383.06604, 381.1026, 373.07794, 373.30438, 398.5273, 369.91818, 367.9106, 393.7957, 369.1097, 325.21603, 344.43253, 365.21622, 374.98993, 377.00848, 389.59412, 423.21582, 396.21445, 346.4282, 339.91074, 372.07, 344.96344, 377.63678, 418.33655, 357.9555, 346.39322, 348.17142, 398.3971, 365.2158, 348.70493, 360.3982, 386.6221, 314.97058, 387.248, 338.0543, 357.25, 397.513, 382.68906, 407.5528, 357.6061, 367.11957, 360.807, 357.96307, 333.38742, 397.68878, 385.56595, 396.59787, 442.3248, 350.39014, 398.32672, 398.88904, 388.32584, 379.87955, 363.70743, 374.4266, 363.86368, 357.47568, 349.2176, 392.5354, 365.54718, 360.76047, 377.5728, 377.1769, 361.6266, 359.2989, 353.49908, 346.17712, 348.81915, 369.73853, 352.3881, 377.62808, 372.30478, 383.50797, 333.36108, 380.57693, 357.24634, 409.1879, 362.0711, 370.25815, 395.00354, 356.1832, 383.71054, 368.7015, 384.06003, 398.40915, 389.12927, 404.9838, 372.8143, 416.3364, 401.17505, 394.0362, 391.37204, 400.71835, 382.11844, 368.64642, 403.09613, 378.2327, 410.23053, 391.0327, 436.0581, 408.60336, 409.35458, 452.8398, 358.10706, 365.75858, 369.17545, 404.69083, 353.418, 398.51254, 430.41876, 435.65347, 376.47638, 396.9619, 414.18765, 392.57196, 389.90833, 367.30722, 388.2495, 379.48105, 402.4909, 411.05994, 451.1725, 434.46277, 429.9322, 439.78223, 390.02878, 368.60913, 373.61935, 374.19125, 393.03546, 400.4957, 385.01138, 392.93533, 400.86298, 453.97736, 422.5925, 392.3409, 379.46304, 358.62848, 415.60614, 367.97186, 388.22742, 377.0564, 394.45532, 415.9833, 436.23694, 409.81967, 387.30325, 378.29523, 406.63806, 412.59177, 381.71002, 380.35345, 332.77628, 357.5353, 364.87698, 381.39453, 401.02124, 384.16183, 419.92767, 400.52692, 459.33722, 398.9805, 428.7121, 416.2615, 447.91235, 474.15973, 452.54794, 402.3808, 360.6962, 380.47266, 374.41962, 443.36893, 445.16006, 406.02478, 414.84857, 424.2524, 401.82233, 388.8941, 368.9627, 403.9029, 364.845, 398.37103, 405.37436, 387.38086, 429.63528, 417.4078, 390.68777, 438.86185, 405.43042, 421.45218, 386.3353, 392.00565, 440.4204, 438.9461, 393.1746, 391.43802, 394.67108, 452.08105, 387.25247, 434.60477, 401.90973, 415.41507, 402.37808, 441.42065, 406.01547, 387.97827, 429.0823, 433.39294, 395.95947, 367.14142, 374.43033, 389.14795, 370.91373, 385.86084, 374.5549, 372.87933, 359.0791, 389.41364, 358.94778, 339.31155, 330.27036, 342.46677, 349.7503, 350.2862, 371.50192, 391.02692, 386.0567, 409.4028, 404.65533, 359.2464, 358.72568, 357.6037, 400.25632, 440.1446, 374.85092, 376.72906, 369.97394, 378.06635, 373.52304, 449.13135, 349.51672, 380.65237, 384.27478, 386.68707, 338.839, 391.6208, 375.19034, 393.94922, 364.4411, 407.2908, 373.46985, 378.84595, 347.74677, 349.19205, 343.03885, 386.35263, 386.39236, 398.89398, 390.53653, 415.06656, 401.7143, 410.76788, 381.34366, 427.762, 407.75412, 374.75052, 362.74738, 375.36575, 379.85495, 412.39966, 408.03394, 403.67157, 422.27893, 391.2717, 377.19745, 336.00876, 372.8854, 368.54907, 368.63184, 373.8615, 376.5769, 389.31015, 371.9818, 375.41794, 389.34747, 388.27856, 427.95847, 350.26703, 335.16223, 375.24405, 356.3081, 374.93655, 363.4128, 369.5981, 366.35522, 404.60748, 371.6799, 357.1989, 346.7347, 345.10345, 380.39752, 383.70636, 347.01547, 348.24704, 323.11942, 376.0478, 369.6726, 330.0309, 302.47473, 327.4924, 409.95566, 388.70538, 418.43384, 418.98877, 386.65805, 369.24335, 385.9363, 372.5353, 360.83658, 390.62482, 373.43475, 371.14746, 339.23447, 354.47086, 371.2534, 365.9205, 336.61557, 327.50452, 344.57846, 338.8214, 366.23322, 379.22186, 388.3058, 355.01065, 372.08142, 391.5616, 414.91437, 360.2416, 341.6798, 356.31445, 363.71448, 395.80264, 371.83292, 369.08923, 411.04156, 369.29364, 358.39026, 375.38562, 422.83572, 405.3084, 376.97937, 393.97308, 367.279, 369.92343, 388.1846, 411.00385, 433.0576, 411.05786, 389.09012, 356.97348, 404.58386, 407.69357, 402.67593, 416.70978, 377.69202, 386.9722, 403.11566, 405.17136, 407.52478, 426.44504, 407.7226, 364.95987, 362.50696, 365.80508, 416.54965, 409.46957, 422.7019, 430.39954, 415.3238, 368.4459, 382.68283, 376.46094, 385.7577, 391.33612, 388.6638, 383.08093, 378.34235, 380.82843, 393.54758, 419.51193, 424.63388, 402.9266, 359.02463, 343.2932, 328.77374, 356.3858, 341.94473, 346.12744, 343.43735, 360.06644, 355.93112, 369.94992, 407.6393, 429.95404, 396.21417, 383.85703, 384.13715, 406.84088, 435.41827, 410.63852, 372.2892, 415.66418, 367.71188, 383.10672, 349.79153, 367.7615, 332.7279, 364.72513, 350.3468, 383.65564, 364.65814, 376.10004, 368.38184, 376.14362, 323.07684, 344.2188, 342.1684, 373.87494, 362.1224, 374.12997, 384.6476, 400.31012, 406.94946, 391.55783, 389.17587, 404.2544, 381.95184, 417.1898, 430.28366, 421.07013, 471.75726, 454.79297, 406.07907, 357.46262, 401.46436, 429.45367, 410.78107, 421.10522, 439.35397, 451.80753, 398.6449, 398.28723, 378.14456, 387.15753, 374.47662, 409.5531, 375.25256, 378.54276, 368.4706, 339.64124, 381.26297, 416.15207, 449.44977, 455.32993, 452.01587, 418.0303, 421.77377, 438.44946, 421.80295, 375.02847, 428.23996, 425.4344, 431.22736, 415.61447, 380.83722, 413.03525, 396.50262, 426.64996, 415.0182, 411.7372, 426.37814, 424.71667, 421.30524, 416.85156, 412.21664, 379.88843, 348.88947, 352.08325, 366.89346, 408.67984, 420.38077, 437.6065, 395.2437, 422.11575, 397.67447, 407.01495, 398.90466, 398.511, 381.4098, 433.1868, 477.16953, 495.85126, 463.7919, 444.62033, 450.64392, 462.36066, 446.76666, 406.34616, 414.67395, 412.07224, 399.59174, 405.3778, 378.08688, 397.59875, 407.75003, 404.43872, 399.03732, 385.98917, 404.72226, 407.06052, 376.21753, 373.71402, 421.42102, 418.1705, 440.5104, 432.1714, 417.90567, 436.93295, 450.389, 425.1737, 383.87378, 365.7283, 393.26697, 381.34427, 384.76736, 412.2226, 397.58487, 400.6336, 399.4475, 394.37317, 382.36197, 411.2364, 430.737, 455.41617, 451.1855, 448.22876, 422.3675, 375.28912, 406.2208, 406.59387, 395.1426, 413.26633, 442.30716, 444.37372, 421.05426, 424.44965, 429.9496, 392.7719, 386.31662, 352.3294, 350.88467, 401.74078, 403.59323, 426.37473, 418.7471, 457.89093, 456.80557, 433.23114, 428.95398, 413.56467, 436.4684, 438.7394, 451.6323, 435.11304, 439.56628, 415.00845, 436.184, 448.53262, 446.4613, 448.16962, 452.60083, 418.84326, 399.8266, 402.7097, 408.0238, 401.78625, 409.66324, 428.1971, 434.74118, 446.26083, 451.77673, 434.91296, 416.37427, 358.48148, 389.0815, 395.45364, 430.9998, 484.07678, 465.78943, 438.05136, 406.8761, 423.51318, 454.9738, 429.18533, 425.6149, 383.89246, 417.85864, 411.26852, 409.3211, 409.72736, 395.82053, 421.61588, 384.9898, 380.15045, 340.70026, 376.80673, 389.85648, 378.21463, 2211.9504, 758.0855, 417.49966, 191.35019, 156.78954, 290.40268, 271.283, 308.134, 285.7955, 368.40454, 352.66898, 337.57632, 350.30182, 392.6831, 356.90082, 427.15283, 361.52927, 313.62234, 319.90887, 371.37485, 353.6048, 381.96866, 368.6091, 361.47272, 395.55692, 386.23187, 416.82205, 376.06717, 391.56522, 368.14426, 353.05627, 360.04855, 331.72366, 359.2985, 396.81793, 387.7983, 421.55554, 458.21756, 448.99188, 441.41983, 450.56482, 408.8638, 385.79236, 408.5948, 378.24463, 368.73837, 352.5395, 424.48502, 433.51273, 367.0276, 405.32657, 406.56525, 404.53006, 398.91138, 400.73553, 407.9125, 384.76562, 415.3735, 426.11838, 389.05347, 340.97467, 399.29373, 379.15875, 401.7843, 379.8309, 407.48004, 383.39392, 415.46826, 381.7831, 416.3122, 358.04425, 423.4108, 438.22144, 423.38208, 407.75168, 423.44254, 412.58737, 395.75793, 421.3639, 444.08344, 425.7172, 388.22726, 391.71957, 401.48022, 425.5754, 447.81412, 426.54224, 412.3361, 415.0549, 397.326, 433.36377, 451.55032, 449.5001, 452.04614, 440.80908, 420.78632, 454.47382, 455.94507, 460.60785, 434.26807, 417.28757, 429.95758, 459.6296, 460.99628, 439.81036, 429.51285, 434.73874, 437.2708, 453.591, 425.36584, 393.69272, 387.0004, 390.34042, 394.53104, 428.50327, 416.00946, 358.11545, 358.00787, 359.74493, 444.65964, 398.6355, 366.9062, 385.85245, 415.69095, 438.1943, 442.28625, 394.9542, 368.5301, 391.04196, 371.8381, 384.4854, 411.98282, 450.26147, 423.19464, 366.2838, 401.02277, 470.85486, 385.70367, 385.3896, 361.88422, 388.1686, 393.66385, 408.30807, 449.79526, 435.23883, 416.8641, 430.30295, 418.82346, 418.05405, 409.03967, 388.01517, 409.6496, 419.01544, 435.34622, 408.8122, 442.53918, 416.22864, 414.59088, 410.9849, 403.43274, 412.60748, 425.18024, 416.30032, 431.01547, 438.76828, 397.29373, 382.94202, 377.60297, 389.93332, 408.61127, 403.49594, 437.07034, 477.73666, 469.6196, 469.78552, 391.81836, 386.95926, 392.7001, 398.17273, 381.24213, 402.05432, 404.25232, 393.88757, 381.89835, 378.85675, 383.6676, 419.7763, 423.00818, 405.0017, 365.26636, 349.26538, 349.9455, 345.92862, 386.59656, 455.24506, 434.81564, 408.57956, 428.34756, 408.22357, 391.76068, 372.80148, 401.49084, 413.85202, 419.22427, 397.786, 426.29965, 437.41382, 432.60922, 467.68988, 421.18143, 390.49487, 411.26147, 441.21225, 451.36548, 433.71378, 365.89423, 374.31042, 415.50073, 454.72226, 457.76053, 452.16632, 444.18082, 476.24258, 479.4531, 503.87207, 453.19897, 401.94577, 358.55167, 381.6471, 385.9137, 386.41324, 429.25375, 407.40738, 423.9251, 394.2069, 406.0683, 406.1548, 418.50366, 393.6757, 452.63654, 431.4094, 450.7428, 443.89935, 435.80746, 411.37762, 440.669, 417.2476, 420.8894, 430.78268, 419.45148, 449.95877, 401.81775, 410.1993, 419.39246, 463.82202, 428.1896, 398.90225, 395.008, 427.559, 417.48682, 429.66364, 434.28214, 429.0536, 447.61917, 439.84763, 397.4253, 422.97412, 401.73895, 408.75455, 422.6899, 372.24823, 359.1405, 374.4781, 346.65552, 354.9035, 390.12033, 402.88925, 412.7942, 414.51413, 407.97406, 398.25125, 391.7508, 406.2367, 424.46988, 447.26535, 421.0534, 435.76962, 394.52997, 384.06888, 396.53177, 384.94818, 405.15363, 378.215, 401.0968, 411.58157, 361.52167, 379.60376, 409.37003, 443.69745, 451.2329, 424.62875, 386.22385, 386.14542, 381.81116, 387.54935, 392.68884, 381.74985, 387.15668, 393.99167, 413.1285, 406.82117, 380.63, 366.67667, 397.73807, 385.9815, 365.7376, 382.92563, 363.24216, 387.9408, 436.01102, 397.25385, 393.26273, 423.83548, 408.29742, 422.20514, 390.99213, 367.79257, 360.87354, 399.62787, 417.91037, 418.1381, 382.79886, 388.09775, 456.8102, 456.05026, 446.43964, 415.48474, 400.94925, 405.35287, 403.1319, 388.11075, 357.995, 367.29767, 375.47775, 404.35397, 392.89178, 387.16415, 380.53732, 373.4553, 388.21582, 387.22916, 390.59152, 433.303, 409.2999, 379.75003, 366.57132, 386.9604, 345.0768, 359.65933, 360.3133, 372.0767, 391.4146, 372.26437, 396.1918, 361.38474, 326.4646, 340.25854, 351.3348, 351.6307, 357.60394, 297.95712, 320.0994, 330.2043, 378.7291, 413.45303, 387.05353, 333.6181, 364.70276, 339.98203, 328.71384, 348.04724, 333.14697, 348.63715, 352.40063, 366.45523, 375.98926, 371.1832, 353.88455, 376.23962, 351.27756, 322.98572, 372.51407, 378.38058, 366.27408, 361.59937, 319.2538, 318.89267, 343.89792, 335.85764, 362.32108, 381.6857, 353.08038, 369.448, 342.23288, 343.5889, 352.9405, 348.42334, 358.69257, 361.1204, 365.42834, 364.01212, 338.5565, 353.29077, 336.64902, 341.43408, 309.5733, 304.84048, 330.3048, 354.17032, 357.31363, 297.86792, 339.07495, 344.9573, 362.85632, 390.0037, 404.1448, 381.77676, 393.63583, 410.66537, 382.74033, 351.1952, 369.95026, 370.85684, 373.46472, 396.94467, 357.91217, 374.07892, 366.62933, 406.4108, 393.56906, 408.94342, 413.33234, 412.96158, 370.1252, 367.81442, 344.66998, 381.0891, 387.44934, 382.46194, 393.21115, 409.27588, 401.4453, 416.28564, 445.6965, 395.01044, 374.4763, 379.95288, 360.33038, 368.29285, 373.83627, 425.18198, 481.25854, 449.37524, 415.17477, 408.30356, 376.43686, 372.64862, 385.2543, 373.33118, 351.0739, 345.538, 326.03674, 333.4923, 336.56888, 331.63797, 338.9402, 353.51855, 374.86197, 379.76154, 403.10876, 444.7779, 378.86264, 424.67432, 379.17145, 370.03723, 385.83536, 374.073, 402.30893, 422.50848, 396.22565, 395.4061, 410.4669, 389.8676, 407.76578, 429.11914, 391.50662, 394.8448, 417.99005, 441.8547, 422.1145, 458.15366, 485.1152, 422.7589, 398.06436, 384.4625, 367.52402, 364.0072, 404.61502, 400.13156, 431.1938, 416.0271, 428.05383, 390.42264, 369.52414, 366.39642, 408.80402, 415.70105, 375.69434, 400.7873, 435.43243, 407.85608, 442.76978, 414.9685, 372.71545, 391.2611, 450.07755, 457.06775, 431.68835, 453.26157, 428.11328, 459.49432, 405.8705, 397.9966, 402.154, 426.2789, 412.2588, 422.8202, 380.5235, 380.91223, 387.55945, 425.28232, 445.55325, 394.12732, 415.43347, 391.3324, 398.9489, 369.79218, 403.48553, 415.4314, 413.43112, 434.44794, 396.32303, 389.82663, 420.5227, 422.60236, 410.98685, 410.75885, 400.70428, 394.85107, 392.9716, 381.5406, 429.16623, 442.46155, 426.0425, 411.94385, 454.56662, 470.6266, 485.99615, 423.05103, 403.57312, 399.08313, 401.98322, 403.93277, 366.76837, 353.45932, 366.1319, 389.65982, 395.31287, 403.32803, 401.31805, 395.62772, 377.91953, 368.57812, 400.61, 381.66156, 384.83798, 371.50565, 392.70276, 373.45667, 366.1011, 404.28058, 399.16995, 440.18198, 442.1488, 412.09235, 419.6733, 413.54218, 400.96332, 432.61542, 431.9184, 437.97537, 401.61444, 423.54062, 449.71133, 436.39816, 412.11548, 396.0793, 395.65997, 397.65106, 402.23407, 386.90805, 370.48108, 395.3459, 426.18402, 402.39133, 406.26117, 377.77634, 364.93097, 382.2819, 447.9129, 425.20355, 428.6103, 375.57394, 384.23364, 365.57718, 366.0268, 375.7321, 386.54083, 371.1539, 371.68643, 360.19708, 316.80408, 330.43506, 396.7016, 398.77463, 405.51434, 406.47638, 401.2912, 367.61984, 392.46536, 370.73804, 396.6908, 400.63477, 414.25543, 395.89642, 397.5175, 460.3712, 378.66635, 393.03787, 411.65213, 376.45068, 376.3544, 392.9817, 393.47278, 370.25305, 365.85892, 379.219, 380.08716, 403.81082, 403.94724, 368.97913, 360.6771, 338.9887, 379.91833, 372.9779, 402.97476, 353.96243, 347.20303, 381.8473, 374.61978, 395.71112, 395.3011, 389.27396, 403.96207, 424.16183, 426.46652, 413.72458, 415.63513, 415.89877, 442.34048, 438.97604, 418.16382, 409.72113, 398.92328, 423.46268, 443.43378, 437.3908, 414.56085, 402.5666, 424.2868, 429.73383, 409.85953, 395.40833, 375.95007, 409.46774, 405.9003, 418.32523, 377.59546, 378.4952, 399.9466, 414.81662, 405.99265, 436.16483, 461.49377, 434.33786, 418.45047, 415.13687, 409.9726, 389.20224, 367.1986, 376.55255, 403.71896, 395.07162, 389.136, 368.99188, 393.43597, 399.25204, 431.24817, 407.9616, 392.80853, 390.27533, 396.6183, 432.48593, 414.62634, 364.71805, 382.0201, 378.4988, 370.85785, 348.65567, 361.4576, 380.73276, 357.56766, 354.21698, 354.83774, 368.97455, 381.41232, 334.03302, 334.93445, 353.76663, 369.50357, 394.91168, 337.39526, 344.14008, 375.13687, 373.95486, 370.85855, 346.4547, 358.5159, 377.04843, 375.3728, 349.77695, 333.34985, 334.4938, 350.99524, 352.0262, 390.239, 361.0478, 357.17316, 374.7334, 338.36465, 361.9315, 411.4541, 379.3576, 375.83893, 345.97144, 340.73645, 374.4275, 374.4204, 353.17657, 326.54773, 345.6264, 337.9801, 329.20105, 7379.4463, 3083.8354, 1603.7964, 719.7939, 488.7725, 614.0962, 380.75607, 284.798, 290.94806, 282.72852, 278.6997, 237.02621, 245.97575, 239.72038, 226.65215, 263.6888, 267.88565, 248.98569, 286.36487, 291.24292, 269.00244, 284.97845, 329.17926, 336.147, 353.0296, 329.1647, 396.14258, 358.55432, 349.9099, 338.08823, 362.29575, 354.0277, 386.34195, 376.44284, 394.69608, 369.38315, 360.1589, 379.1228, 363.03717, 405.7139, 335.60968, 362.7232, 418.57443, 389.04825, 400.33725, 405.4515, 384.5634, 372.3812, 391.81375, 367.1581, 369.47, 376.16425, 354.01328, 348.21686, 338.28757, 390.7832, 403.6192, 418.4616, 401.92426, 405.17996, 416.33224, 432.84717, 409.6602, 412.42978, 424.31735, 418.0731, 425.07858, 405.21268, 427.74554, 411.10114, 438.7282, 397.43204, 423.1953, 447.11444, 417.00427, 366.5649, 340.6776, 372.2066, 380.48572, 363.7271, 393.55975, 387.5459, 402.76666, 383.1265, 387.1552, 375.46008, 409.2265, 412.27576, 402.05908, 430.3574, 410.01196, 348.42435, 379.16937, 365.75208, 408.66574, 386.77533, 397.05713, 396.85498, 409.58728, 417.1513, 438.06534, 409.51193, 354.15704, 354.722, 337.47455, 368.88034, 346.19492, 400.23187, 391.9186, 363.7553, 392.86932, 409.3763, 396.26605, 355.32468, 375.59943, 371.89438, 417.35315, 423.91757, 417.97894, 403.57004, 396.07956, 391.89566, 391.75156, 356.93622, 370.94882, 379.75888, 415.70352, 396.68976, 424.2505, 401.27838, 374.24496, 373.69183, 381.6416, 354.80914, 300.23215, 290.30878, 280.19452, 274.90915, 262.28574, 283.03067, 311.14926, 283.24768, 246.33104, 258.95596, 292.32767, 277.52377, 269.34604, 251.88596, 261.07928, 269.4506, 321.5762, 322.9768, 323.05603, 332.21173, 336.34366, 337.57434, 334.81207, 374.75922, 352.49872, 347.82843, 386.04367, 378.61716, 369.0656, 384.85165, 398.5629, 383.6417, 387.57355, 343.538, 323.2887, 381.25006, 378.5576, 359.79865, 329.18686, 334.9507, 363.93732, 356.67905, 369.627, 332.63138, 320.82083, 322.34247, 354.78748, 360.60733, 344.56363, 359.32336, 348.20544, 357.38803, 349.17056, 337.7112, 344.8015, 345.4859, 306.99768, 372.02393, 314.14606, 314.02005, 319.50427, 295.82837, 318.37985, 333.02353, 338.8107, 334.8533, 360.357, 347.98654, 334.10287, 298.43134, 305.14258, 317.51434, 316.89908, 340.00247, 357.12064, 345.99554, 336.27823, 387.6393, 362.49988, 377.4655, 377.33145, 375.54947, 343.59775, 356.51495, 374.3896, 384.4861, 365.6386, 308.23804, 282.77798, 359.63937, 346.05823, 358.21692, 364.76486, 370.1396, 371.454, 344.2268, 354.75836, 338.78195, 340.85248, 361.0521, 357.81186, 344.4735, 332.3025, 355.06396, 350.7832, 339.14822, 351.8304, 362.37866, 348.95923, 339.71393, 344.78592, 359.04034, 344.5241, 336.0815, 347.16672, 317.24396, 292.17987, 287.9171, 263.29633, 287.19778, 352.0283, 340.28824, 344.57858, 358.22015, 376.31033, 359.56195, 332.5632, 347.7289, 365.58282, 364.04517, 357.52118, 362.31348, 347.76242, 373.20987, 349.3566, 342.1143, 324.39734, 367.3852, 347.3304, 329.98633, 375.29895, 371.1589, 358.31262, 336.19382, 351.55417, 382.75195, 365.49014, 388.08972, 367.8362, 392.05118, 351.60532, 337.3181, 352.6964, 362.09735, 351.78412, 348.6583, 354.63498, 367.6131, 357.73666, 346.70825, 331.36636, 323.9048, 345.39703, 367.06747, 372.96634, 369.91064, 382.6833, 379.1594, 361.94342, 361.4872, 357.99002, 374.18463, 346.64087, 323.78146, 338.8263, 347.35855, 335.87698, 336.21753, 332.951, 338.39764, 380.1646, 392.10852, 368.88824, 362.4366, 377.67114, 355.65234, 354.24756, 351.92297, 361.42975, 371.35068, 383.23196, 363.0719, 368.29807, 347.2088, 347.13562, 339.6351, 339.4332, 324.53778, 369.52133, 371.78387, 333.60352, 331.835, 365.48636, 365.20117, 365.58615, 358.4344, 362.07764, 389.41977, 394.97302, 366.88834, 351.66956, 330.41968, 324.01282, 352.4211, 351.0249, 373.49963, 346.54013, 333.31653, 323.1436, 374.91174, 400.15698, 389.7662, 366.3609, 321.0783, 331.68674, 331.3658, 341.99634, 355.29575, 377.36713, 391.15286, 429.67328, 386.31754, 381.5114, 339.05392, 353.93195, 373.0241, 344.13113, 334.9616, 338.2574, 325.35626, 325.7072, 398.8133, 371.0093, 353.55237, 359.0654, 352.90854, 331.236, 355.0523, 433.59213, 407.01428, 323.5661, 325.4366, 354.1312, 357.0497, 346.1216, 376.11353, 384.53314, 378.14563, 336.28165, 330.03085, 349.7402, 332.7025, 343.3909, 346.65323, 390.11774, 372.11688, 328.92297, 353.76947, 406.1995, 342.86066, 308.37952, 328.33664, 341.62405, 343.72855, 343.00385, 314.21448, 302.20996, 288.0412, 340.3798, 326.3054, 320.77316, 333.97693, 333.4881, 300.42847, 301.9933, 319.5145, 296.42136, 307.23297, 335.71664, 376.94006, 360.8029, 398.35852, 343.36462, 339.4244, 353.0074, 341.15726, 372.72885, 386.78757, 368.75662, 350.8148, 343.7227, 349.48502, 374.41647, 386.20697, 366.47214, 394.6182, 395.4437, 398.76648, 354.7424, 354.49866, 345.99536, 380.57657, 382.01526, 383.3067, 381.6189, 368.1427, 376.55182, 364.00726, 366.53046, 337.58994, 383.70435, 336.1223, 338.5072, 350.70627, 366.0295, 346.6477, 350.39856, 371.25406, 378.94037, 371.86957, 373.09644, 387.52762, 380.75092, 378.75674, 370.4634, 335.47208, 369.045, 400.73206, 310.3882, 332.44012, 389.3376, 346.34146, 331.97623, 325.58917, 343.48312, 361.84702, 329.4567, 323.65677, 355.08005, 371.4211, 363.53433, 365.20877, 381.62686, 405.30316, 384.70325, 372.65088, 361.35645, 348.50143, 382.14062, 367.6991, 361.48636, 335.78116, 344.18713, 338.15985, 332.648, 339.89944, 329.07343, 353.1826, 299.89926, 337.13086, 351.35092, 333.70657, 366.6491, 342.30508, 343.7011, 364.2379, 390.1851, 311.7226, 340.57773, 338.0331, 403.38528, 363.73145, 373.0885, 337.26645, 352.3367, 346.67648, 324.39856, 336.24036, 364.64178, 370.8831, 345.7077, 339.7934, 355.7188, 379.57333, 355.97406, 324.0474, 332.48502, 350.5156, 366.94608, 354.2672, 336.79968, 344.2948, 368.0329, 352.07254, 363.89975, 368.1317, 372.91492, 352.7714, 352.40778, 368.65833, 406.18158, 373.57977, 375.3695, 404.7015, 395.0265, 395.4409, 428.7283, 425.03818, 385.99738, 330.14346, 350.5719, 378.2929, 378.5799, 400.31824, 407.2767, 413.77155, 396.40723, 375.1763, 355.3386, 363.92664, 345.26077, 328.24902, 326.05597, 358.3716, 360.59915, 356.04593, 360.20337, 367.54474, 370.97668, 364.61792, 352.80048, 349.03345, 333.02917, 323.5379, 348.92236, 340.66248, 324.35028, 334.89575, 335.15082, 345.54742, 354.09955, 352.51257, 352.40863, 361.2343, 377.7141, 371.05463, 365.40332, 335.3537, 344.39948, 327.00317, 326.0334, 335.01764, 324.9621, 347.87482, 331.39563, 330.14752, 322.7395, 327.0172, 336.14478, 323.85016, 318.6878, 366.3731, 351.5765, 338.5296, 309.8373, 322.63763, 358.45544, 337.14935, 338.1038, 344.67194, 318.13657, 317.2355, 363.725, 350.01547, 359.83252, 335.70407, 329.99716, 322.5699, 336.93344, 353.23737, 348.54242, 337.15918, 335.25546, 385.47037, 364.5588, 377.08978, 370.04602, 343.0001, 335.24725, 344.95007, 347.43744, 385.55878, 385.28662, 356.04578, 370.64255, 359.13843, 417.39682, 377.38107, 382.0062, 323.41125, 335.49164, 350.28787, 420.11176, 391.67722, 361.41025, 345.48682, 368.2291, 354.4374, 355.3298, 380.08386, 407.64288, 408.90317, 388.0941, 382.43784, 383.48016, 367.58212, 348.5953, 383.3912, 352.42172, 340.25916, 358.11935, 364.53186, 363.77997, 360.59894, 343.83563, 341.19394, 391.92215, 359.29755, 358.2256, 332.42667, 343.02005, 288.38937, 308.6405, 289.8534, 285.1936, 282.1226, 301.19415, 320.4116, 318.75473, 308.82874, 353.3093, 391.8053, 356.78748, 389.60257, 340.44485, 351.401, 388.87723, 368.18018, 374.5447, 383.5632, 375.53802, 353.15866, 354.2072, 314.394, 323.97974, 366.272, 381.0543, 341.17365, 304.74536, 349.76804, 368.4974, 368.33038, 306.9043, 360.8382, 323.0339, 325.02206, 317.4745, 319.7928, 320.5467, 332.01804, 368.09787, 300.99374, 329.13086, 332.51718, 358.21832, 384.812, 323.18546, 365.88745, 363.07166, 388.87537, 341.4511, 286.90668, 223.66473, 223.42824, 231.5385, 235.62059, 232.06627, 225.69606, 254.41182, 236.31085, 231.63698, 230.91267, 222.14784, 224.8648, 228.98018, 216.94434, 227.01997, 213.70331, 231.01947, 253.48929, 249.46545, 241.3212, 266.40875, 243.63591, 228.42136, 234.38666, 226.37997, 241.80658, 218.71036, 225.09216, 272.78198, 258.82748, 313.52524, 305.4034, 372.3569, 411.73828, 392.29315, 378.45544, 359.3224, 357.05652, 368.18945, 378.72067, 396.32898, 417.57352, 405.57227, 370.5721, 397.30276, 356.02936, 364.96674, 402.13788, 396.23767, 361.06262, 375.9898, 395.1964, 396.4737, 413.94934, 446.51376, 410.02808, 388.54337, 377.01935, 413.07074, 416.1435, 417.6698, 427.74957, 424.6795, 405.5018, 399.4498, 379.90094, 401.75916, 404.45187, 395.8109, 401.57376, 432.6037, 431.60886, 388.34116, 391.33865, 356.59967, 377.1846, 346.35245, 354.10202, 340.08893, 340.69464, 349.24377, 316.83203, 324.00745, 338.55334, 370.33456, 364.96344, 341.8432, 350.28537, 340.93506, 324.21475, 298.34973, 333.1558, 347.72708, 347.25385, 360.1352, 377.90564, 378.49902, 362.18747, 371.70605, 388.4646, 374.63126, 361.49277, 372.4525, 363.2763, 345.1577, 336.80627, 346.8438, 369.58478, 364.92142, 400.32996, 424.88483, 432.0682, 380.829, 396.5, 396.4685, 394.37607, 401.03268, 397.70612, 430.9736, 463.23163, 409.61676, 401.13522, 394.8626, 423.05475, 407.96545, 402.95844, 429.3418, 388.8632, 362.23245, 381.20038, 349.5144, 327.40714, 326.8742, 309.00333, 364.07846, 377.43042, 377.3, 357.5312, 361.09302, 352.7882, 343.714, 328.44775, 354.72604, 365.2929, 369.17743, 362.17804, 360.21783, 363.49304, 354.93628, 316.30408, 319.797, 362.48712, 366.22156, 364.22784, 350.06897, 338.4566, 334.16812, 348.62558, 335.54462, 344.25507, 341.81717, 379.51956, 324.13193, 339.82214, 346.4802, 336.16333, 335.84222, 359.9514, 332.70587, 329.50943, 368.2045, 392.19672, 373.55695, 370.27982, 374.21234, 334.5058, 333.0546, 338.35986, 360.37894, 377.508, 372.75748, 346.32373, 364.77145, 353.69763, 343.96088, 321.45905, 303.04642, 318.539, 324.35382, 330.18256, 323.7089, 383.45807, 365.32224, 384.3421, 363.0248, 366.4845, 382.2799, 346.4842, 319.80862, 330.8288, 349.1759, 337.4053, 340.9447, 347.49722, 365.9462, 352.52896, 347.59326, 329.34836, 330.4613, 324.73795, 323.12732, 345.58398, 347.51346, 340.15244, 303.68555, 335.41425, 351.68228, 369.8676, 338.971, 332.62933, 358.54895, 333.80463, 371.83096, 319.71152, 317.60095, 317.04648, 353.6268, 323.96844, 329.71643, 340.77948, 339.65567, 350.50003, 362.08954, 323.4266, 331.57523, 329.7472, 299.42917, 317.77066, 327.96167, 330.78015, 334.73413, 358.98016, 334.61172, 329.5081, 329.91882, 364.06293, 333.78394, 369.78012, 344.8684, 331.2564, 341.55225, 388.65375, 417.9876, 389.29684, 346.49298, 359.7262, 375.31808, 355.24112, 400.98138, 391.63333, 354.67938, 348.77585, 357.44788, 368.7479, 330.3539, 325.91147, 318.92975, 347.24713, 350.87952, 337.15598, 333.96326, 346.97797, 361.4228, 352.81082, 367.291, 371.32944, 362.47894, 373.7605, 356.6844, 372.6565, 396.46143, 418.98224, 418.97394, 400.21396, 374.18546, 371.2066, 407.195, 426.38348, 444.89224, 405.8996, 387.69452, 406.0928, 434.40326, 410.9102, 412.39432, 389.8647, 378.68338, 385.23474, 402.57736, 399.45004, 398.51468, 397.7624, 385.48773, 360.24774, 391.2325, 416.80045, 407.22766, 397.30847, 405.37512, 404.13715, 433.60513, 424.88916, 424.7895, 391.17902, 418.1947, 374.08362, 392.00702, 357.0317, 352.7623, 326.44855, 362.3664, 374.9038, 367.60666, 365.30533, 377.63275, 370.6443, 385.58704, 366.8444, 378.49103, 370.73672, 368.74493, 372.5641, 401.7482, 448.5341, 423.8099, 433.60605, 380.6738, 364.0423, 387.1585, 398.9036, 410.1784, 367.3814, 398.88565, 372.00452, 329.72708, 363.9484, 363.39957, 335.05347, 344.06778, 382.38043, 340.89212, 346.78638, 355.9898, 357.11865, 330.4511, 327.08987, 342.00922, 359.67114, 394.75745, 359.17877, 360.68427, 382.66815, 365.32806, 363.02625, 328.9149, 372.38358, 387.9193, 405.71793, 407.17682, 396.93024, 388.31183, 378.23834, 380.67007, 410.86142, 402.273, 380.22995, 379.29257, 401.2979, 361.6649, 396.322, 369.04248, 347.1781, 366.91623, 344.7107, 355.93884, 361.4828, 366.3212, 375.15643, 333.02155, 331.31522, 371.0952, 346.43332, 340.77063, 392.03693, 380.70724, 371.98688, 367.58478, 365.82675, 353.58386, 337.72168, 376.36612, 356.11823, 339.77972, 353.7855, 343.39215, 335.07565, 359.45435, 348.2636, 362.37894, 373.94934, 411.0007, 387.103, 355.41895, 336.07977, 392.25702, 379.11713, 390.73468, 370.25348, 389.9884, 389.43503, 381.20337, 367.50616, 360.16464, 372.71515, 341.3138, 398.80154, 442.1703, 409.2503, 362.47714, 324.42035, 344.32635, 337.97858, 337.33643, 359.87192, 338.94946, 315.14984, 341.1832, 355.78946, 365.67307, 362.52722, 366.8698, 333.94354, 330.12985, 342.8413, 337.42224, 346.64453, 382.62878, 334.31586, 362.23358, 354.85095, 364.58057, 355.26294, 313.7073, 318.8636, 365.1443, 371.2901, 345.31372, 330.73077, 347.98694, 366.91675, 356.8076, 389.88898, 409.44592, 404.80515, 366.09872, 349.01465, 334.54565, 337.21808, 338.16614, 377.1919, 373.62158, 360.2894, 344.56506, 349.0314, 333.2915, 333.35794, 336.59692, 360.293, 353.86816, 348.56293, 369.8185, 364.792, 356.94376, 351.19934, 341.09116, 354.65015, 360.08463, 370.87848, 373.32388, 374.10028, 353.66962, 328.55057, 333.02704, 327.6776, 341.618, 317.63223, 330.2219, 332.31726, 324.3344, 338.60278, 333.12088, 348.82733, 361.6699, 400.5392, 399.48645, 386.1932, 399.54782, 374.3988, 380.5318, 361.82263, 368.6556, 394.98737, 380.30908, 390.2678, 402.3822, 379.5995, 365.0377, 379.83557, 409.43915, 356.32812, 336.98068, 276.35364, 241.0513, 242.5522, 257.56534, 245.21506, 242.69449, 233.73943, 230.09988, 261.6689, 267.5387, 256.3025, 269.348, 240.85268, 249.00223, 234.71158, 261.40182, 294.25592, 269.94257, 290.97144, 297.62863, 267.89288, 254.67169, 266.07858, 252.56598, 263.1257, 261.75912, 261.797, 274.9677, 310.33255, 297.51178, 264.68582, 307.6807, 268.30432, 268.9273, 280.65164, 262.14328, 254.38046, 251.20032, 259.52686, 264.08862, 275.68222, 275.27402, 285.95535, 278.4294, 292.86096, 319.41345, 281.267, 263.29007, 257.8006, 254.8316, 249.28412, 261.57547, 261.49164, 297.0389, 276.2164, 272.87366, 276.60098, 280.33572, 277.63608, 305.71875, 282.9197, 281.3265, 325.6446, 300.015, 291.33893, 281.12827, 338.26923, 343.09323, 358.12692, 313.434, 292.29172, 270.86557, 268.79562, 283.56198, 300.0386, 301.131, 294.18866, 278.3183, 265.23962, 285.09116, 291.81183, 272.91275, 266.44455, 282.97733, 271.06555, 269.64624, 261.8769, 259.23676, 273.3989, 254.05508, 281.32605, 273.8656, 274.96246, 262.17844, 252.13092, 266.05182, 261.6751, 265.66837, 307.60526, 288.3426, 274.3621, 249.16644, 271.29355, 286.96143, 259.14325, 300.49878, 378.29755, 420.43762, 436.06058, 397.3739, 382.49994, 382.91113, 397.94492, 432.05524, 435.57614, 411.66986, 370.23706, 413.53864, 409.2473, 373.05457, 379.6405, 378.08838, 443.4188, 401.56305, 389.60834, 367.26266, 382.64236, 408.98627, 446.8803, 428.3357, 374.61377, 354.45285, 345.49808, 361.3341, 401.4652, 386.20752, 365.0558, 343.30847, 348.71118, 342.69452, 365.1707, 382.52585, 390.31238, 390.8081, 384.8038, 428.20435, 399.68347, 374.45007, 385.96027, 387.7113, 393.4383, 396.26294, 371.13345, 401.38205, 388.1889, 406.76282, 401.56616, 431.51758, 444.468, 431.6588, 409.6334, 378.92834, 372.35925, 347.21255, 386.35577, 410.8239, 412.12497, 401.15808, 406.60162, 403.05344, 394.88403, 356.37476, 365.247, 398.7161, 413.7909, 384.42847, 447.1358, 359.5189, 371.2292, 375.8231, 379.00812, 401.84222, 405.6793, 416.7671, 396.29578, 394.453, 387.14893, 406.2707, 403.4246, 413.20856, 415.6536, 434.38525, 404.27103, 372.51282, 369.5066, 388.80145, 405.80255, 434.0162, 444.44403, 405.49078, 416.93796, 387.92426, 399.0626, 387.92203, 380.38553, 381.0791, 381.2958, 386.45148, 374.77664, 367.65015, 352.41644, 365.9267, 401.02606, 402.72726, 367.49326, 371.90125, 397.57712, 370.46542, 399.53946, 404.2552, 404.42743, 378.37863, 374.86533, 375.104, 390.47284, 402.3862, 410.12994, 373.72107, 370.1034, 392.8375, 406.17377, 383.65015, 413.4972, 410.51404, 355.23587, 354.9286, 353.8784, 330.71237, 327.8387, 331.41174, 370.9629, 409.6504, 441.1523, 415.05283, 371.71893, 371.90952, 359.4052, 378.4198, 363.08844, 371.56656, 403.59656, 409.14066, 410.2315, 386.66553, 382.5507, 369.02054, 383.32782, 387.12317, 389.00256, 405.79715, 407.7533, 419.67386, 390.03052, 369.04523, 367.9759, 384.18338, 377.06128, 392.4643, 374.85324, 377.12173, 401.69586, 380.65326, 386.66412, 389.88174, 389.88193, 363.50046, 399.64423, 368.9817, 337.40274, 382.86493, 391.71292, 386.5632, 396.2983, 360.9497, 371.06415, 398.71454, 386.9444, 383.19714, 384.62292, 398.5615, 384.65826, 426.806, 410.17188, 405.0393, 382.82666, 401.93777, 411.08472, 410.617, 367.5679, 369.4234, 365.43637, 409.08624, 369.27094, 360.95303, 384.73398, 408.6354, 410.18906, 438.21228, 447.81775, 402.17084, 351.81537, 366.36465, 411.19592, 418.09448, 385.56516, 417.6849, 431.72723, 430.4585, 413.7665, 423.96976, 399.4797, 420.724, 391.42398, 383.235, 352.34787, 356.914, 379.17444, 402.88467, 394.1415, 403.16498, 413.5515, 374.8214, 380.7555, 357.48557, 425.768, 368.6419, 356.31763, 347.0126, 366.92804, 380.4329, 362.2043, 379.64133, 411.07172, 401.65466, 372.43237, 392.41135, 443.20895, 407.1629, 370.57336, 358.58356, 351.93552, 374.34134, 380.39133, 384.36267, 386.72415, 374.00467, 362.5453, 396.8463, 381.0041, 368.70108, 370.50665, 355.75635, 387.46515, 386.1935, 385.83087, 399.77325, 390.50098, 354.8127, 336.52557, 397.9368, 416.25345, 410.46924, 427.98535, 408.3348, 374.18167, 346.74066, 359.15338, 361.67163, 367.85593, 392.0601, 414.19455, 405.70227, 378.50684, 374.17413, 370.06628, 404.05426, 356.1043, 364.25934, 359.03107, 391.1271, 389.5579, 364.17706, 357.28766, 340.97018, 341.76962, 346.49365, 341.60522, 323.12515, 336.5665, 329.18927, 324.63043, 364.77148, 340.58893, 387.43182, 412.9832, 357.276, 375.61005, 330.4781, 309.65845, 323.40616, 317.42822, 331.12256, 321.25983, 346.25534, 331.93192, 318.24796, 338.64447, 358.60828, 328.8536, 365.1807, 350.7887, 348.6144, 322.0871, 348.88116, 339.4062, 343.50998, 341.985, 332.62238, 358.09668, 376.83002, 392.642, 358.08777, 359.8968, 378.97067, 378.4773, 405.67352, 395.29147, 361.45905, 347.30383, 359.5807, 353.17188, 377.81265, 367.37775, 365.91394, 359.5105, 339.12054, 355.44904, 379.3187, 357.8758, 384.95993, 405.05133, 396.61212, 417.19714, 388.07062, 388.13034, 383.82184, 404.0898, 346.20508, 402.53824, 459.32812, 442.58752, 409.91144, 349.88037, 359.29245, 386.65448, 430.7395, 373.9556, 395.72018, 371.76007, 381.69092, 361.6939, 319.71277, 329.50363, 334.21692, 349.98688, 384.5974, 364.02383, 343.62195, 391.8916, 353.89563, 356.23718, 387.562, 381.98795, 376.2182, 393.35422, 361.74396, 402.6872, 420.22476, 415.54776, 418.2674, 438.51123, 407.06998, 396.96924, 411.20032, 410.55887, 392.42957, 381.50037, 375.94333, 398.72162, 389.77567, 368.0575, 385.4422, 349.1679, 351.99243, 368.4195, 374.09888, 389.41663, 379.64655, 384.71652, 383.50653, 360.10333, 340.87628, 333.4526, 344.98016, 359.03214, 334.5968, 354.74872, 398.00836, 384.1926, 383.24997, 377.45035, 370.50415, 377.4754, 388.022, 403.7346, 380.18213, 405.11047, 394.32513, 349.41403, 328.58136, 327.25293, 397.28125, 378.27383, 362.4061, 355.95172, 336.856, 375.75656, 389.92447, 391.50433, 352.54523, 392.69046, 356.05948, 370.74097, 352.3032, 406.41724, 419.32947, 387.45258, 403.9298, 422.11444, 395.85593, 380.1761, 367.7313, 358.96936, 368.9769, 410.9048, 353.8949, 395.14523, 393.1058, 395.79428, 372.19778, 387.9074, 369.8396, 353.40158, 383.7088, 414.3238, 389.95004, 405.40958, 380.73007, 371.36786, 388.54123, 402.3428, 366.32532, 363.3138, 375.78937, 360.25403, 371.74457, 351.80194, 370.25302, 348.27695, 303.9739, 356.81097, 390.39554, 390.50928, 392.70233, 379.69348, 403.53806, 401.4605, 377.89218, 382.40887, 341.37643, 352.79587, 370.18616, 396.50998, 390.5286, 384.17325, 371.68048, 337.13797, 355.2577, 399.50784, 406.84485, 389.97296, 377.882, 390.69577, 397.19495, 380.4125, 375.935, 367.82697, 381.58228, 390.23212, 405.06464, 359.2844, 329.18634, 340.78116, 375.5121, 381.74805, 339.54718, 371.56042, 383.77325, 388.68277, 395.09222, 367.97433, 356.1261, 341.3261, 349.25607, 335.28235, 327.0746, 342.5573, 315.11755, 387.32462, 343.32532, 324.8656, 338.14252, 371.15796, 393.59076, 374.93103, 357.135, 373.0339, 378.5744, 383.38406, 366.03424, 353.21478, 372.29828, 381.62305, 415.60168, 365.8277, 376.9529, 380.4443, 350.91296, 376.219, 348.76932, 357.68164, 345.9371, 366.14038, 376.5375, 383.57437, 396.4654, 372.40594, 370.93387, 367.09158, 387.11734, 367.80533, 376.38922, 341.39496, 378.81155, 387.837, 374.48096, 383.61316, 416.17087, 367.95636, 364.1113, 348.7489, 328.17734, 375.50864, 353.56833, 331.36365, 330.6724, 362.82153, 369.80084, 389.98645, 364.1321, 346.9835, 344.87057, 357.8189, 333.187, 341.24786, 326.03897, 327.26175, 368.04193, 360.49377, 334.4911, 334.3064, 316.58093, 357.10956, 355.43475, 375.64874, 410.8128, 420.22458, 407.13672, 398.91263, 374.54678, 354.7556, 381.82104, 384.71216, 362.49115, 352.65305, 296.1591, 337.87537, 368.76517, 346.65945, 327.4627, 352.12363, 327.24927, 347.08618, 340.91632, 360.8554, 374.54044, 362.55096, 380.72046, 392.3948, 369.79575, 370.04495, 398.70212, 370.69617, 392.51068, 394.46423, 384.4025, 370.56866, 379.02307, 366.3475, 388.32028, 444.46048, 401.39636, 394.57803, 408.7876, 382.1014, 387.46777, 370.23846, 338.4842, 328.98788, 335.27, 378.34402, 335.99597, 325.47504, 352.25836, 354.96765, 383.6139, 377.13876, 373.55682, 355.0588, 379.09357, 373.3808, 410.36218, 475.4419, 421.8062, 378.21033, 361.65036, 370.8387, 398.4051, 394.58508, 364.8886, 375.84534, 340.49725, 385.3201, 346.54907, 335.15137, 367.48328, 381.31793, 373.1996, 394.63983, 387.38962, 350.46613, 326.2838, 356.75482, 363.4436, 358.8624, 367.95743, 325.73956, 354.56696, 338.01642, 340.4602, 341.4995, 373.36792, 404.1543, 381.59967, 372.85364, 363.1816, 372.46454, 382.27136, 401.06866, 362.46063, 378.88287, 369.08652, 409.00494, 391.96954, 386.59738, 401.9216, 412.83554, 370.0947, 338.32773, 345.53998, 389.86172, 420.60406, 377.60034, 405.31033, 337.368, 364.09372, 399.84128, 375.3207, 404.8376, 401.71283, 392.38223, 362.87054, 386.77643, 364.74835, 337.9139, 343.09344, 343.2771, 346.0132, 385.537, 370.06107, 347.5903, 363.33716, 377.07452, 391.74698, 394.8164, 387.14432, 362.17944, 356.76865, 370.48743, 344.51324, 368.5425, 400.4653, 385.2537, 355.91608, 347.49664, 361.64142, 357.16486, 369.81018, 374.40656, 366.90283, 402.22638, 397.73178, 368.2593, 366.21844, 370.1105, 349.7477, 349.44208, 362.1845, 381.54382, 378.08395, 357.26352, 354.00842, 362.37833, 362.9079, 345.67834, 338.8677, 357.9436, 327.00415, 306.69144, 312.0923, 354.68936, 355.86676, 388.5904, 385.7202, 375.06476, 382.91663, 419.84012, 396.43137, 374.42746, 350.66785, 348.60715, 343.15723, 378.22916, 353.22333, 343.02402, 385.26007, 383.71777, 357.13483, 374.42673, 380.71368, 384.82162, 365.09982, 375.2552, 354.86, 388.19214, 427.49155, 407.98267, 384.15973, 355.27942, 349.1583, 377.02676, 400.73413, 383.78354, 370.84882, 369.89413, 406.2536, 400.98828, 365.91388, 409.41794, 346.61307, 369.22223, 387.55502, 391.60574, 352.24564, 331.91013, 354.5827, 372.2411, 383.4269, 355.51346, 366.86432, 367.12787, 353.86816, 372.24457, 321.22968, 321.13962, 316.43512, 339.1687, 344.3447, 313.1777, 266.88214, 247.64606, 235.33057, 248.34906]\n"
     ]
    }
   ],
   "source": [
    "#checking Q values of (0,0,0) state action (0,4)\n",
    "print('Mean Q_Value: {} and median is :{} \\n'.format(np.mean(agent.states_tracked),np.median(agent.states_tracked)))\n",
    "print(agent.states_tracked)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference: As we can see Q-Value of (0,0,0) state action (0,4) coverging around 375 started from near 500."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting rewards per episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(0, figsize=(16,7))\n",
    "plt.title('Rewards per episode')\n",
    "xaxis = np.asarray(range(0, len(rewards_per_episode)))\n",
    "plt.plot(xaxis,np.asarray(rewards_per_episode))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference: Plotting rewards per episode, you can see that Rewards started from negative values ,after few episodes are getting approximately constant after 7500 episodes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Epsilon-decay sample function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Try building a similar epsilon-decay function for your model.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = np.arange(0,10000)\n",
    "epsilon = []\n",
    "for i in range(0,10000):\n",
    "    epsilon.append(0 + (1 - 0) * np.exp(-0.0009*i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(time, epsilon)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
